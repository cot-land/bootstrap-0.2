// AST-to-IR Lowering Pass
// Transforms parsed AST into flat IR suitable for SSA construction.
//
// Reference: src/frontend/lower.zig (Zig bootstrap)
// Reference: ~/learning/go/src/cmd/compile/internal/ssagen/ssa.go
//
// Design (following Go's walk patterns):
// 1. Walk AST in dependency order (declarations first, then expressions)
// 2. Emit IR nodes using FuncBuilder
// 3. Track loop context for break/continue
// 4. Handle control flow with explicit blocks

import "ast.cot"
import "ir.cot"
import "types.cot"
import "parser.cot"  // For parse_* functions
import "../lib/strmap.cot"  // For O(1) function lookup

// ============================================================================
// Lowerer Context
// ============================================================================

// Compile-time constant entry
struct ConstEntry {
    name_start: i64,
    name_len: i64,
    value: i64,
}

// cot1: Type alias entry for tracking type Name = TargetType
struct TypeAliasEntry {
    name_start: i64,    // Offset in source
    name_len: i64,      // Length of alias name
    target_type: i64,   // Resolved TypeRegistry type index
}

// MAX_CONSTANTS removed - using dynamic growth

// Dynamic reallocation for growing arrays (after struct definitions)
extern fn realloc_IRLocal(ptr: *IRLocal, old_count: i64, new_count: i64) *IRLocal;
extern fn realloc_IRNode(ptr: *IRNode, old_count: i64, new_count: i64) *IRNode;
extern fn realloc_IRFunc(ptr: *IRFunc, old_count: i64, new_count: i64) *IRFunc;
extern fn realloc_IRGlobal(ptr: *IRGlobal, old_count: i64, new_count: i64) *IRGlobal;
extern fn realloc_ConstEntry(ptr: *ConstEntry, old_count: i64, new_count: i64) *ConstEntry;

// Malloc externs for self-allocation (Lowerer allocates its own internal storage)
extern fn malloc_TypeAliasEntry(count: i64) *TypeAliasEntry;
extern fn malloc_MethodEntry(count: i64) *MethodEntry;
extern fn malloc_u8(count: i64) *u8;

// Initial capacities for Lowerer-owned storage
const LW_INIT_DEFER_STACK: i64 = 256;
const LW_INIT_TYPE_ALIASES: i64 = 256;
const LW_INIT_LABEL_STACK: i64 = 64;

// Copy function name string to owned buffer (matches Zig's func_name: []const u8)
fn copy_func_name(source: *u8, start: i64, len: i64) i64 {
    let buf: *u8 = malloc_u8(len + 1);
    var i: i64 = 0;
    while i < len {
        (buf + i).* = (source + start + i).*;
        i = i + 1;
    }
    (buf + len).* = 0;
    return @ptrToInt(buf);
}

// Get pointer to "memset_zero" string for call emission
// Following Zig pattern: src/frontend/lower.zig:486 emits call to memset_zero
fn get_memset_zero_name() i64 {
    let buf: *u8 = malloc_u8(12);  // "memset_zero" + null
    (buf + 0).* = 109;   // 'm'
    (buf + 1).* = 101;   // 'e'
    (buf + 2).* = 109;   // 'm'
    (buf + 3).* = 115;   // 's'
    (buf + 4).* = 101;   // 'e'
    (buf + 5).* = 116;   // 't'
    (buf + 6).* = 95;    // '_'
    (buf + 7).* = 122;   // 'z'
    (buf + 8).* = 101;   // 'e'
    (buf + 9).* = 114;   // 'r'
    (buf + 10).* = 111;  // 'o'
    (buf + 11).* = 0;    // null
    return @ptrToInt(buf);
}

// Get pointer to "exit" string for @assert failure
fn get_exit_name() i64 {
    let buf: *u8 = malloc_u8(5);  // "exit" + null
    (buf + 0).* = 101;   // 'e'
    (buf + 1).* = 120;   // 'x'
    (buf + 2).* = 105;   // 'i'
    (buf + 3).* = 116;   // 't'
    (buf + 4).* = 0;     // null
    return @ptrToInt(buf);
}

// print() and println() are built-in functions that handle strings and integers

// Struct field info for name-based lookup
struct StructFieldLookup {
    offset: i64,
    found: bool,
}

// cot1: Method registry entry for method call desugaring
// Maps (type_name, method_name) → synthesized_method_name
struct MethodEntry {
    type_name_start: i64,      // Start of type name in source
    type_name_len: i64,        // Length of type name
    method_name_start: i64,    // Start of method name in source
    method_name_len: i64,      // Length of method name
    synth_name_ptr: i64,       // Pointer to synthesized name (TypeName_methodName)
    synth_name_len: i64,       // Length of synthesized name
}

struct Lowerer {
    // AST to lower (pointer to Node array + count)
    nodes: *Node,
    nodes_count: i64,

    // Children array for lists (args, stmts, params)
    children: *i64,
    children_count: i64,

    // Source text for name extraction
    source: *u8,
    source_len: i64,

    // Type information for field access
    type_pool: *TypeRegistry,

    // Current function being lowered
    current_func: *FuncBuilder,

    // IR output storage (externally allocated)
    ir_nodes: *IRNode,
    ir_nodes_cap: i64,
    ir_nodes_count: i64,

    ir_locals: *IRLocal,
    ir_locals_cap: i64,
    ir_locals_count: i64,

    // Function metadata (externally allocated)
    ir_funcs: *IRFunc,
    ir_funcs_cap: i64,
    ir_funcs_count: i64,

    // Global variables (externally allocated)
    ir_globals: *IRGlobal,
    ir_globals_cap: i64,
    ir_globals_count: i64,
    globals_data_offset: i64,  // Running offset for globals in data section

    // Compile-time constants
    constants: *ConstEntry,
    constants_count: i64,
    constants_cap: i64,

    // cot1: Type aliases
    type_aliases: *TypeAliasEntry,
    type_aliases_count: i64,
    type_aliases_cap: i64,

    // Loop context for break/continue (block indices, -1 if not in loop)
    loop_continue_block: i64,
    loop_break_block: i64,
    loop_defer_depth: i64,        // defer_stack depth at loop entry

    // cot1: Label stack for labeled break/continue
    // Reference: Zig lower.zig label handling in GenZir
    label_names_start: *i64,      // Start positions of label names in source
    label_names_len: *i64,        // Lengths of label names
    label_break_blocks: *i64,     // Break block for each labeled loop
    label_continue_blocks: *i64,  // Continue block for each labeled loop
    label_defer_depths: *i64,     // Defer depth at each labeled loop entry
    label_count: i64,             // Current label stack depth
    label_cap: i64,               // Label stack capacity

    // Defer stack for pending defer expressions (Zig-style scope tracking)
    // When entering a block, record the current depth. On block exit, emit
    // defers from current depth down to recorded depth in LIFO order.
    // Reference: Zig lower.zig:59 defer_stack
    defer_stack: *i64,            // Array of node indices for deferred expressions
    defer_stack_count: i64,
    defer_stack_cap: i64,

    // call_args removed - args now stored directly in IRNode.call_args (matches Zig)

    // Function name → index map for O(1) lookup
    func_map: StrMap,
    // Function name → return type handle map for O(1) return type lookup
    func_ret_map: StrMap,

    // cot1: Synthesized names buffer for impl block methods
    // Stores "TypeName_methodName" strings for methods defined in impl blocks
    // name_start for these methods points into this buffer (as absolute pointer)
    synth_names: *u8,
    synth_names_count: i64,
    synth_names_cap: i64,

    // cot1: Track which FnDecl nodes are inside impl blocks
    // impl_method_flags[i] = 1 if node i is a method inside an impl block
    impl_method_flags: *u8,
    impl_method_flags_count: i64,

    // cot1: Method registry for method call desugaring
    // Maps (type_name, method_name) → synthesized_method_name
    method_registry: *MethodEntry,
    method_registry_count: i64,
    method_registry_cap: i64,

    // Test mode: when true, compile test declarations and generate test runner
    test_mode: i64,    // 0 = false, 1 = true

    // Collected test names for test runner generation
    // Each test name is stored as (start, len) pair into synth_names buffer
    test_name_starts: *i64,
    test_name_lens: *i64,
    test_names_count: i64,
    test_names_cap: i64,
}

// ============================================================================
// Type Resolution - TypeExpr AST Node to TypeRegistry Index
// ============================================================================
// Reference: src/frontend/checker.zig resolveTypeExpr(), resolveType()

// Resolve a TypeExpr AST node to a TypeRegistry index
// This is called by the lowerer when it needs to know the actual type

impl Lowerer {

    fn resolveNamedType(self: *Lowerer, name_start: i64, name_len: i64) i64 {
        // First check type aliases
        let alias_type: i64 = self.lookupTypeAlias(name_start, name_len);
        if alias_type >= 0 {
            return alias_type;
        }
    
        // Fall back to built-in and struct/enum types
        return resolve_named_type(self.type_pool, self.source, name_start, name_len);
    }

    fn resolveTypeHandle(self: *Lowerer, type_handle: i64) i64 {
        // Basic types: direct mapping (0-9)
        if type_handle >= 0 and type_handle < PTYPE_PTR_BASE {
            return type_handle;
        }
    
        // Pointer types: PTYPE_PTR_BASE (10) + pointee_handle
        if type_handle >= PTYPE_PTR_BASE and type_handle < PTYPE_USER_BASE {
            let pointee_handle: i64 = type_handle - PTYPE_PTR_BASE;
            let pointee_type: i64 = self.resolveTypeHandle(pointee_handle);
            return self.type_pool.makePointer( pointee_type);
        }
    
        // User-defined types: PTYPE_USER_BASE (100) + source_offset
        if type_handle >= PTYPE_USER_BASE {
            let name_start: i64 = type_handle - PTYPE_USER_BASE;
            // Scan to find the end of the type name
            var name_len: i64 = 0;
            var pos: i64 = name_start;
            while true {
                let c: u8 = (self.source + pos).*;
                // Identifier char: a-z, A-Z, 0-9, _
                if (c >= 97 and c <= 122) or (c >= 65 and c <= 90) or
                   (c >= 48 and c <= 57) or c == 95 {
                    name_len = name_len + 1;
                    pos = pos + 1;
                } else {
                    break;
                }
            }
    
            // First check type aliases
            let alias_type: i64 = self.lookupTypeAlias(name_start, name_len);
            if alias_type >= 0 {
                return alias_type;
            }
    
            // Fall back to TypeRegistry lookup for structs/enums
            return self.type_pool.lookupByName( self.source, name_start, name_len);
        }
    
        return TYPE_INVALID;
    }

    fn init(self: *Lowerer,
                    nodes: *Node, nodes_count: i64,
                    children: *i64, children_count: i64,
                    source: *u8, source_len: i64,
                    type_pool: *TypeRegistry,
                    ir_nodes: *IRNode, ir_nodes_cap: i64,
                    ir_locals: *IRLocal, ir_locals_cap: i64,
                    ir_funcs: *IRFunc, ir_funcs_cap: i64,
                    constants: *ConstEntry, constants_cap: i64) {
        self.nodes = nodes;
        self.nodes_count = nodes_count;
        self.children = children;
        self.children_count = children_count;
        self.source = source;
        self.source_len = source_len;
        self.type_pool = type_pool;
        self.current_func = null;
        self.ir_nodes = ir_nodes;
        self.ir_nodes_cap = ir_nodes_cap;
        self.ir_nodes_count = 0;
        self.ir_locals = ir_locals;
        self.ir_locals_cap = ir_locals_cap;
        self.ir_locals_count = 0;
        self.ir_funcs = ir_funcs;
        self.ir_funcs_cap = ir_funcs_cap;
        self.ir_funcs_count = 0;
        self.ir_globals = null;
        self.ir_globals_cap = 0;
        self.ir_globals_count = 0;
        self.constants = constants;
        self.constants_count = 0;
        self.constants_cap = constants_cap;
        self.loop_continue_block = 0 - 1;  // -1 means not in a loop
        self.loop_break_block = 0 - 1;
        self.loop_defer_depth = 0;
    
        // Lowerer owns its internal storage (matches bootstrap Zig pattern)
        // Allocate defer stack
        self.defer_stack_cap = LW_INIT_DEFER_STACK;
        self.defer_stack = malloc_i64(self.defer_stack_cap);
        self.defer_stack_count = 0;
    
        // Allocate type aliases
        self.type_aliases_cap = LW_INIT_TYPE_ALIASES;
        self.type_aliases = malloc_TypeAliasEntry(self.type_aliases_cap);
        self.type_aliases_count = 0;
    
        // Allocate label stack (5 parallel arrays for labeled break/continue)
        self.label_cap = LW_INIT_LABEL_STACK;
        self.label_names_start = malloc_i64(self.label_cap);
        self.label_names_len = malloc_i64(self.label_cap);
        self.label_break_blocks = malloc_i64(self.label_cap);
        self.label_continue_blocks = malloc_i64(self.label_cap);
        self.label_defer_depths = malloc_i64(self.label_cap);
        self.label_count = 0;
    
        // Initialize function map for O(1) lookup
        self.func_map = StrMap_init(256);
        // Initialize function return type map for O(1) lookup
        self.func_ret_map = StrMap_init(256);
    
        // cot1: Initialize synthesized names buffer for impl block methods
        self.synth_names_cap = 4096;  // Should be enough for most impl blocks
        self.synth_names = malloc_u8(self.synth_names_cap);
        self.synth_names_count = 0;
    
        // cot1: Initialize impl method flags array
        // Will be sized to nodes_count when Lowerer_markImplMethods is called
        self.impl_method_flags = null;
        self.impl_method_flags_count = 0;
    
        // cot1: Initialize method registry
        self.method_registry_cap = 256;
        self.method_registry = malloc_MethodEntry(self.method_registry_cap);
        self.method_registry_count = 0;

        // Initialize test mode (disabled by default)
        self.test_mode = 0;  // 0 = false

        // Initialize test names storage
        self.test_names_cap = 64;
        self.test_name_starts = malloc_i64(self.test_names_cap);
        self.test_name_lens = malloc_i64(self.test_names_cap);
        self.test_names_count = 0;
    }

    // Set test mode (must be called before lowering)
    fn setTestMode(self: *Lowerer, enabled: i64) {
        self.test_mode = enabled;
    }

    fn registerTypeAlias(self: *Lowerer, name_start: i64, name_len: i64, target_type: i64) {
        if self.type_aliases == null { return; }
        if self.type_aliases_count >= self.type_aliases_cap { return; }
    
        let entry: *TypeAliasEntry = self.type_aliases + self.type_aliases_count;
        entry.name_start = name_start;
        entry.name_len = name_len;
        entry.target_type = target_type;
        self.type_aliases_count = self.type_aliases_count + 1;
    }

    fn lookupTypeAlias(self: *Lowerer, name_start: i64, name_len: i64) i64 {
        if self.type_aliases == null { return -1; }
    
        var i: i64 = 0;
        while i < self.type_aliases_count {
            let entry: *TypeAliasEntry = self.type_aliases + i;
            if entry.name_len == name_len {
                // Compare names
                var match: bool = true;
                var j: i64 = 0;
                while j < name_len {
                    let c1: u8 = (self.source + entry.name_start + j).*;
                    let c2: u8 = (self.source + name_start + j).*;
                    if c1 != c2 {
                        match = false;
                        break;
                    }
                    j = j + 1;
                }
                if match {
                    return entry.target_type;
                }
            }
            i = i + 1;
        }
        return -1;  // Not found
    }

    fn synthMethodName(self: *Lowerer, type_name_start: i64, type_name_len: i64,
                                method_name_start: i64, method_name_len: i64,
                                out_len: *i64) i64 {
        // Calculate total length: TypeName + _ + methodName
        let total_len: i64 = type_name_len + 1 + method_name_len;
    
        // Ensure capacity
        if self.synth_names_count + total_len > self.synth_names_cap {
            // Grow buffer
            let new_cap: i64 = self.synth_names_cap * 2;
            self.synth_names = realloc_u8(self.synth_names, self.synth_names_cap, new_cap);
            self.synth_names_cap = new_cap;
        }
    
        // Get pointer to where we'll write the synthesized name
        let result_ptr: *u8 = self.synth_names + self.synth_names_count;
        let result_addr: i64 = @ptrToInt(result_ptr);
    
        // Copy TypeName
        var i: i64 = 0;
        while i < type_name_len {
            (result_ptr + i).* = (self.source + type_name_start + i).*;
            i = i + 1;
        }
    
        // Add underscore
        (result_ptr + type_name_len).* = 95;  // '_'
    
        // Copy methodName
        i = 0;
        while i < method_name_len {
            (result_ptr + type_name_len + 1 + i).* = (self.source + method_name_start + i).*;
            i = i + 1;
        }
    
        self.synth_names_count = self.synth_names_count + total_len;
        out_len.* = total_len;
    
        return result_addr;
    }

    fn registerMethod(self: *Lowerer, type_name_start: i64, type_name_len: i64,
                               method_name_start: i64, method_name_len: i64,
                               synth_name_ptr: i64, synth_name_len: i64) {
        if self.method_registry == null { return; }
        if self.method_registry_count >= self.method_registry_cap { return; }
    
        let entry: *MethodEntry = self.method_registry + self.method_registry_count;
        entry.type_name_start = type_name_start;
        entry.type_name_len = type_name_len;
        entry.method_name_start = method_name_start;
        entry.method_name_len = method_name_len;
        entry.synth_name_ptr = synth_name_ptr;
        entry.synth_name_len = synth_name_len;
        self.method_registry_count = self.method_registry_count + 1;
    }

    fn lookupMethod(self: *Lowerer, type_name_start: i64, type_name_len: i64,
                             method_name_start: i64, method_name_len: i64) *MethodEntry {
        if self.method_registry == null { return null; }
    
        var i: i64 = 0;
        while i < self.method_registry_count {
            let entry: *MethodEntry = self.method_registry + i;
    
            // Match type name
            if entry.type_name_len == type_name_len {
                var type_match: bool = true;
                var tj: i64 = 0;
                while tj < type_name_len {
                    let c1: u8 = (self.source + entry.type_name_start + tj).*;
                    let c2: u8 = (self.source + type_name_start + tj).*;
                    if c1 != c2 {
                        type_match = false;
                        break;
                    }
                    tj = tj + 1;
                }
    
                if type_match {
                    // Match method name
                    if entry.method_name_len == method_name_len {
                        var method_match: bool = true;
                        var mj: i64 = 0;
                        while mj < method_name_len {
                            let c3: u8 = (self.source + entry.method_name_start + mj).*;
                            let c4: u8 = (self.source + method_name_start + mj).*;
                            if c3 != c4 {
                                method_match = false;
                                break;
                            }
                            mj = mj + 1;
                        }
    
                        if method_match {
                            return entry;
                        }
                    }
                }
            }
            i = i + 1;
        }
        return null;
    }

    fn markImplMethods(self: *Lowerer) {
        // Allocate flags array sized to nodes_count
        self.impl_method_flags_count = self.nodes_count;
        self.impl_method_flags = malloc_u8(self.impl_method_flags_count);
    
        // Initialize all to 0 (not an impl method)
        var j: i64 = 0;
        while j < self.impl_method_flags_count {
            (self.impl_method_flags + j).* = 0;
            j = j + 1;
        }
    
        // Scan for ImplBlock nodes and mark their method children
        var i: i64 = 0;
        while i < self.nodes_count {
            let node: *Node = self.nodes + i;
            if node.kind == NodeKind.ImplBlock {
                let methods_start: i64 = node.field2;
                let methods_count: i64 = node.field3;
    
                var method_idx: i64 = 0;
                while method_idx < methods_count {
                    let method_node_idx_ptr: *i64 = self.children + methods_start + method_idx;
                    let method_node_idx: i64 = method_node_idx_ptr.*;
    
                    // Mark this node as an impl method
                    if method_node_idx >= 0 and method_node_idx < self.impl_method_flags_count {
                        (self.impl_method_flags + method_node_idx).* = 1;
                    }
    
                    method_idx = method_idx + 1;
                }
            }
            i = i + 1;
        }
    }

    fn isImplMethod(self: *Lowerer, node_idx: i64) bool {
        if self.impl_method_flags == null { return false; }
        if node_idx < 0 or node_idx >= self.impl_method_flags_count { return false; }
        return (self.impl_method_flags + node_idx).* == 1;
    }

    fn pushLabel(self: *Lowerer, name_start: i64, name_len: i64,
                         break_block: i64, continue_block: i64, defer_depth: i64) {
        if self.label_names_start == null { return; }
        if self.label_count >= self.label_cap { return; }
    
        let idx: i64 = self.label_count;
        let ns: *i64 = self.label_names_start + idx;
        let nl: *i64 = self.label_names_len + idx;
        let bb: *i64 = self.label_break_blocks + idx;
        let cb: *i64 = self.label_continue_blocks + idx;
        let dd: *i64 = self.label_defer_depths + idx;
    
        ns.* = name_start;
        nl.* = name_len;
        bb.* = break_block;
        cb.* = continue_block;
        dd.* = defer_depth;
        self.label_count = self.label_count + 1;
    }

    fn popLabel(self: *Lowerer) {
        if self.label_count > 0 {
            self.label_count = self.label_count - 1;
        }
    }

    fn findLabel(self: *Lowerer, name_start: i64, name_len: i64) i64 {
        if self.label_names_start == null { return -1; }
        if name_len == 0 { return -1; }
    
        var i: i64 = 0;
        while i < self.label_count {
            let stored_start: *i64 = self.label_names_start + i;
            let stored_len: *i64 = self.label_names_len + i;
            if stored_len.* == name_len {
                // Compare names
                var match: bool = true;
                var j: i64 = 0;
                while j < name_len {
                    let c1: u8 = (self.source + stored_start.* + j).*;
                    let c2: u8 = (self.source + name_start + j).*;
                    if c1 != c2 {
                        match = false;
                        break;
                    }
                    j = j + 1;
                }
                if match {
                    return i;
                }
            }
            i = i + 1;
        }
        return -1;
    }

    fn getLabelBreakBlock(self: *Lowerer, idx: i64) i64 {
        if idx < 0 or idx >= self.label_count { return -1; }
        let bb: *i64 = self.label_break_blocks + idx;
        return bb.*;
    }

    fn getLabelContinueBlock(self: *Lowerer, idx: i64) i64 {
        if idx < 0 or idx >= self.label_count { return -1; }
        let cb: *i64 = self.label_continue_blocks + idx;
        return cb.*;
    }

    fn getLabelDeferDepth(self: *Lowerer, idx: i64) i64 {
        if idx < 0 or idx >= self.label_count { return 0; }
        let dd: *i64 = self.label_defer_depths + idx;
        return dd.*;
    }

    fn ensureLocalsCapacity(self: *Lowerer, additional: i64) {
        let needed: i64 = self.ir_locals_count + additional;
        if needed <= self.ir_locals_cap {
            return;  // Already have enough
        }
        // Grow by 2x or to needed, whichever is larger
        var new_cap: i64 = self.ir_locals_cap * 2;
        if new_cap < needed {
            new_cap = needed;
        }
        // Realloc
        self.ir_locals = realloc_IRLocal(self.ir_locals, self.ir_locals_cap, new_cap);
        self.ir_locals_cap = new_cap;
    }

    fn ensureNodesCapacity(self: *Lowerer, additional: i64) {
        let needed: i64 = self.ir_nodes_count + additional;
        if needed <= self.ir_nodes_cap {
            return;
        }
        var new_cap: i64 = self.ir_nodes_cap * 2;
        if new_cap < needed {
            new_cap = needed;
        }
        self.ir_nodes = realloc_IRNode(self.ir_nodes, self.ir_nodes_cap, new_cap);
        self.ir_nodes_cap = new_cap;
    }

    fn ensureFuncsCapacity(self: *Lowerer, additional: i64) {
        let needed: i64 = self.ir_funcs_count + additional;
        if needed <= self.ir_funcs_cap {
            return;
        }
        var new_cap: i64 = self.ir_funcs_cap * 2;
        if new_cap < needed {
            new_cap = needed;
        }
        self.ir_funcs = realloc_IRFunc(self.ir_funcs, self.ir_funcs_cap, new_cap);
        self.ir_funcs_cap = new_cap;
    }

    fn ensureGlobalsCapacity(self: *Lowerer, additional: i64) {
        let needed: i64 = self.ir_globals_count + additional;
        if needed <= self.ir_globals_cap {
            return;
        }
        var new_cap: i64 = self.ir_globals_cap * 2;
        if new_cap < needed {
            new_cap = needed;
        }
        self.ir_globals = realloc_IRGlobal(self.ir_globals, self.ir_globals_cap, new_cap);
        self.ir_globals_cap = new_cap;
    }

    fn ensureConstantsCapacity(self: *Lowerer, additional: i64) {
        let needed: i64 = self.constants_count + additional;
        if needed <= self.constants_cap {
            return;
        }
        var new_cap: i64 = self.constants_cap * 2;
        if new_cap < needed {
            new_cap = needed;
        }
        self.constants = realloc_ConstEntry(self.constants, self.constants_cap, new_cap);
        self.constants_cap = new_cap;
    }

    fn ensureSynthNameCapacity(self: *Lowerer, additional: i64) {
        let needed: i64 = self.synth_names_count + additional;
        if needed <= self.synth_names_cap {
            return;
        }
        var new_cap: i64 = self.synth_names_cap * 2;
        if new_cap < needed {
            new_cap = needed;
        }
        // Allocate new buffer and copy
        let new_buf: *u8 = malloc_u8(new_cap);
        var i: i64 = 0;
        while i < self.synth_names_count {
            (new_buf + i).* = (self.synth_names + i).*;
            i = i + 1;
        }
        self.synth_names = new_buf;
        self.synth_names_cap = new_cap;
    }

    fn getDeferDepth(self: *Lowerer) i64 {
        return self.defer_stack_count;
    }

    fn pushDefer(self: *Lowerer, expr_idx: i64) {
        if self.defer_stack == null or self.defer_stack_count >= self.defer_stack_cap {
            return;
        }
        let slot: *i64 = self.defer_stack + self.defer_stack_count;
        slot.* = expr_idx;
        self.defer_stack_count = self.defer_stack_count + 1;
    }

    fn emitDeferredExprs(self: *Lowerer, target_depth: i64) {
        while self.defer_stack_count > target_depth {
            // Pop from stack
            self.defer_stack_count = self.defer_stack_count - 1;
            let slot: *i64 = self.defer_stack + self.defer_stack_count;
            let defer_expr_idx: i64 = slot.*;
    
            // Lower the deferred expression
            if defer_expr_idx >= 0 {
                let expr: *Node = self.nodes + defer_expr_idx;
                self.lowerExpr(expr);
            }
        }
    }

    fn clearDeferStack(self: *Lowerer) {
        self.defer_stack_count = 0;
    }

    fn setGlobals(self: *Lowerer, globals: *IRGlobal, globals_cap: i64) {
        self.ir_globals = globals;
        self.ir_globals_cap = globals_cap;
        self.ir_globals_count = 0;
        self.globals_data_offset = 0;  // Start at offset 0 in data section
    }

    fn registerGlobal(self: *Lowerer, name_start: i64, name_len: i64, type_idx: i64, is_mutable: bool) i64 {
        if self.ir_globals == null {
            return -1;  // Not initialized
        }
        self.ensureGlobalsCapacity(1);
        let idx: i64 = self.ir_globals_count;
        let g: *IRGlobal = self.ir_globals + idx;
        g.name_start = name_start;
        g.name_len = name_len;
        g.type_idx = type_idx;
        g.is_mutable = is_mutable;
        g.is_array = false;
        g.array_len = 0;
        g.size = 8;  // 64-bit value
        g.data_offset = self.globals_data_offset;
        g.init_value = 0;
        g.has_init = false;
        self.globals_data_offset = self.globals_data_offset + 8;  // Advance by size
        self.ir_globals_count = self.ir_globals_count + 1;
        return idx;
    }

    fn setGlobalInit(self: *Lowerer, global_idx: i64, value: i64) {
        if self.ir_globals == null or global_idx < 0 or global_idx >= self.ir_globals_count {
            return;
        }
        let g: *IRGlobal = self.ir_globals + global_idx;
        g.init_value = value;
        g.has_init = true;
    }

    fn registerArrayGlobal(self: *Lowerer, name_start: i64, name_len: i64, type_idx: i64, is_mutable: bool, array_len: i64) i64 {
        if self.ir_globals == null {
            return -1;  // Not initialized
        }
        self.ensureGlobalsCapacity(1);
        // Align to 8 bytes for arrays
        let aligned_offset: i64 = (self.globals_data_offset + 7) & (0 - 8);  // Round up to 8
        let idx: i64 = self.ir_globals_count;
        let g: *IRGlobal = self.ir_globals + idx;
        g.name_start = name_start;
        g.name_len = name_len;
        g.type_idx = type_idx;
        g.is_mutable = is_mutable;
        g.is_array = true;
        g.array_len = array_len;
        g.size = array_len;  // For u8 arrays, size = length
        g.data_offset = aligned_offset;
        g.init_value = 0;
        g.has_init = false;
        self.globals_data_offset = aligned_offset + array_len;  // Advance by size
        self.ir_globals_count = self.ir_globals_count + 1;
        return idx;
    }

    fn lookupGlobal(self: *Lowerer, name_start: i64, name_len: i64) i64 {
        if self.ir_globals == null { return -1; }
        var i: i64 = 0;
        while i < self.ir_globals_count {
            let g: *IRGlobal = self.ir_globals + i;
            if names_equal(self.source, g.name_start, g.name_len, name_start, name_len) {
                return i;
            }
            i = i + 1;
        }
        return -1;  // Not found
    }

    fn lookupFunc(self: *Lowerer, name_start: i64, name_len: i64) i64 {
        return self.func_map.get( self.source + name_start, name_len);
    }

    fn lookupEnumVariant(self: *Lowerer, enum_name_start: i64, enum_name_len: i64,
                                  variant_name_start: i64, variant_name_len: i64) i64 {
        // Search all AST nodes for EnumDecl nodes
        var i: i64 = 0;
        while i < self.nodes_count {
            let node: *Node = self.nodes + i;
            if node.kind == NodeKind.EnumDecl {
                // EnumDecl fields: field0=name_start, field1=name_len,
                //                  field2=variants_start, field3=variants_count
                let name_start: i64 = node.field0;
                let name_len: i64 = node.field1;
    
                // Check if this enum matches the requested name
                if names_equal(self.source, name_start, name_len, enum_name_start, enum_name_len) {
                    // Found the enum, now look for the variant
                    let variants_start: i64 = node.field2;
                    let variants_count: i64 = node.field3;
    
                    var v: i64 = 0;
                    while v < variants_count {
                        // Get variant node index from children array
                        let child_ptr: *i64 = self.children + variants_start + v;
                        let variant_idx: i64 = child_ptr.*;
    
                        // Variant is stored as an Ident node
                        let variant_node: *Node = self.nodes + variant_idx;
                        if variant_node.kind == NodeKind.Ident {
                            let var_name_start: i64 = variant_node.field0;
                            let var_name_len: i64 = variant_node.field1;
    
                            if names_equal(self.source, var_name_start, var_name_len,
                                           variant_name_start, variant_name_len) {
                                // Found the variant, return its index (value)
                                return v;
                            }
                        }
                        v = v + 1;
                    }
                    // Enum found but variant not found
                    return -1;
                }
            }
            i = i + 1;
        }
        return -1;  // Enum not found
    }

    fn getGlobal(self: *Lowerer, idx: i64) *IRGlobal {
        return self.ir_globals + idx;
    }

    fn lookupConst(self: *Lowerer, name_start: i64, name_len: i64) i64 {
        var i: i64 = 0;
        while i < self.constants_count {
            let c: *ConstEntry = self.constants + i;
            if names_equal(self.source, c.name_start, c.name_len, name_start, name_len) {
                return c.value;
            }
            i = i + 1;
        }
        return -1;  // Not found (note: this limits const values to non-negative!)
    }

    fn hasConst(self: *Lowerer, name_start: i64, name_len: i64) bool {
        var i: i64 = 0;
        while i < self.constants_count {
            let c: *ConstEntry = self.constants + i;
            if names_equal(self.source, c.name_start, c.name_len, name_start, name_len) {
                return true;
            }
            i = i + 1;
        }
        // Debug: show failed lookups for TYPE_I64 specifically
        return false;
    }

    fn addConst(self: *Lowerer, name_start: i64, name_len: i64, value: i64) {
        self.ensureConstantsCapacity(1);
        let c: *ConstEntry = self.constants + self.constants_count;
        c.name_start = name_start;
        c.name_len = name_len;
        c.value = value;
        self.constants_count = self.constants_count + 1;
    }

    fn findFuncRetType(self: *Lowerer, name_start: i64, name_len: i64) i64 {
        return self.func_ret_map.get( self.source + name_start, name_len);
    }

    fn exprReturnsSlice(self: *Lowerer, node: *Node) bool {
        if node.kind == NodeKind.CallExpr {
            // Get callee (must be Ident for now)
            let callee_node: *Node = self.nodes + node.field0;
            if callee_node.kind == NodeKind.Ident {
                let ret_type: i64 = self.findFuncRetType(callee_node.field0, callee_node.field1);
                // Check if slice type: PTYPE_SLICE_BASE = 100000
                if ret_type >= PTYPE_SLICE_BASE {
                    return true;
                }
            }
        }
        return false;
    }

    fn lowerConstDecl(self: *Lowerer, node: *Node) {
        // ConstDecl fields:
        // field0 = name_start
        // field1 = name_len
        // field2 = type_handle (-1 if inferred)
        // field3 = init_expr node index
    
        let name_start: i64 = node.field0;
        let name_len: i64 = node.field1;
        let init_expr_idx: i64 = node.field3;
    
        // Evaluate the initializer (must be a constant expression)
        if init_expr_idx >= 0 {
            let init_node: *Node = self.nodes + init_expr_idx;
            if init_node.kind == NodeKind.IntLit {
                // Simple integer literal
                self.addConst(name_start, name_len, init_node.field0);
            } else if init_node.kind == NodeKind.UnaryExpr {
                // UnaryExpr: check for negation of integer literal (e.g., -1)
                // UnaryExpr fields: field0 = operand, field1 = operator
                let operand_idx: i64 = init_node.field0;
                let op: i64 = init_node.field1;
                if operand_idx >= 0 and op == 0 {  // 0 = UnaryOp.Neg (negate)
                    let operand: *Node = self.nodes + operand_idx;
                    if operand.kind == NodeKind.IntLit {
                        let neg_value: i64 = 0 - operand.field0;  // negate the value
                        self.addConst(name_start, name_len, neg_value);
                    }
                }
            }
            // TODO: Support more complex constant expressions
        }
    }

    fn registerGlobalVar(self: *Lowerer, node: *Node) {
        // VarDecl fields (from ast.cot Node_varDecl):
        // field0 = is_let (1 = let, 0 = var)
        // field1 = name_start
        // field2 = name_len
        // field3 = init_expr node index (-1 if none)
        // field4 = type_start (legacy)
        // field5 = type_expr (TypeExpr AST node index)
    
        let is_mutable: bool = node.field0 == 0;  // 0 = var (mutable), 1 = let (immutable)
        let name_start: i64 = node.field1;
        let name_len: i64 = node.field2;
        let init_expr_idx: i64 = node.field3;
        let type_expr_idx: i64 = node.field5;
    
        // Resolve TypeExpr AST node to TypeRegistry index
        var type_idx: i64 = resolve_type_expr(self, type_expr_idx);
        if type_idx < 0 {
            type_idx = TYPE_I64;  // Fallback
        }
    
        // Check if this is an array type
        var global_idx: i64 = 0 - 1;
        let type_info: *Type = self.type_pool.get( type_idx);
        if type_info.kind == TypeKind.Array {
            global_idx = self.registerArrayGlobal(name_start, name_len, type_idx, is_mutable, type_info.len);
        } else {
            global_idx = self.registerGlobal(name_start, name_len, type_idx, is_mutable);
        }
    
        // Check for compile-time constant initializer
        if init_expr_idx >= 0 and global_idx >= 0 {
            let init_node: *Node = self.nodes + init_expr_idx;
            // If it's an integer literal, use it as the init value
            if init_node.kind == NodeKind.IntLit {
                // IntLit: field0 = parsed integer value (set by parser)
                let init_val: i64 = init_node.field0;
                self.setGlobalInit(global_idx, init_val);
            }
        }
    }

    fn registerStructType(self: *Lowerer, node: *Node, node_idx: i64) {
        if node.kind != NodeKind.StructDecl { return; }
    
        let name_start: i64 = node.field0;
        let name_len: i64 = node.field1;
        let ast_fields_start: i64 = node.field2;
        let fields_count: i64 = node.field3;
    
        // Bounds check
        if ast_fields_start < 0 or ast_fields_start + fields_count > self.children_count {
            return;
        }
    
        // Record start of fields in TypeRegistry's fields array
        let type_fields_start: i64 = self.type_pool.fields_count;
    
        // Process each field and compute offsets with proper alignment
        var offset: i64 = 0;
        var max_align: i64 = 1;
        var i: i64 = 0;
        while i < fields_count {
            let child_ptr: *i64 = self.children + ast_fields_start + i;
            let field_node_idx: i64 = child_ptr.*;
    
            // Bounds check field_node_idx
            if field_node_idx < 0 or field_node_idx >= self.nodes_count {
                i = i + 1;
                continue;
            }
    
            let field_node: *Node = self.nodes + field_node_idx;
    
            let fname_start: i64 = field_node.field0;
            let fname_len: i64 = field_node.field1;
            let type_expr_idx: i64 = field_node.field3;
    
            // Bounds check type_expr_idx
            if type_expr_idx < 0 or type_expr_idx >= self.nodes_count {
                i = i + 1;
                continue;
            }
    
            // Resolve field type using TypeExpr AST node
            var field_type: i64 = resolve_type_expr(self, type_expr_idx);
            if field_type < 0 {
                field_type = TYPE_I64;
            }
    
            // Bounds check resolved type before TypeRegistry_get
            if field_type < 0 or field_type >= self.type_pool.count {
                i = i + 1;
                continue;
            }
    
            // Get size and alignment from resolved type
            let field_type_info: *Type = self.type_pool.get( field_type);
            let field_size: i64 = field_type_info.size;
            let field_align: i64 = field_type_info.align;
    
            // Align offset to field alignment
            if field_align > 0 {
                offset = (offset + field_align - 1) / field_align * field_align;
            }
    
            // Track max alignment for struct alignment
            if field_align > max_align {
                max_align = field_align;
            }
    
            // Add field to TypeRegistry with computed offset
            self.type_pool.addField( fname_start, fname_len, field_type, offset);
    
            // Advance offset by field size
            offset = offset + field_size;
    
            i = i + 1;
        }
    
        // Align final size to struct alignment
        let struct_size: i64 = (offset + max_align - 1) / max_align * max_align;
    
        // Create struct type in TypeRegistry
        let struct_type: i64 = self.type_pool.makeStruct( name_start, name_len,
                                                 type_fields_start, fields_count,
                                                 struct_size, max_align);
    }

    fn lowerAll(self: *Lowerer) i64 {
        var t0: i64 = get_time_ns();
        var t1: i64 = 0;
    
        // Pass 0: Register struct types in TypeRegistry
        // This must happen before any type references are resolved
        var i: i64 = 0;
        while i < self.nodes_count {
            let node: *Node = self.nodes + i;
            if node.kind == NodeKind.StructDecl {
                self.registerStructType(node, i);
            }
            i = i + 1;
        }
        t1 = get_time_ns();
        print("    pass0 structs: "); print((t1 - t0) / 1000000); print("ms\n");
        t0 = t1;
    
        // cot1 Pass 0.5: Register type aliases
        // TypeAliasDecl: field0=name_start, field1=name_len, field2=type_node_idx (AST node, NOT PTYPE_*)
        i = 0;
        while i < self.nodes_count {
            let node: *Node = self.nodes + i;
            if node.kind == NodeKind.TypeAliasDecl {
                let name_start: i64 = node.field0;
                let name_len: i64 = node.field1;
                let type_node_idx: i64 = node.field2;
                // Resolve the target type from AST node (not PTYPE_* handle!)
                let target_type: i64 = resolve_type_expr(self, type_node_idx);
                // Register the alias
                self.registerTypeAlias(name_start, name_len, target_type);
            }
            i = i + 1;
        }
        t1 = get_time_ns();
        print("    pass0.5 aliases: "); print((t1 - t0) / 1000000); print("ms\n");
        t0 = t1;
    
        // First pass: process const declarations
        i = 0;
        while i < self.nodes_count {
            let node: *Node = self.nodes + i;
            if node.kind == NodeKind.ConstDecl {
                self.lowerConstDecl(node);
            }
            i = i + 1;
        }
        t1 = get_time_ns();
        print("    pass1 consts: "); print((t1 - t0) / 1000000); print("ms\n");
        t0 = t1;
    
        // Pass 1.5: Register global variable declarations (top-level var)
        i = 0;
        while i < self.nodes_count {
            let node: *Node = self.nodes + i;
            if node.kind == NodeKind.GlobalVarDecl {
                self.registerGlobalVar(node);
            }
            i = i + 1;
        }
        t1 = get_time_ns();
        print("    pass1.5 globals: "); print((t1 - t0) / 1000000); print("ms\n");
        t0 = t1;
    
        // cot1 Pass 1.8: Mark impl block methods so they're skipped in regular FnDecl processing
        self.markImplMethods();
    
        // Pass 1.9: Pre-populate func_map and func_ret_map with all function names for O(1) lookup
        // This must happen before lowering function bodies
        // Also includes ExternFnDecl for return type lookups
        // cot1: Also handles impl block methods with synthesized names
        // cot1: Skip FnDecl nodes that are inside impl blocks (handled separately)
        var func_idx: i64 = 0;
        i = 0;
        while i < self.nodes_count {
            let node: *Node = self.nodes + i;
            if node.kind == NodeKind.FnDecl {
                // cot1: Skip if this is an impl method (will be handled with synthesized name)
                if not self.isImplMethod(i) {
                    self.func_map.put( self.source + node.field0, node.field1, func_idx);
                    // Store return type handle for O(1) lookup (field4 = ret_type_handle)
                    self.func_ret_map.put( self.source + node.field0, node.field1, node.field4);
                    func_idx = func_idx + 1;
                }
            } else if node.kind == NodeKind.ExternFnDecl {
                // ExternFnDecl also needs return type in map for call type inference
                self.func_ret_map.put( self.source + node.field0, node.field1, node.field4);
            } else if node.kind == NodeKind.ImplBlock {
                // cot1: Register impl block methods with synthesized names
                // ImplBlock: field0=type_name_start, field1=type_name_len, field2=methods_start, field3=methods_count
                let type_name_start: i64 = node.field0;
                let type_name_len: i64 = node.field1;
                let methods_start: i64 = node.field2;
                let methods_count: i64 = node.field3;
    
                var method_idx: i64 = 0;
                while method_idx < methods_count {
                    let method_node_idx_ptr: *i64 = self.children + methods_start + method_idx;
                    let method_node_idx: i64 = method_node_idx_ptr.*;
                    let method_node: *Node = self.nodes + method_node_idx;
    
                    // Synthesize "TypeName_methodName"
                    var synth_len: i64 = 0;
                    let synth_name_ptr: i64 = self.synthMethodName(type_name_start, type_name_len,
                        method_node.field0, method_node.field1,
                        &synth_len);
    
                    // Register with synthesized name
                    self.func_map.put( @intToPtr(*u8, synth_name_ptr), synth_len, func_idx);
                    self.func_ret_map.put( @intToPtr(*u8, synth_name_ptr), synth_len, method_node.field4);
                    func_idx = func_idx + 1;
    
                    method_idx = method_idx + 1;
                }
            }
            i = i + 1;
        }
        t1 = get_time_ns();
        print("    pass1.9 funcmap: "); print((t1 - t0) / 1000000); print("ms\n");
        t0 = t1;
    
        // Second pass: process function declarations
        // Note: ExternFnDecl nodes are skipped - they don't need IR,
        // the linker will resolve external symbols
        // cot1: Also handles impl block methods
        // cot1: Skip FnDecl nodes that are inside impl blocks (handled by ImplBlock processing)
        i = 0;
        while i < self.nodes_count {
            let node: *Node = self.nodes + i;
            if node.kind == NodeKind.FnDecl {
                // cot1: Skip if this is an impl method
                if not self.isImplMethod(i) {
                    self.lowerFnDecl(node);
                }
            } else if node.kind == NodeKind.ImplBlock {
                // cot1: Lower impl block methods with synthesized names
                self.lowerImplBlock(node);
            }
            // ExternFnDecl - skip, no IR needed (linker resolves external symbols)
            i = i + 1;
        }
        t1 = get_time_ns();
        print("    pass2 functions: "); print((t1 - t0) / 1000000); print("ms\n");
        t0 = t1;

        // Test mode pass: process test declarations
        if self.test_mode != 0 {
            i = 0;
            while i < self.nodes_count {
                let node: *Node = self.nodes + i;
                if node.kind == NodeKind.TestDecl {
                    self.lowerTestDecl(node);
                }
                i = i + 1;
            }
            t1 = get_time_ns();
            print("    test declarations: "); print((t1 - t0) / 1000000); print("ms\n");
            t0 = t1;

            // Generate test runner main()
            if self.test_names_count > 0 {
                self.generateTestRunner();
            }
            t1 = get_time_ns();
            print("    test runner gen: "); print((t1 - t0) / 1000000); print("ms\n");
        }

        return self.ir_nodes_count;
    }

    fn lowerFnDecl(self: *Lowerer, node: *Node) {
        // FnDecl fields:
        // field0 = name_start
        // field1 = name_len
        // field2 = params_start
        // field3 = params_count
        // field4 = ret_type
        // field5 = body (block node index)

        // Skip user's main() when in test mode (test runner generates its own main)
        if self.test_mode != 0 and node.field1 == 4 {
            // Check if function name is "main"
            let name_ptr: *u8 = self.source + node.field0;
            if name_ptr.* == 109 {           // 'm'
                if (name_ptr + 1).* == 97 {  // 'a'
                    if (name_ptr + 2).* == 105 { // 'i'
                        if (name_ptr + 3).* == 110 { // 'n'
                            return;  // Skip main() in test mode
                        }
                    }
                }
            }
        }

        // Ensure capacity for this function's locals and nodes
        // Estimate: params + 100 locals per function should be safe
        let estimated_locals: i64 = node.field3 + 100;
        self.ensureLocalsCapacity(estimated_locals);
        self.ensureNodesCapacity(500);  // Estimate 500 IR nodes per function
    
        // Debug: find when corruption first occurs
        // Record starting positions for this function
        let nodes_start: i64 = self.ir_nodes_count;
        let locals_start: i64 = self.ir_locals_count;
    
        // Get return type from FnDecl node (field4 contains type expression node index)
        // BUG-054: Resolve to actual type index for hidden return detection on large structs
        var return_type: i64 = resolve_type_expr(self, node.field4);
        if return_type < 0 {
            return_type = TYPE_VOID;
        }
    
        // Create function builder
        var fb: FuncBuilder = undefined;
        let remaining_locals: i64 = self.ir_locals_cap - self.ir_locals_count;
        let remaining_nodes: i64 = self.ir_nodes_cap - self.ir_nodes_count;
    
        // DEBUG: Check capacity (disabled - using dynamic growth now)
        // if remaining_locals <= 0 or remaining_nodes <= 0 {
        //     print("LOWER ERROR: Out of capacity!\n");
        // }
    
        fb.init(
                          node.field0, node.field1,  // name_start, name_len
                          return_type,               // actual return type from parsed node
                          self.ir_locals + self.ir_locals_count,
                          remaining_locals,
                          self.ir_nodes + self.ir_nodes_count,
                          remaining_nodes);
    
        self.current_func = &fb;
    
        // Add function parameters as locals (before lowering body so they're available)
        let params_start: i64 = node.field2;
        let params_count: i64 = node.field3;
        var param_idx: i64 = 0;
        while param_idx < params_count {
            // Get param node index from children array
            let child_ptr: *i64 = self.children + params_start + param_idx;
            let param_node_idx: i64 = child_ptr.*;
            let param_node: *Node = self.nodes + param_node_idx;
    
            // ParamDecl: field0=name_start, field1=name_len, field2=type_start, field3=type_expr
            var param_type: i64 = resolve_type_expr(self, param_node.field3);
            if param_type < 0 {
                param_type = TYPE_I64;  // Fallback
            }
            // Following Zig pattern: lower.zig:153-154 - compute param_size for addParam
            let param_size: i64 = self.type_pool.sizeof( param_type);
            let local_idx: i64 = fb.addParam(
                                   param_node.field0, param_node.field1,
                                   param_type, param_idx, param_size);
    
            // BUG-012 FIX: Set struct_type_start/len for pointer-to-struct parameters
            // Following Zig pattern (lower.zig:1554-1561) for auto-dereference through pointers
            // This allows p.*.field to find correct field offsets
            if local_idx >= 0 {
                let local: *IRLocal = fb.locals + local_idx;
                let type_info: *Type = self.type_pool.get( param_type);
                if type_info != null and type_info.kind == TypeKind.Pointer {
                    let pointee: *Type = self.type_pool.get( type_info.elem);
                    if pointee != null and pointee.kind == TypeKind.Struct {
                        // Use TypeRegistry struct name
                        local.struct_type_start = pointee.name_start;
                        local.struct_type_len = pointee.name_len;
                    } else {
                        // Fallback: Extract struct name from TypeExpr AST
                        // For *Lowerer: TypeExprPointer.field0 = TypeExprNamed.field0/field1 = name
                        let type_expr_idx: i64 = param_node.field3;
                        if type_expr_idx >= 0 and type_expr_idx < self.nodes_count {
                            let type_expr: *Node = self.nodes + type_expr_idx;
                            if type_expr.kind == NodeKind.TypeExprPointer {
                                let inner_idx: i64 = type_expr.field0;
                                if inner_idx >= 0 and inner_idx < self.nodes_count {
                                    let inner_expr: *Node = self.nodes + inner_idx;
                                    if inner_expr.kind == NodeKind.TypeExprNamed {
                                        // Found the struct name!
                                        let name_start: i64 = inner_expr.field0;
                                        let name_len: i64 = inner_expr.field1;
                                        if name_start >= 0 and name_len > 0 and name_len < 100 and
                                           name_start + name_len <= self.source_len {
                                            local.struct_type_start = name_start;
                                            local.struct_type_len = name_len;
                                        }
                                    }
                                }
                            }
                        }
                    }
                } else if type_info != null {
                    // Type is not a pointer - extract struct name directly from TypeExpr if it's a struct
                    let type_expr_idx: i64 = param_node.field3;
                    if type_expr_idx >= 0 {
                        let type_expr: *Node = self.nodes + type_expr_idx;
                        if type_expr.kind == NodeKind.TypeExprNamed {
                            // Direct struct parameter
                            local.struct_type_start = type_expr.field0;
                            local.struct_type_len = type_expr.field1;
                        }
                    }
                }
            }
    
            param_idx = param_idx + 1;
        }
    
        // Lower the function body (field5 is the body block node index)
        let body_idx: i64 = node.field5;
        var body_terminated: bool = false;
    
        if body_idx >= 0 {
            let body_node: *Node = self.nodes + body_idx;
            body_terminated = self.lowerBlockCheckTerminated(body_node);
        }
    
        // If function body doesn't end with a return, emit implicit void return
        if not body_terminated {
            fb.emitReturnVoid();
        }
    
        // Update counts from function builder
        self.ir_nodes_count = self.ir_nodes_count + fb.nodes_count;
        self.ir_locals_count = self.ir_locals_count + fb.locals_count;
    
        // Record function metadata - ensure capacity and register
        self.ensureFuncsCapacity(1);
        let func_ptr: *IRFunc = self.ir_funcs + self.ir_funcs_count;
    
        func_ptr.name_start = node.field0;
        func_ptr.name_len = node.field1;
        func_ptr.return_type = return_type;
        func_ptr.nodes_start = nodes_start;
        func_ptr.nodes_count = fb.nodes_count;
        func_ptr.locals_start = locals_start;
        func_ptr.locals_count = fb.locals_count;
        func_ptr.code_offset = 0;
    
        self.ir_funcs_count = self.ir_funcs_count + 1;

        self.current_func = null;
    }

    // Lower a test declaration as a void function with synthesized name.
    // test "basic addition" { ... } becomes fn test_basic_addition() void { ... }
    fn lowerTestDecl(self: *Lowerer, node: *Node) {
        // TestDecl fields:
        // field0 = name_start (offset after opening quote in source)
        // field1 = name_len (length of test name, excluding quotes)
        // field2 = body (block node index)

        let name_start: i64 = node.field0;
        let name_len: i64 = node.field1;
        let body_idx: i64 = node.field2;

        // Sanitize test name and create "test_" + sanitized_name
        let synth_len: i64 = 5 + name_len;  // "test_" prefix
        self.ensureSynthNameCapacity(synth_len);

        let synth_name_ptr: i64 = @ptrToInt(self.synth_names) + self.synth_names_count;
        let synth_start: i64 = self.synth_names_count;

        // Write "test_" prefix
        (self.synth_names + synth_start).* = 116;      // 't'
        (self.synth_names + synth_start + 1).* = 101;  // 'e'
        (self.synth_names + synth_start + 2).* = 115;  // 's'
        (self.synth_names + synth_start + 3).* = 116;  // 't'
        (self.synth_names + synth_start + 4).* = 95;   // '_'

        // Copy and sanitize name: spaces and non-alphanumeric become '_'
        var i: i64 = 0;
        while i < name_len {
            let c: u8 = (self.source + name_start + i).*;
            var out_char: u8 = 95;  // Default to '_'
            // Check if alphanumeric: a-z, A-Z, 0-9
            if (c >= 97 and c <= 122) or (c >= 65 and c <= 90) or (c >= 48 and c <= 57) {
                out_char = c;
            }
            (self.synth_names + synth_start + 5 + i).* = out_char;
            i = i + 1;
        }

        self.synth_names_count = self.synth_names_count + synth_len;

        // Store test name for test runner generation
        if self.test_names_count >= self.test_names_cap {
            // Grow capacity (simple doubling)
            let new_cap: i64 = self.test_names_cap * 2;
            let new_starts: *i64 = malloc_i64(new_cap);
            let new_lens: *i64 = malloc_i64(new_cap);
            // Copy existing
            var j: i64 = 0;
            while j < self.test_names_count {
                (new_starts + j).* = (self.test_name_starts + j).*;
                (new_lens + j).* = (self.test_name_lens + j).*;
                j = j + 1;
            }
            self.test_name_starts = new_starts;
            self.test_name_lens = new_lens;
            self.test_names_cap = new_cap;
        }
        // Store OFFSET (not pointer) - synth_names buffer may be reallocated later
        (self.test_name_starts + self.test_names_count).* = synth_start;
        (self.test_name_lens + self.test_names_count).* = synth_len;
        self.test_names_count = self.test_names_count + 1;

        // Ensure capacity for test function
        self.ensureLocalsCapacity(100);
        self.ensureNodesCapacity(500);

        let nodes_start: i64 = self.ir_nodes_count;
        let locals_start: i64 = self.ir_locals_count;

        // Create function builder for test (void return, no params)
        var fb: FuncBuilder = undefined;
        let remaining_locals: i64 = self.ir_locals_cap - self.ir_locals_count;
        let remaining_nodes: i64 = self.ir_nodes_cap - self.ir_nodes_count;

        fb.init(synth_name_ptr, synth_len,
                TYPE_VOID,  // Tests are void functions
                self.ir_locals + self.ir_locals_count,
                remaining_locals,
                self.ir_nodes + self.ir_nodes_count,
                remaining_nodes);

        self.current_func = &fb;

        // Lower test body
        var body_terminated: bool = false;
        if body_idx >= 0 {
            let body_node: *Node = self.nodes + body_idx;
            body_terminated = self.lowerBlockCheckTerminated(body_node);
        }

        // Emit implicit void return
        if not body_terminated {
            fb.emitReturnVoid();
        }

        // Update counts
        self.ir_nodes_count = self.ir_nodes_count + fb.nodes_count;
        self.ir_locals_count = self.ir_locals_count + fb.locals_count;

        // Record function metadata
        self.ensureFuncsCapacity(1);
        let func_ptr: *IRFunc = self.ir_funcs + self.ir_funcs_count;

        // Store NEGATIVE offset (-offset-1) as marker for synth_names
        // Will be converted to absolute pointer by fixupSynthNames() after all lowering
        func_ptr.name_start = -synth_start - 1;
        func_ptr.name_len = synth_len;
        func_ptr.return_type = TYPE_VOID;
        func_ptr.nodes_start = nodes_start;
        func_ptr.nodes_count = fb.nodes_count;
        func_ptr.locals_start = locals_start;
        func_ptr.locals_count = fb.locals_count;
        func_ptr.code_offset = 0;

        self.ir_funcs_count = self.ir_funcs_count + 1;
        self.current_func = null;
    }

    // Generate test runner main() function that calls each test
    fn generateTestRunner(self: *Lowerer) {
        // Ensure capacity
        self.ensureLocalsCapacity(16);
        self.ensureNodesCapacity(self.test_names_count * 10 + 20);

        let nodes_start: i64 = self.ir_nodes_count;
        let locals_start: i64 = self.ir_locals_count;

        // Create "main" function name
        self.ensureSynthNameCapacity(4);  // Call FIRST before taking pointer
        let main_name_offset: i64 = self.synth_names_count;  // Store offset for later fixup
        (self.synth_names + self.synth_names_count).* = 109;      // 'm'
        (self.synth_names + self.synth_names_count + 1).* = 97;   // 'a'
        (self.synth_names + self.synth_names_count + 2).* = 105;  // 'i'
        (self.synth_names + self.synth_names_count + 3).* = 110;  // 'n'
        self.synth_names_count = self.synth_names_count + 4;

        var fb: FuncBuilder = undefined;
        let remaining_locals: i64 = self.ir_locals_cap - self.ir_locals_count;
        let remaining_nodes: i64 = self.ir_nodes_cap - self.ir_nodes_count;

        // Calculate temp pointer for FuncBuilder (only used during lowering)
        let main_name_ptr: i64 = @ptrToInt(self.synth_names) + main_name_offset;
        fb.init(main_name_ptr, 4,
                TYPE_I64,  // main returns i64
                self.ir_locals + self.ir_locals_count,
                remaining_locals,
                self.ir_nodes + self.ir_nodes_count,
                remaining_nodes);

        self.current_func = &fb;

        // Call each test function in sequence
        var i: i64 = 0;
        while i < self.test_names_count {
            let test_name_offset: i64 = (self.test_name_starts + i).*;
            let test_name_len: i64 = (self.test_name_lens + i).*;
            // Convert offset to absolute pointer (synth_names buffer is stable now)
            let test_name_ptr: i64 = @ptrToInt(self.synth_names) + test_name_offset;

            // Emit call to test function (no args, void return)
            var call_args: I64List = undefined;
            i64list_init(&call_args);  // Empty args list
            var call_node: IRNode = IRNode_new(IRNodeKind.Call, TYPE_VOID);
            call_node.func_name_start = test_name_ptr;
            call_node.func_name_len = test_name_len;
            call_node.call_args = call_args;
            fb.emit(call_node);

            i = i + 1;
        }

        // Return 0 (all tests passed)
        let zero_idx: i64 = fb.emitConstInt(0);
        fb.emitReturn(zero_idx);

        // Update counts
        self.ir_nodes_count = self.ir_nodes_count + fb.nodes_count;
        self.ir_locals_count = self.ir_locals_count + fb.locals_count;

        // Record function metadata
        self.ensureFuncsCapacity(1);
        let func_ptr: *IRFunc = self.ir_funcs + self.ir_funcs_count;

        // Store NEGATIVE offset (-offset-1) as marker for synth_names
        // Will be converted to absolute pointer by fixupSynthNames() after all lowering
        func_ptr.name_start = -main_name_offset - 1;
        func_ptr.name_len = 4;
        func_ptr.return_type = TYPE_I64;
        func_ptr.nodes_start = nodes_start;
        func_ptr.nodes_count = fb.nodes_count;
        func_ptr.locals_start = locals_start;
        func_ptr.locals_count = fb.locals_count;
        func_ptr.code_offset = 0;

        self.ir_funcs_count = self.ir_funcs_count + 1;
        self.current_func = null;
    }

    // Fix up synthesized function names after all lowering is complete.
    // Negative name_start values are markers: -offset-1 means offset into synth_names buffer.
    // This must be called AFTER all lowering and BEFORE SSA building.
    fn fixupSynthNames(self: *Lowerer) {
        var i: i64 = 0;
        while i < self.ir_funcs_count {
            let func_ptr: *IRFunc = self.ir_funcs + i;
            if func_ptr.name_start < 0 {
                // Decode offset: stored as -offset-1, so offset = -name_start - 1
                let offset: i64 = -func_ptr.name_start - 1;
                // Convert to absolute pointer
                func_ptr.name_start = @ptrToInt(self.synth_names) + offset;
            }
            i = i + 1;
        }
    }

    fn lowerMethodWithName(self: *Lowerer, node: *Node, synth_name_ptr: i64, synth_name_len: i64) {
        // Ensure capacity for this function's locals and nodes
        let estimated_locals: i64 = node.field3 + 100;
        self.ensureLocalsCapacity(estimated_locals);
        self.ensureNodesCapacity(500);
    
        // Record starting positions for this function
        let nodes_start: i64 = self.ir_nodes_count;
        let locals_start: i64 = self.ir_locals_count;
    
        // Get return type from FnDecl node
        var return_type: i64 = resolve_type_expr(self, node.field4);
        if return_type < 0 {
            return_type = TYPE_VOID;
        }
    
        // Create function builder with synthesized name
        var fb: FuncBuilder = undefined;
        let remaining_locals: i64 = self.ir_locals_cap - self.ir_locals_count;
        let remaining_nodes: i64 = self.ir_nodes_cap - self.ir_nodes_count;
    
        fb.init(
                          synth_name_ptr, synth_name_len,  // synthesized name
                          return_type,
                          self.ir_locals + self.ir_locals_count,
                          remaining_locals,
                          self.ir_nodes + self.ir_nodes_count,
                          remaining_nodes);
    
        self.current_func = &fb;
    
        // Add function parameters as locals
        let params_start: i64 = node.field2;
        let params_count: i64 = node.field3;
        var param_idx: i64 = 0;
        while param_idx < params_count {
            let child_ptr: *i64 = self.children + params_start + param_idx;
            let param_node_idx: i64 = child_ptr.*;
            let param_node: *Node = self.nodes + param_node_idx;
    
            var param_type: i64 = resolve_type_expr(self, param_node.field3);
            if param_type < 0 {
                param_type = TYPE_I64;
            }
            let param_size: i64 = self.type_pool.sizeof( param_type);
            let local_idx: i64 = fb.addParam(
                                   param_node.field0, param_node.field1,
                                   param_type, param_idx, param_size);
    
            // Set struct_type_start/len for pointer-to-struct parameters
            if local_idx >= 0 {
                let local: *IRLocal = fb.locals + local_idx;
                let type_info: *Type = self.type_pool.get( param_type);
                if type_info != null and type_info.kind == TypeKind.Pointer {
                    let pointee: *Type = self.type_pool.get( type_info.elem);
                    if pointee != null and pointee.kind == TypeKind.Struct {
                        local.struct_type_start = pointee.name_start;
                        local.struct_type_len = pointee.name_len;
                    }
                }
            }
    
            param_idx = param_idx + 1;
        }
    
        // Lower the function body
        let body_idx: i64 = node.field5;
        var body_terminated: bool = false;
    
        if body_idx >= 0 {
            let body_node: *Node = self.nodes + body_idx;
            body_terminated = self.lowerBlockCheckTerminated(body_node);
        }
    
        // If function body doesn't end with a return, emit implicit void return
        if not body_terminated {
            fb.emitReturnVoid();
        }
    
        // Update counts from function builder
        self.ir_nodes_count = self.ir_nodes_count + fb.nodes_count;
        self.ir_locals_count = self.ir_locals_count + fb.locals_count;
    
        // Record function metadata with synthesized name
        self.ensureFuncsCapacity(1);
        let func_ptr: *IRFunc = self.ir_funcs + self.ir_funcs_count;
    
        func_ptr.name_start = synth_name_ptr;  // Pointer to synthesized name
        func_ptr.name_len = synth_name_len;
        func_ptr.return_type = return_type;
        func_ptr.nodes_start = nodes_start;
        func_ptr.nodes_count = fb.nodes_count;
        func_ptr.locals_start = locals_start;
        func_ptr.locals_count = fb.locals_count;
        func_ptr.code_offset = 0;
    
        self.ir_funcs_count = self.ir_funcs_count + 1;
    
        self.current_func = null;
    }

    fn lowerImplBlock(self: *Lowerer, node: *Node) {
        // ImplBlock: field0=type_name_start, field1=type_name_len, field2=methods_start, field3=methods_count
        let type_name_start: i64 = node.field0;
        let type_name_len: i64 = node.field1;
        let methods_start: i64 = node.field2;
        let methods_count: i64 = node.field3;
    
    
        var method_idx: i64 = 0;
        while method_idx < methods_count {
            let method_node_idx_ptr: *i64 = self.children + methods_start + method_idx;
            let method_node_idx: i64 = method_node_idx_ptr.*;
            let method_node: *Node = self.nodes + method_node_idx;
    
            // Synthesize "TypeName_methodName"
            var synth_len: i64 = 0;
            let synth_name_ptr: i64 = self.synthMethodName(type_name_start, type_name_len,
                method_node.field0, method_node.field1,
                &synth_len);
    
            // Register method in registry for later lookup (method call syntax)
            self.registerMethod(type_name_start, type_name_len,
                method_node.field0, method_node.field1,
                synth_name_ptr, synth_len);
    
            // Lower the method with synthesized name
            self.lowerMethodWithName(method_node, synth_name_ptr, synth_len);
    
            method_idx = method_idx + 1;
        }
    }

    fn lowerBlock(self: *Lowerer, node: *Node) {
        self.lowerBlockCheckTerminated(node);
    }

    fn lowerBlockCheckTerminated(self: *Lowerer, node: *Node) bool {
        // Handle non-block nodes (like IfStmt from "else if")
        // This matches Zig's pattern of checking node type and dispatching
        if node.kind == NodeKind.IfStmt {
            self.lowerIf(node);
            return false;  // If statements don't guarantee termination
        }
    
        if node.kind != NodeKind.BlockStmt {
            // For other statement types, lower as statement
            self.lowerStmt(node);
            return node.kind == NodeKind.ReturnStmt;
        }
    
        // BlockStmt fields:
        // field0 = stmts_start (index in children array)
        // field1 = stmts_count
    
        let stmts_start: i64 = node.field0;
        let stmts_count: i64 = node.field1;
    
        // Safety check: bail if stmts_count is corrupted
        if stmts_count > 500 {
            return false;  // Stop lowering this corrupted block
        }
    
        var terminated: bool = false;
    
        // Iterate over statements in the block
        // Following Zig's pattern at lower.zig:288-296 with index validation
        var i: i64 = 0;
        while i < stmts_count {
            // Get statement node index from children array
            let child_ptr: *i64 = self.children + stmts_start + i;
            let stmt_idx: i64 = child_ptr.*;
    
            // Validate node index - skip invalid indices (like Zig's getNode() orelse continue)
            if stmt_idx >= 0 {
                let stmt_node: *Node = self.nodes + stmt_idx;
    
                // Check if this is a terminator
                if stmt_node.kind == NodeKind.ReturnStmt {
                    terminated = true;
                }
    
                // Lower the statement
                self.lowerStmt(stmt_node);
            }
    
            i = i + 1;
        }
    
        return terminated;
    }

    fn lowerStmt(self: *Lowerer, node: *Node) {
        // Set source position for debug info
        let fb: *FuncBuilder = self.current_func;
        if fb != null {
            fb.setPos( node.start);
        }
    
        if node.kind == NodeKind.ReturnStmt {
            self.lowerReturn(node);
        } else if node.kind == NodeKind.VarDecl {
            self.lowerVarDecl(node);
        } else if node.kind == NodeKind.IfStmt {
            self.lowerIf(node);
        } else if node.kind == NodeKind.WhileStmt {
            self.lowerWhile(node);
        } else if node.kind == NodeKind.ForStmt {
            self.lowerFor(node);
        } else if node.kind == NodeKind.BreakStmt {
            self.lowerBreak(node);
        } else if node.kind == NodeKind.ContinueStmt {
            self.lowerContinue(node);
        } else if node.kind == NodeKind.DeferStmt {
            // Push deferred expression onto stack - will be emitted at scope exit
            // Reference: Zig lower.zig:314-318
            // DeferStmt fields: field0 = expression node index
            self.pushDefer(node.field0);
        } else if node.kind == NodeKind.ExprStmt {
            self.lowerExprStmt(node);
        } else if node.kind == NodeKind.BlockStmt {
            // Handle nested block as statement - copy from Zig lower.zig:284-300
            // Track defer depth for block scope
            let defer_depth: i64 = self.defer_stack_count;
    
            // Enter new scope for variable shadowing
            let fb: *FuncBuilder = self.current_func;
            if fb != null {
                fb.enterScope();
            }
    
            // Process block statements
            let stmts_start: i64 = node.field0;
            let stmts_count: i64 = node.field1;
            var i: i64 = 0;
            while i < stmts_count {
                let child_ptr: *i64 = self.children + stmts_start + i;
                let stmt_idx: i64 = child_ptr.*;
                if stmt_idx >= 0 {  // Validation like Zig's getNode() orelse continue
                    let stmt_node: *Node = self.nodes + stmt_idx;
                    self.lowerStmt(stmt_node);
                }
                i = i + 1;
            }
    
            // Emit block-scoped defers on normal exit
            self.emitDeferredExprs(defer_depth);
    
            // Exit scope for variable shadowing
            if fb != null {
                fb.exitScope();
            }
        }
    }

    fn lowerExprStmt(self: *Lowerer, node: *Node) {
        // ExprStmt fields:
        // field0 = expression node index
        if node.field0 >= 0 {
            let expr_node: *Node = self.nodes + node.field0;
            self.lowerExpr(expr_node);
        }
    }

    fn lowerReturn(self: *Lowerer, node: *Node) {
        // ReturnStmt fields:
        // field0 = value (node index, -1 if void)
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null {
            return;
        }
    
        // Lower return value expression FIRST (before defers modify state)
        // Reference: Zig lower.zig:329-334
        var value_idx: i64 = NULL_NODE;
        if node.field0 >= 0 {
            let expr: *Node = self.nodes + node.field0;
            value_idx = self.lowerExpr(expr);
        }
    
        // If we have deferred expressions and a return value, save to temp local
        // This ensures the return value survives calls in deferred expressions
        // Bug fix: defer calls can clobber x0 where return value might be
        var saved_local_idx: i64 = -1;
        if self.defer_stack_count > 0 and value_idx != NULL_NODE {
            // Create temporary local for return value
            saved_local_idx = fb.addLocal( 0, 0, TYPE_I64, true);
            fb.emitStoreLocal( saved_local_idx, value_idx);
        }
    
        // Emit all deferred expressions in LIFO order (Zig semantics)
        // Reference: Zig lower.zig:334 emitDeferredExprs(0)
        self.emitDeferredExprs(0);
    
        // Load back the saved return value if we saved it
        if saved_local_idx >= 0 {
            value_idx = fb.emitLoadLocal( saved_local_idx);
        }
    
        // Now emit the return with the pre-computed value
        var ret_node: IRNode = IRNode_new(IRNodeKind.Return, TYPE_VOID);
        ret_node.left = value_idx;
        fb.emit( ret_node);
    }

    fn lowerVarDecl(self: *Lowerer, node: *Node) {
        // VarDecl fields:
        // field0 = is_let (1 = let/immutable, 0 = var/mutable)
        // field1 = name_start
        // field2 = name_len
        // field3 = init_expr node index
        // field4 = type_start (legacy, not used with TypeExpr)
        // field5 = type_expr (TypeExpr AST node index)
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null {
            return;
        }
    
        // is_mutable = NOT is_let (var = mutable, let = immutable)
        let is_mutable: bool = node.field0 == 0;
        let type_expr_idx: i64 = node.field5;
    
        // Resolve TypeExpr AST node to TypeRegistry index
        // Reference: Zig's checker.zig resolveTypeExpr()
        var type_idx: i64 = resolve_type_expr(self, type_expr_idx);
        if type_idx < 0 {
            type_idx = TYPE_I64;  // Fallback
        }
    
        // Determine local type and size based on resolved type
        var local_type: i64 = TYPE_I64;
        var array_len: i64 = 0;
        var array_elem_size: i64 = 8;
        var struct_size: i64 = 0;
    
        if type_idx > 0 {
            let type_info: *Type = self.type_pool.get( type_idx);
            if type_info.kind == TypeKind.Slice {
                local_type = TYPE_SLICE;
            } else if type_info.kind == TypeKind.String {
                // BUG-055 fix: Handle string type (16 bytes: ptr + len)
                local_type = TYPE_STRING;
            } else if type_info.kind == TypeKind.Array {
                local_type = type_idx;
                array_len = type_info.len;
                // Get element size from element type
                let elem_type_info: *Type = self.type_pool.get( type_info.elem);
                array_elem_size = elem_type_info.size;
            } else if type_info.kind == TypeKind.Struct {
                local_type = type_idx;
                struct_size = type_info.size;
            } else if type_info.kind == TypeKind.Pointer {
                local_type = type_idx;
            } else if type_info.kind == TypeKind.Func {
                // Function pointer - preserve the function type index
                // This enables indirect call detection in Lowerer_lowerCall
                local_type = type_idx;
            } else if type_info.kind == TypeKind.Bool or type_info.kind == TypeKind.I8 or type_info.kind == TypeKind.I16 or type_info.kind == TypeKind.I32 or type_info.kind == TypeKind.I64 or type_info.kind == TypeKind.U8 or type_info.kind == TypeKind.U16 or type_info.kind == TypeKind.U32 or type_info.kind == TypeKind.U64 {
                // Primitive types - preserve the actual type_idx for codegen
                local_type = type_idx;
            }
        }
    
        let local_idx: i64 = fb.addLocal( node.field1, node.field2, local_type, is_mutable);
    
        // DEBUG: Track local registration (enable with toggle)
        if false {  // Toggle to true for debug
            print("LOWER: Added local '");
            self.printName(node.field1, node.field2);
            print("' idx=");
            print(local_idx);
            print(" in func '");
            self.printName(fb.name_start, fb.name_len);
            print("' total=");
            print(fb.locals_count);
            print("\n");
        }
    
        // Set slice/string local size to 16 bytes (ptr + len)
        // BUG-055 fix: Also handle TYPE_STRING
        if local_type == TYPE_SLICE or local_type == TYPE_STRING {
            fb.setLocalSize( local_idx, 16);
        }
    
        // Set array local size based on array length and element size
        if array_len > 0 {
            let array_size: i64 = array_len * array_elem_size;
            fb.setLocalSize( local_idx, array_size);
        }
    
        // Set struct local size based on struct size from TypeRegistry
        if struct_size > 0 {
            fb.setLocalSize( local_idx, struct_size);
        }
    
        // Set struct type info on the local for struct and pointer-to-struct types
        // This is used later for field access resolution
        var struct_name_start: i64 = -1;
        var struct_name_len: i64 = 0;
        var is_pointer_to_struct: bool = false;
    
        if type_idx > 0 {
            let type_info: *Type = self.type_pool.get( type_idx);
            if type_info != null {
                if type_info.kind == TypeKind.Struct {
                    struct_name_start = type_info.name_start;
                    struct_name_len = type_info.name_len;
                } else if type_info.kind == TypeKind.Pointer {
                    // Check if it's a pointer to a struct
                    let pointee: *Type = self.type_pool.get( type_info.elem);
                    if pointee != null and pointee.kind == TypeKind.Struct {
                        struct_name_start = pointee.name_start;
                        struct_name_len = pointee.name_len;
                        is_pointer_to_struct = true;
                    }
                }
            }
        }
    
        // Store struct type info on the local
        if struct_name_start >= 0 {
            let local: *IRLocal = fb.locals + local_idx;
            local.struct_type_start = struct_name_start;
            local.struct_type_len = struct_name_len;
        }

        // Go-style: zero memory for locals without initializers (structs, arrays)
        // Following Zig: src/frontend/lower.zig:475-486
        // This fixes stage2 hang where `var t: Token;` left Token.kind as garbage
        if node.field3 < 0 {
            // No initializer - zero struct/array types for safety
            let local: *IRLocal = fb.locals + local_idx;
            var type_size: i64 = local.size;
            if type_size <= 0 {
                type_size = self.type_pool.sizeof(local.type_idx);
            }
            // Only zero non-trivial types (size > 8 or struct/array)
            if type_size > 8 or struct_size > 0 or array_len > 0 {
                let addr_ir: i64 = fb.emitAddrLocal(local_idx, TYPE_I64);
                let size_ir: i64 = fb.emitConstInt(type_size);
                var call_node: IRNode = IRNode_new(IRNodeKind.Call, TYPE_VOID);
                call_node.func_name_start = get_memset_zero_name();
                call_node.func_name_len = 11;
                i64list_append(&call_node.call_args, addr_ir);
                i64list_append(&call_node.call_args, size_ir);
                fb.emit(call_node);
            }
            return;
        }

        // If there's an initializer, emit store
        if node.field3 >= 0 {
            let init_expr: *Node = self.nodes + node.field3;
    
            // Go-style: zero memory for "undefined" initializer instead of leaving uninitialized
            // Following Zig: src/frontend/lower.zig:475-486 emits memset_zero call
            // This prevents non-deterministic behavior from uninitialized stack memory
            if init_expr.kind == NodeKind.Ident {
                if name_is_undefined(self.source, init_expr.field0, init_expr.field1) {
                    // Get local's size
                    let local: *IRLocal = fb.locals + local_idx;
                    var type_size: i64 = local.size;
                    if type_size <= 0 {
                        // Try getting size from type
                        type_size = self.type_pool.sizeof(local.type_idx);
                    }
                    if type_size > 0 {
                        // Emit memset_zero(addr, size) call
                        let addr_ir: i64 = fb.emitAddrLocal(local_idx, TYPE_I64);
                        let size_ir: i64 = fb.emitConstInt(type_size);

                        // Build call node
                        var call_node: IRNode = IRNode_new(IRNodeKind.Call, TYPE_VOID);
                        call_node.func_name_start = get_memset_zero_name();
                        call_node.func_name_len = 11;  // "memset_zero"
                        i64list_append(&call_node.call_args, addr_ir);
                        i64list_append(&call_node.call_args, size_ir);
                        fb.emit(call_node);
                    }
                    return;
                }
            }
    
            // Special case for struct literal initialization
            if init_expr.kind == NodeKind.StructLit {
                // Record struct type on the local for field access later
                let local: *IRLocal = fb.locals + local_idx;
                local.struct_type_start = init_expr.field0;  // type_name_start
                local.struct_type_len = init_expr.field1;    // type_name_len
    
                self.lowerStructLitToLocal(init_expr, local_idx);
            } else if init_expr.kind == NodeKind.ArrayLit {
                // Array literal initialization: [elem1, elem2, ...]
                self.lowerArrayLitToLocal(init_expr, local_idx);
            } else if init_expr.kind == NodeKind.SliceExpr {
                // Slice expression: arr[start:end] - store ptr and len separately
                self.lowerSliceExprToLocal(init_expr, local_idx);
            } else if init_expr.kind == NodeKind.CallExpr and local_type == TYPE_SLICE {
                // Call returning slice - extract ptr and len and store separately
                let call_ir: i64 = self.lowerExpr(init_expr);
                let ptr_ir: i64 = fb.emitSlicePtr( call_ir, TYPE_I64);
                let len_ir: i64 = fb.emitSliceLen( call_ir);
                fb.emitStoreFieldLocal( local_idx, 0, ptr_ir);
                fb.emitStoreFieldLocal( local_idx, 8, len_ir);
            } else if init_expr.kind == NodeKind.BinaryExpr and local_type == TYPE_STRING {
                // String concatenation: a + b -> __cot_str_concat call
                // Following Zig pattern: src/frontend/lower.zig:1476-1484
                let concat_ir: i64 = self.lowerExpr(init_expr);
                let ptr_ir: i64 = fb.emitSlicePtr( concat_ir, TYPE_I64);
                let len_ir: i64 = fb.emitSliceLen( concat_ir);
                fb.emitStoreFieldLocal( local_idx, 0, ptr_ir);
                fb.emitStoreFieldLocal( local_idx, 8, len_ir);
            } else if init_expr.kind == NodeKind.BuiltinCall and (local_type == TYPE_SLICE or local_type == TYPE_STRING) {
                // BuiltinCall returning string/slice (@string) - extract ptr and len and store separately
                let builtin_ir: i64 = self.lowerExpr(init_expr);
                let ptr_ir: i64 = fb.emitSlicePtr( builtin_ir, TYPE_I64);
                let len_ir: i64 = fb.emitSliceLen( builtin_ir);
                fb.emitStoreFieldLocal( local_idx, 0, ptr_ir);
                fb.emitStoreFieldLocal( local_idx, 8, len_ir);
            } else if init_expr.kind == NodeKind.StringLit and (local_type == TYPE_SLICE or local_type == TYPE_STRING) {
                // String literal to string/slice - decompose into ptr and len
                // BUG-055 fix: Handle both TYPE_SLICE and TYPE_STRING
                // Following Zig: src/frontend/ssa_builder.zig:586-648 (store_local slice handling)
                // StringLit: field0 = str_start, field1 = str_len (source length, before escapes)
                let str_start: i64 = init_expr.field0;
                let source_len: i64 = init_expr.field1;
                // Compute actual length after escape processing
                let actual_len: i64 = compute_escaped_length(self.source, str_start, source_len);
                // Emit ConstString for the pointer (uses source len for copying)
                let ptr_ir: i64 = fb.emitConstString( str_start, source_len);
                // Emit ConstInt for the actual length (after escape processing)
                let len_ir: i64 = fb.emitConstInt( actual_len);
                // Store ptr at offset 0, len at offset 8
                fb.emitStoreFieldLocal( local_idx, 0, ptr_ir);
                fb.emitStoreFieldLocal( local_idx, 8, len_ir);
            } else {
                // Check if this is array copy: var b: [N]T = a
                // Following Zig pattern (lower.zig:437-481): copy element-by-element
                let local_type_info: *Type = self.type_pool.get( local_type);
                if local_type_info != null and local_type_info.kind == TypeKind.Array {
                    // Array copy: need to copy each element
                    let elem_type: i64 = local_type_info.elem;
                    let elem_size: i64 = self.type_pool.sizeof( elem_type);
                    let arr_len: i64 = local_type_info.len;
    
                    // Check if source is an identifier (another local)
                    if init_expr.kind == NodeKind.Ident {
                        let src_name_start: i64 = init_expr.field0;
                        let src_name_len: i64 = init_expr.field1;
    
                        // Look up source local
                        var src_local_idx: i64 = -1;
                        var j: i64 = 0;
                        while j < fb.locals_count {
                            let src_local: *IRLocal = fb.locals + j;
                            if names_equal(self.source, src_local.name_start, src_local.name_len,
                                          src_name_start, src_name_len) {
                                src_local_idx = j;
                                break;
                            }
                            j = j + 1;
                        }
    
                        if src_local_idx >= 0 {
                            // Copy each element: dst[i] = src[i]
                            var i: i64 = 0;
                            while i < arr_len {
                                let idx_ir: i64 = fb.emitConstInt( i);
                                // Load src[i]
                                let src_elem: i64 = fb.emitIndexLocal( src_local_idx, idx_ir, elem_size, elem_type);
                                // Store to dst[i]
                                fb.emitStoreIndexLocal( local_idx, idx_ir, src_elem, elem_size);
                                i = i + 1;
                            }
                        } else {
                            // Source not found, fallback to default store
                            let value_idx: i64 = self.lowerExpr(init_expr);
                            fb.emitStoreLocal( local_idx, value_idx);
                        }
                    } else {
                        // Not an identifier, fallback to default store
                        let value_idx: i64 = self.lowerExpr(init_expr);
                        fb.emitStoreLocal( local_idx, value_idx);
                    }
                } else if local_type_info != null and (local_type_info.kind == TypeKind.String or local_type_info.kind == TypeKind.Slice) {
                    // String/slice copy: var s2: string = s1
                    // Following Zig pattern: copy both ptr (offset 0) and len (offset 8)
                    if init_expr.kind == NodeKind.Ident {
                        let src_name_start: i64 = init_expr.field0;
                        let src_name_len: i64 = init_expr.field1;
    
                        // Look up source local
                        var src_local_idx: i64 = -1;
                        var j: i64 = 0;
                        while j < fb.locals_count {
                            let src_local: *IRLocal = fb.locals + j;
                            if names_equal(self.source, src_local.name_start, src_local.name_len,
                                          src_name_start, src_name_len) {
                                src_local_idx = j;
                                break;
                            }
                            j = j + 1;
                        }
    
                        if src_local_idx >= 0 {
                            // Copy ptr field (offset 0)
                            let src_ptr: i64 = fb.emitFieldLocal( src_local_idx, 0, TYPE_I64);
                            fb.emitStoreFieldLocal( local_idx, 0, src_ptr);
                            // Copy len field (offset 8)
                            let src_len: i64 = fb.emitFieldLocal( src_local_idx, 8, TYPE_I64);
                            fb.emitStoreFieldLocal( local_idx, 8, src_len);
                        } else {
                            // Source not found, fallback to default store
                            let value_idx: i64 = self.lowerExpr(init_expr);
                            fb.emitStoreLocal( local_idx, value_idx);
                        }
                    } else {
                        // Not an identifier, fallback to default store
                        let value_idx: i64 = self.lowerExpr(init_expr);
                        fb.emitStoreLocal( local_idx, value_idx);
                    }
                } else {
                    // Not an array, use default store
                    let value_idx: i64 = self.lowerExpr(init_expr);
                    fb.emitStoreLocal( local_idx, value_idx);
                }
            }
        }
    }

    fn lowerStructLitToLocal(self: *Lowerer, node: *Node, local_idx: i64) {
        // StructLit fields:
        // field0 = type_name_start
        // field1 = type_name_len
        // field2 = fields_start (index in children array)
        // field3 = fields_count
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return; }
    
        let struct_name_start: i64 = node.field0;
        let struct_name_len: i64 = node.field1;
        let fields_start: i64 = node.field2;
        let fields_count: i64 = node.field3;
    
        // For each field initializer, emit a store to the local's field
        var i: i64 = 0;
        while i < fields_count {
            // Get field init node from children array
            let child_ptr: *i64 = self.children + fields_start + i;
            let field_init_idx: i64 = child_ptr.*;
            let field_init: *Node = self.nodes + field_init_idx;
    
            // FieldInit fields:
            // field0 = field_name_start
            // field1 = field_name_len
            // field2 = value (node index)
    
            let fname_start: i64 = field_init.field0;
            let fname_len: i64 = field_init.field1;
            let value_node_idx: i64 = field_init.field2;
            let value_node: *Node = self.nodes + value_node_idx;
    
            // Lower the value expression
            let value_ir: i64 = self.lowerExpr(value_node);
    
            // Look up field offset from TypeRegistry (single source of truth)
            var field_offset: i64 = i * 8;  // Fallback
            let struct_type_idx: i64 = self.type_pool.lookupByName( self.source, struct_name_start, struct_name_len);
            if struct_type_idx > 0 {
                let field_info: *FieldInfo = self.type_pool.lookupField( struct_type_idx,
                                                                       self.source + fname_start, fname_len);
                if field_info != null {
                    field_offset = field_info.offset;
                }
            }
    
            // Emit store to local's field using StoreFieldLocal
            fb.emitStoreFieldLocal( local_idx, field_offset, value_ir);
    
            i = i + 1;
        }
    }

    fn lowerArrayLitToLocal(self: *Lowerer, node: *Node, local_idx: i64) {
        // ArrayLit fields:
        // field0 = elements_start (index in children array)
        // field1 = elements_count
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return; }
    
        let elements_start: i64 = node.field0;
        let elements_count: i64 = node.field1;
    
        // Set the local's size to fit all elements (8 bytes per element for i64)
        let array_size: i64 = elements_count * 8;
        fb.setLocalSize( local_idx, array_size);
    
        // For each element, store to the local at the appropriate offset
        var i: i64 = 0;
        while i < elements_count {
            // Get element node from children array
            let child_ptr: *i64 = self.children + elements_start + i;
            let elem_idx: i64 = child_ptr.*;
            let elem_node: *Node = self.nodes + elem_idx;
    
            // Lower the element expression
            let value_ir: i64 = self.lowerExpr(elem_node);
    
            // Calculate element offset (assuming 8 bytes per element for i64)
            let elem_offset: i64 = i * 8;
    
            // Emit store to local's element using StoreFieldLocal
            fb.emitStoreFieldLocal( local_idx, elem_offset, value_ir);
    
            i = i + 1;
        }
    }

    fn lowerSliceExprToLocal(self: *Lowerer, node: *Node, local_idx: i64) {
        // SliceExpr fields:
        // field0 = base expression (node index)
        // field1 = start index (-1 if omitted)
        // field2 = end index (-1 if omitted)
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return; }
    
        let base_node: *Node = self.nodes + node.field0;
        let start_node_idx: i64 = node.field1;
        let end_node_idx: i64 = node.field2;
    
        // For cot0, assume element type is i64 (8 bytes)
        let elem_size: i64 = 8;
    
        // Default start to 0 if not specified
        var start_ir: i64;
        if start_node_idx < 0 {
            start_ir = fb.emitConstInt( 0);
        } else {
            let start_node: *Node = self.nodes + start_node_idx;
            start_ir = self.lowerExpr(start_node);
        }
    
        // Look up base local first (needed for implicit end)
        var base_local_idx: i64 = -1;
        var array_len: i64 = 0;
        var deref_ptr_local_idx: i64 = -1;
    
        if base_node.kind == NodeKind.Ident {
            var i: i64 = 0;
            while i < fb.locals_count {
                let local: *IRLocal = fb.locals + i;
                if names_equal(self.source, local.name_start, local.name_len,
                              base_node.field0, base_node.field1) {
                    base_local_idx = i;
                    // Get array length from local size (arrays are stored with size = len * 8)
                    if local.size > 0 and local.size != 16 {
                        array_len = local.size / 8;
                    }
                }
                i = i + 1;
            }
        } else if base_node.kind == NodeKind.DerefExpr {
            // Handle arr.*[:] where arr is a pointer to an array
            let ptr_operand: *Node = self.nodes + base_node.field0;
            if ptr_operand.kind == NodeKind.Ident {
                // Look up the pointer local
                var i: i64 = 0;
                while i < fb.locals_count {
                    let local: *IRLocal = fb.locals + i;
                    if names_equal(self.source, local.name_start, local.name_len,
                                  ptr_operand.field0, ptr_operand.field1) {
                        deref_ptr_local_idx = i;
                        // Get array length from pointee type
                        let ptr_type: *Type = self.type_pool.get( local.type_idx);
                        if ptr_type.kind == TypeKind.Pointer {
                            let pointee_type: *Type = self.type_pool.get( ptr_type.elem);
                            if pointee_type.kind == TypeKind.Array {
                                array_len = pointee_type.len;
                            }
                        }
                    }
                    i = i + 1;
                }
            }
        }
    
        // Lower end index - use array length if not specified
        var end_ir: i64;
        if end_node_idx < 0 {
            end_ir = fb.emitConstInt( array_len);
        } else {
            let end_node: *Node = self.nodes + end_node_idx;
            end_ir = self.lowerExpr(end_node);
        }
    
        // Calculate length: end - start
        let len_ir: i64 = fb.emitBinary(IR_OP_SUB, end_ir, start_ir, TYPE_I64);
    
        // Get pointer to base[start]
        // Following Zig: src/frontend/ssa_builder.zig:1422-1444
        // For slices/strings: load ptr from offset 0 of slice struct
        // For arrays: use local_addr (address of inline data)
        var ptr_ir: i64 = fb.emitConstInt( 0);
        if base_local_idx >= 0 {
            let base_local: *IRLocal = fb.locals + base_local_idx;
            let base_type: *Type = self.type_pool.get( base_local.type_idx);
    
            var base_ptr: i64;
            var actual_elem_size: i64 = elem_size;
    
            if base_type != null and (base_type.kind == TypeKind.String or base_type.kind == TypeKind.Slice) {
                // For slices/strings: load the ptr field from offset 0
                // Following Zig: lines 1432-1435 (load from offset 0)
                base_ptr = fb.emitFieldLocal( base_local_idx, 0, TYPE_I64);
                // For strings, elem_size is 1 (u8)
                if base_type.kind == TypeKind.String {
                    actual_elem_size = 1;
                }
            } else {
                // For arrays: get address of inline array data
                base_ptr = fb.emitAddrLocal( base_local_idx, TYPE_I64);
            }
    
            // Calculate offset: start * elem_size
            let elem_size_ir: i64 = fb.emitConstInt( actual_elem_size);
            let offset_ir: i64 = fb.emitBinary(IR_OP_MUL, start_ir, elem_size_ir, TYPE_I64);
            // Add offset to base pointer
            ptr_ir = fb.emitBinary(IR_OP_ADD, base_ptr, offset_ir, TYPE_I64);
        } else if deref_ptr_local_idx >= 0 {
            // For arr.*[:], load the pointer value as the base
            let base_ptr: i64 = fb.emitLoadLocal( deref_ptr_local_idx);
            // Calculate offset: start * elem_size
            let elem_size_ir: i64 = fb.emitConstInt( elem_size);
            let offset_ir: i64 = fb.emitBinary(IR_OP_MUL, start_ir, elem_size_ir, TYPE_I64);
            // Add offset to base pointer
            ptr_ir = fb.emitBinary(IR_OP_ADD, base_ptr, offset_ir, TYPE_I64);
        }
    
        // Store ptr at offset 0 of slice local
        fb.emitStoreFieldLocal( local_idx, 0, ptr_ir);
        // Store len at offset 8 of slice local
        fb.emitStoreFieldLocal( local_idx, 8, len_ir);
    }

    fn lowerIf(self: *Lowerer, node: *Node) {
        // IfStmt fields:
        // field0 = condition expr node index
        // field1 = then body node index
        // field2 = else body node index (-1 if none)
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return; }
    
        // Create blocks
        let then_block: i64 = fb.newBlock();
        var else_block: i64 = -1;
        if node.field2 >= 0 {
            else_block = fb.newBlock();
        }
        let merge_block: i64 = fb.newBlock();
    
        // Lower condition
        let cond_node: *Node = self.nodes + node.field0;
        let cond_idx: i64 = self.lowerExpr(cond_node);
    
        // Emit branch
        var target_else: i64 = merge_block;
        if else_block >= 0 {
            target_else = else_block;
        }
        fb.emitBranch( cond_idx, then_block, target_else);
    
        // Lower then body
        fb.setBlock( then_block);
        let then_node: *Node = self.nodes + node.field1;
        let then_terminated: bool = self.lowerBlockCheckTerminated(then_node);
        if not then_terminated {
            fb.emitJump( merge_block);
        }
    
        // Lower else body if present
        if else_block >= 0 {
            fb.setBlock( else_block);
            let else_node: *Node = self.nodes + node.field2;
            let else_terminated: bool = self.lowerBlockCheckTerminated(else_node);
            if not else_terminated {
                fb.emitJump( merge_block);
            }
        }
    
        // Continue in merge block
        fb.setBlock( merge_block);
    }

    fn lowerWhile(self: *Lowerer, node: *Node) {
        // WhileStmt fields:
        // field0 = condition expr
        // field1 = body
        // field2 = label name start (0 if no label) - cot1
        // field3 = label name len (0 if no label) - cot1
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return; }
    
        // Create blocks: header (condition), body, exit
        let header_block: i64 = fb.newBlock();
        let body_block: i64 = fb.newBlock();
        let exit_block: i64 = fb.newBlock();
    
        // Save outer loop context and set new one
        // Reference: Zig lower.zig:944-948
        let saved_continue: i64 = self.loop_continue_block;
        let saved_break: i64 = self.loop_break_block;
        let saved_defer_depth: i64 = self.loop_defer_depth;
        self.loop_continue_block = header_block;
        self.loop_break_block = exit_block;
        self.loop_defer_depth = self.getDeferDepth();
    
        // cot1: If this while loop has a label, push it onto the label stack
        let label_start: i64 = node.field2;
        let label_len: i64 = node.field3;
        let has_label: bool = label_len > 0;
        if has_label {
            self.pushLabel(label_start, label_len, exit_block, header_block,
                              self.getDeferDepth());
        }
    
        // Jump from current block to header
        fb.emitJump( header_block);
    
        // Header block: evaluate condition, branch to body or exit
        fb.setBlock( header_block);
        let cond_node: *Node = self.nodes + node.field0;
        let cond_idx: i64 = self.lowerExpr(cond_node);
        fb.emitBranch( cond_idx, body_block, exit_block);
    
        // Body block: execute body, jump back to header
        fb.setBlock( body_block);
        let body_node: *Node = self.nodes + node.field1;
        // Safety check: ensure body is a BlockStmt
        if body_node.kind != NodeKind.BlockStmt {
            // cot1: Pop label before early return
            if has_label { self.popLabel(); }
            return;
        }
        let body_terminated: bool = self.lowerBlockCheckTerminated(body_node);
        if not body_terminated {
            fb.emitJump( header_block);
        }
    
        // cot1: Pop label from stack
        if has_label {
            self.popLabel();
        }
    
        // Restore outer loop context
        self.loop_continue_block = saved_continue;
        self.loop_break_block = saved_break;
        self.loop_defer_depth = saved_defer_depth;
    
        // Continue in exit block
        fb.setBlock( exit_block);
    }

    fn lowerFor(self: *Lowerer, node: *Node) {
        // ForStmt fields:
        // field0 = binding name_start
        // field1 = binding name_len
        // field2 = iterable expression (node index)
        // field3 = body (block node index)
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return; }
    
        let binding_start: i64 = node.field0;
        let binding_len: i64 = node.field1;
        let iter_node_idx: i64 = node.field2;
        let body_node_idx: i64 = node.field3;
    
        // Get the iterable node
        let iter_node: *Node = self.nodes + iter_node_idx;
    
        // Determine array length from iterable
        // For now, we need the iterable to be an identifier to look up its type
        var array_len: i64 = 0;
        var iter_local_idx: i64 = -1;
        var TypeInfo_isSlice: bool = false;
        if iter_node.kind == NodeKind.Ident {
            // Look up the local variable
            var i: i64 = 0;
            while i < fb.locals_count {
                let local: *IRLocal = fb.locals + i;
                if names_equal(self.source, local.name_start, local.name_len,
                              iter_node.field0, iter_node.field1) {
                    iter_local_idx = i;
                    if local.type_idx == TYPE_SLICE {
                        // Slice: length stored at offset 8 (loaded at runtime)
                        TypeInfo_isSlice = true;
                    } else {
                        // Array: get length from local size (assuming 8 bytes per element)
                        array_len = local.size / 8;
                        if array_len < 1 {
                            array_len = 1;  // Default to at least 1
                        }
                    }
                }
                i = i + 1;
            }
        }
    
        // Create index variable: var __idx: i64 = 0
        let idx_local: i64 = fb.addLocal( 0, 0, TYPE_I64, true);  // unnamed temp local
        let zero: i64 = fb.emitConstInt( 0);
        fb.emitStoreLocal( idx_local, zero);
    
        // Create length variable: var __len: i64 = <length>
        let len_local: i64 = fb.addLocal( 0, 0, TYPE_I64, false);
        if TypeInfo_isSlice {
            // For slices: load length from slice local (offset 8)
            let len_val: i64 = fb.emitFieldLocal( iter_local_idx, 8, TYPE_I64);
            fb.emitStoreLocal( len_local, len_val);
        } else {
            // For arrays: use compile-time constant
            let len_val: i64 = fb.emitConstInt( array_len);
            fb.emitStoreLocal( len_local, len_val);
        }
    
        // Create loop blocks: header (condition), body, incr, exit
        let header_block: i64 = fb.newBlock();
        let body_block: i64 = fb.newBlock();
        let incr_block: i64 = fb.newBlock();
        let exit_block: i64 = fb.newBlock();
    
        // Save outer loop context and set new one
        // Note: continue goes to incr_block (increment then check), break goes to exit_block
        // Reference: Zig lower.zig:1052-1056
        let saved_continue: i64 = self.loop_continue_block;
        let saved_break: i64 = self.loop_break_block;
        let saved_defer_depth: i64 = self.loop_defer_depth;
        self.loop_continue_block = incr_block;
        self.loop_break_block = exit_block;
        self.loop_defer_depth = self.getDeferDepth();
    
        // Jump to header
        fb.emitJump( header_block);
    
        // Header block: __idx < __len
        fb.setBlock( header_block);
        let idx_val: i64 = fb.emitLoadLocal( idx_local);
        let len_cond: i64 = fb.emitLoadLocal( len_local);
        let cond: i64 = fb.emitBinary(IR_OP_LT, idx_val, len_cond, TYPE_BOOL);
        fb.emitBranch( cond, body_block, exit_block);
    
        // Body block: let item = array[__idx]; body
        fb.setBlock( body_block);
    
        // Create binding variable: let item = array[__idx]
        let binding_local: i64 = fb.addLocal( binding_start, binding_len, TYPE_I64, false);
    
        // Load current index
        let cur_idx: i64 = fb.emitLoadLocal( idx_local);
    
        // Get element at index
        if iter_local_idx >= 0 {
            let elem_size: i64 = 8;  // Assume i64 elements
            if TypeInfo_isSlice {
                // For slices: load ptr from offset 0, then index through it
                let ptr_val: i64 = fb.emitFieldLocal( iter_local_idx, 0, TYPE_I64);
                let elem_val: i64 = fb.emitIndexValue( ptr_val, cur_idx, elem_size, TYPE_I64);
                fb.emitStoreLocal( binding_local, elem_val);
            } else {
                // For arrays: arr[__idx]
                let elem_val: i64 = fb.emitIndexLocal( iter_local_idx, cur_idx, elem_size, TYPE_I64);
                fb.emitStoreLocal( binding_local, elem_val);
            }
        }
    
        // Lower body
        let body_node: *Node = self.nodes + body_node_idx;
        let body_terminated: bool = self.lowerBlockCheckTerminated(body_node);
        if not body_terminated {
            fb.emitJump( incr_block);
        }
    
        // Increment block: __idx = __idx + 1
        fb.setBlock( incr_block);
        let idx_before_incr: i64 = fb.emitLoadLocal( idx_local);
        let one: i64 = fb.emitConstInt( 1);
        let idx_after_incr: i64 = fb.emitBinary(IR_OP_ADD, idx_before_incr, one, TYPE_I64);
        fb.emitStoreLocal( idx_local, idx_after_incr);
        fb.emitJump( header_block);
    
        // Restore outer loop context
        self.loop_continue_block = saved_continue;
        self.loop_break_block = saved_break;
        self.loop_defer_depth = saved_defer_depth;
    
        // Continue in exit block
        fb.setBlock( exit_block);
    }

    fn lowerBreak(self: *Lowerer, node: *Node) {
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return; }
    
        // cot1: Check for labeled break
        let label_start: i64 = node.field0;
        let label_len: i64 = node.field1;
    
        var target_block: i64 = self.loop_break_block;
        var defer_depth: i64 = self.loop_defer_depth;
    
        if label_len > 0 {
            // Labeled break: look up the label
            let label_idx: i64 = self.findLabel(label_start, label_len);
            if label_idx >= 0 {
                target_block = self.getLabelBreakBlock(label_idx);
                defer_depth = self.getLabelDeferDepth(label_idx);
            }
        }
    
        if target_block < 0 { return; }  // Not in a loop
    
        // Emit defers from current depth down to target loop entry
        // Reference: Zig lower.zig:1125
        self.emitDeferredExprs(defer_depth);
    
        fb.emitJump( target_block);
    }

    fn lowerContinue(self: *Lowerer, node: *Node) {
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return; }
    
        // cot1: Check for labeled continue
        let label_start: i64 = node.field0;
        let label_len: i64 = node.field1;
    
        var target_block: i64 = self.loop_continue_block;
        var defer_depth: i64 = self.loop_defer_depth;
    
        if label_len > 0 {
            // Labeled continue: look up the label
            let label_idx: i64 = self.findLabel(label_start, label_len);
            if label_idx >= 0 {
                target_block = self.getLabelContinueBlock(label_idx);
                defer_depth = self.getLabelDeferDepth(label_idx);
            }
        }
    
        if target_block < 0 { return; }  // Not in a loop
    
        // Emit defers from current depth down to target loop entry
        // Reference: Zig lower.zig:1135
        self.emitDeferredExprs(defer_depth);
    
        fb.emitJump( target_block);
    }

    fn lowerExpr(self: *Lowerer, node: *Node) i64 {
        let fb: *FuncBuilder = self.current_func;
        if fb == null {
            return NULL_NODE;
        }
    
        // Set source position for debug info (DWARF line tables)
        fb.setPos( node.start);
    
        if node.kind == NodeKind.IntLit {
            return self.lowerIntLit(node);
        } else if node.kind == NodeKind.StringLit {
            return self.lowerStringLit(node);
        } else if node.kind == NodeKind.Ident {
            return self.lowerIdent(node);
        } else if node.kind == NodeKind.BinaryExpr {
            return self.lowerBinary(node);
        } else if node.kind == NodeKind.UnaryExpr {
            return self.lowerUnary(node);
        } else if node.kind == NodeKind.CallExpr {
            return self.lowerCall(node);
        } else if node.kind == NodeKind.AssignExpr {
            return self.lowerAssign(node);
        } else if node.kind == NodeKind.AddressOf {
            return self.lowerAddressOf(node);
        } else if node.kind == NodeKind.DerefExpr {
            return self.lowerDeref(node);
        } else if node.kind == NodeKind.FieldAccess {
            return self.lowerFieldAccess(node);
        } else if node.kind == NodeKind.IndexExpr {
            return self.lowerIndex(node);
        } else if node.kind == NodeKind.SliceExpr {
            return self.lowerSliceExpr(node);
        } else if node.kind == NodeKind.BuiltinCall {
            return self.lowerBuiltinCall(node);
        } else if node.kind == NodeKind.SwitchExpr {
            return self.lowerSwitchExpr(node);
        } else if node.kind == NodeKind.StructLit {
            return self.lowerStructLit(node);
        }
    
        // DEBUG: Report unhandled expression type
        print("LOWERER ERROR: Unhandled expr kind=");
        Lowerer_printNodeKind(node.kind);
        print(" at pos=");
        print(node.start);
        print("\n");
        return NULL_NODE;
    }

    fn printName(self: *Lowerer, start: i64, len: i64) {
        // Print actual chars from source
        if start >= 0 and start + len <= self.source_len {
            write(1, self.source + start, len);
        } else {
            print("INVALID pos=");
            print(start);
            print(" len=");
            print(len);
            print(" src_len=");
            print(self.source_len);
        }
    }

    // Note: printNodeKind moved outside impl block (static function)

    fn lowerIntLit(self: *Lowerer, node: *Node) i64 {
        // IntLit fields:
        // field0 = value (the integer value)
    
        let fb: *FuncBuilder = self.current_func;
        return fb.emitConstInt( node.field0);
    }

    fn lowerStringLit(self: *Lowerer, node: *Node) i64 {
        // StringLit fields:
        // field0 = string_start (offset in source, after opening quote)
        // field1 = string_len (length of string content, excluding quotes)
    
        let fb: *FuncBuilder = self.current_func;
        return fb.emitConstString( node.field0, node.field1);
    }

    fn lowerStructLit(self: *Lowerer, node: *Node) i64 {
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        // StructLit fields:
        // field0 = type_name_start, field1 = type_name_len
        // field2 = fields_start (in children), field3 = fields_count
        let type_name_start: i64 = node.field0;
        let type_name_len: i64 = node.field1;
        let fields_start: i64 = node.field2;
        let fields_count: i64 = node.field3;
    
        // Look up the struct type by name
        let struct_type_idx: i64 = self.type_pool.findByName( self.source + type_name_start, type_name_len);
        if struct_type_idx < 0 {
            return NULL_NODE;
        }
    
        // Get struct size
        let struct_size: i64 = self.type_pool.sizeof( struct_type_idx);
    
        // Create a temporary local for the struct
        let temp_idx: i64 = fb.addLocal( 0, 0, struct_type_idx, true);
        fb.setLocalSize( temp_idx, struct_size);
    
        // Initialize each field
        var i: i64 = 0;
        while i < fields_count {
            let field_child_ptr: *i64 = self.children + fields_start + i;
            let field_init_idx: i64 = field_child_ptr.*;
            let field_init_node: *Node = self.nodes + field_init_idx;
    
            // FieldInit fields:
            // field0 = field_name_start, field1 = field_name_len, field2 = value
            let field_name_start: i64 = field_init_node.field0;
            let field_name_len: i64 = field_init_node.field1;
            let value_node_idx: i64 = field_init_node.field2;
    
            // Lower the value expression
            let value_node: *Node = self.nodes + value_node_idx;
            let value_ir: i64 = self.lowerExpr(value_node);
    
            // Look up field offset from struct type
            let field_info: *FieldInfo = self.type_pool.lookupField( struct_type_idx,
                                                                  self.source + field_name_start, field_name_len);
            if field_info != null {
                let field_offset: i64 = field_info.offset;
                fb.emitStoreFieldLocal( temp_idx, field_offset, value_ir);
            }
    
            i = i + 1;
        }
    
        // Return a load of the temporary struct
        return fb.emitLoadLocal( temp_idx);
    }

    fn lowerIdent(self: *Lowerer, node: *Node) i64 {
        // Ident fields:
        // field0 = name_start
        // field1 = name_len
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        // Handle keyword literals (following Zig: src/frontend/lower.zig:1400-1408)
        if name_is_undefined(self.source, node.field0, node.field1) {
            // undefined: emit zero for safety (Zig emits ConstNull)
            return fb.emitConstInt( 0);
        }
        if name_is_null(self.source, node.field0, node.field1) {
            return fb.emitConstInt( 0);
        }
        if name_is_true(self.source, node.field0, node.field1) {
            return fb.emitConstInt( 1);
        }
        if name_is_false(self.source, node.field0, node.field1) {
            return fb.emitConstInt( 0);
        }
    
        // First check if this is a constant
        if self.hasConst(node.field0, node.field1) {
            let const_value: i64 = self.lookupConst(node.field0, node.field1);
            return fb.emitConstInt( const_value);
        }
    
        // Look up local variable by name - iterate BACKWARD for proper shadowing
        // Only consider locals whose scope_depth <= current scope
        var i: i64 = fb.locals_count - 1;
        while i >= 0 {
            let local: *IRLocal = fb.locals + i;
            // Skip locals from inner scopes that are no longer active
            if local.scope_depth <= fb.current_scope {
                if names_equal(self.source, local.name_start, local.name_len, node.field0, node.field1) {
                    let local_type: i64 = local.type_idx;
                    // Arrays are passed by reference - emit address instead of load
                    // Following src/frontend/lower.zig:1438-1442
                    if TypeInfo_isArray(self.type_pool, local_type) {
                        return fb.emitAddrLocal( i, local_type);
                    }
                    return fb.emitLoadLocal( i);
                }
            }
            i = i - 1;
        }
    
        // Check for global variable
        let global_idx: i64 = self.lookupGlobal(node.field0, node.field1);
        if global_idx >= 0 {
            let g: *IRGlobal = self.getGlobal(global_idx);
            // Arrays are accessed by address, scalars are loaded
            if g.is_array {
                return fb.emitAddrGlobal( global_idx, g.type_idx);
            }
            return fb.emitLoadGlobal( global_idx, g.type_idx);
        }
    
        // Check if it's a function name (for function pointers)
        // Following Zig: src/frontend/lower.zig:1446-1449
        let func_idx: i64 = self.lookupFunc(node.field0, node.field1);
        if func_idx >= 0 {
            // Emit function address - copy name to owned buffer
            let name_ptr: i64 = copy_func_name(self.source, node.field0, node.field1);
            return fb.emitFuncAddr( name_ptr, node.field1, TYPE_I64);
        }
    
        // Not found - return null node (silently for now)
        return NULL_NODE;
    }

    fn inferExprType(self: *Lowerer, node: *Node) i64 {
        let fb: *FuncBuilder = self.current_func;
    
        // Literals
        if node.kind == NodeKind.IntLit {
            return TYPE_I64;
        }
        if node.kind == NodeKind.StringLit {
            return TYPE_STRING;
        }
    
        // Boolean literals (True/False are parsed as IntLit with value 1/0)
        // If we need to distinguish, check the token - for now treat as i64
    
        // Identifiers: look up local or global variable type
        if node.kind == NodeKind.Ident {
            if fb != null {
                var i: i64 = 0;
                while i < fb.locals_count {
                    let local: *IRLocal = fb.locals + i;
                    if names_equal(self.source, local.name_start, local.name_len, node.field0, node.field1) {
                        return local.type_idx;
                    }
                    i = i + 1;
                }
            }
            // Also check globals
            let global_idx: i64 = self.lookupGlobal(node.field0, node.field1);
            if global_idx >= 0 {
                let g: *IRGlobal = self.getGlobal(global_idx);
                return g.type_idx;
            }
            return TYPE_I64;
        }
    
        // Binary expressions
        if node.kind == NodeKind.BinaryExpr {
            let ast_op: i64 = node.field2;
            // Comparison operators return bool
            // BinaryOp enum: Equal=4, NotEqual=5, Less=6, LessEq=7, Greater=8, GreaterEq=9
            if ast_op >= 4 and ast_op <= 9 {
                return TYPE_BOOL;
            }
            // And=10, Or=11 also return bool
            if ast_op == 10 or ast_op == 11 {
                return TYPE_BOOL;
            }
            // Arithmetic/bitwise: use left operand type
            let left_node: *Node = self.nodes + node.field0;
            return self.inferExprType(left_node);
        }
    
        // Unary expressions
        if node.kind == NodeKind.UnaryExpr {
            let unary_op: i64 = node.field1;
            // UnaryOp::Not (logical not) returns bool
            if unary_op == 1 {  // Not = 1
                return TYPE_BOOL;
            }
            // Neg, BitNot: follow operand type
            let operand_node: *Node = self.nodes + node.field0;
            return self.inferExprType(operand_node);
        }
    
        // Address-of: return pointer to operand type
        if node.kind == NodeKind.AddressOf {
            let operand_node: *Node = self.nodes + node.field0;
            let operand_type: i64 = self.inferExprType(operand_node);
            return self.type_pool.makePointer( operand_type);
        }
    
        // Dereference: return pointee type
        if node.kind == NodeKind.DerefExpr {
            let operand_node: *Node = self.nodes + node.field0;
            let ptr_type: i64 = self.inferExprType(operand_node);
            return TypeInfo_getPointee(self.type_pool, ptr_type);
        }
    
        // Call expression: look up function return type
        if node.kind == NodeKind.CallExpr {
            let callee_node: *Node = self.nodes + node.field0;
            if callee_node.kind == NodeKind.Ident {
                let ret_type: i64 = self.findFuncRetType(callee_node.field0, callee_node.field1);
                if ret_type >= 0 {
                    return ret_type;
                }
            }
            return TYPE_I64;
        }
    
        // Field access: look up field type
        if node.kind == NodeKind.FieldAccess {
            let base_node: *Node = self.nodes + node.field0;
            let base_type: i64 = self.inferExprType(base_node);
            let field_name_start: i64 = node.field1;
            let field_name_len: i64 = node.field2;
    
            // Get struct type (dereference if pointer)
            var struct_type_idx: i64 = base_type;
            if TypeInfo_isPointer(self.type_pool, base_type) {
                struct_type_idx = TypeInfo_getPointee(self.type_pool, base_type);
            }
    
            // Look up field type from TypeRegistry
            let field_info: *FieldInfo = self.type_pool.lookupField( struct_type_idx,
                                                                   self.source + field_name_start, field_name_len);
            if field_info != null {
                return field_info.type_idx;
            }
            return TYPE_I64;
        }
    
        // Index expression: return element type
        if node.kind == NodeKind.IndexExpr {
            let base_node: *Node = self.nodes + node.field0;
            let base_type: i64 = self.inferExprType(base_node);
    
            // For arrays/slices, get element type
            let elem_type: i64 = TypeInfo_elem(self.type_pool, base_type);
            if elem_type > 0 {
                return elem_type;
            }
            return TYPE_I64;
        }
    
        // Default to i64 for unknown expressions
        return TYPE_I64;
    }

    fn getPtrElemSize(self: *Lowerer, type_idx: i64) i64 {
        // Get the pointee type and return its size
        let pointee_idx: i64 = TypeInfo_getPointee(self.type_pool, type_idx);
        if pointee_idx <= 0 {
            // Not a valid pointer type, default to 8
            return 8;
        }
        let pointee_type: *Type = self.type_pool.get( pointee_idx);
        if pointee_type.size > 0 {
            return pointee_type.size;
        }
        // Default to 8 bytes (i64/pointer size)
        return 8;
    }

    fn lowerBinary(self: *Lowerer, node: *Node) i64 {
        // BinaryExpr fields:
        // field0 = left operand (node index)
        // field1 = right operand (node index)
        // field2 = op (BinaryOp as integer)
    
        let fb: *FuncBuilder = self.current_func;
    
        // Lower left and right operands
        let left_node: *Node = self.nodes + node.field0;
        let right_node: *Node = self.nodes + node.field1;
    
        // Check if left operand is a pointer type (for pointer arithmetic scaling)
        // This matches C/Zig semantics: ptr + n = ptr + n * sizeof(*ptr)
        let left_type: i64 = self.inferExprType(left_node);
        let is_ptr_arith: bool = TypeInfo_isPointer(self.type_pool, left_type);
        let ast_op: i64 = node.field2;  // BinaryOp as integer
        // Only scale for Add (0) or Sub (1) operations
        let is_add_or_sub: bool = ast_op == 0 or ast_op == 1;
    
        // String concatenation: string + string -> call __cot_str_concat
        // Following Zig pattern: src/frontend/lower.zig:1476-1484
        if left_type == TYPE_STRING and ast_op == 0 {
            return self.lowerStrConcat(left_node, right_node);
        }
    
        // Short-circuit evaluation for logical and/or
        // AST BinaryOp: And=11, Or=12
        // Must generate control flow to avoid evaluating right when unnecessary
        if ast_op == 11 or ast_op == 12 {
            return self.lowerLogicalBinary(left_node, right_node, ast_op);
        }
    
        // BUG-049 FIX: If right operand is a call, the left operand must be spilled
        // to stack before the call and loaded after. This is because function calls
        // clobber caller-saved registers (X0-X18), so any value in those registers
        // would be lost after the call returns.
        //
        // Pattern: for "n * factorial(n-1)":
        // 1. Lower left (n) into a register
        // 2. Spill n to temp local (survives across call)
        // 3. Lower right (factorial call)
        // 4. Load n back from temp local
        // 5. Emit binary operation with (loaded_n, call_result)
        let right_is_call: bool = right_node.kind == NodeKind.CallExpr;
    
        var final_left_idx: i64 = 0;
        var right_idx: i64 = 0;
    
        if right_is_call {
            // Lower left operand first
            let left_idx: i64 = self.lowerExpr(left_node);
    
            // Spill to temp local
            let temp_local: i64 = fb.addLocal( 0, 0, TYPE_I64, true);
            fb.emitStoreLocal( temp_local, left_idx);
    
            // Now lower right operand (the call)
            right_idx = self.lowerExpr(right_node);
    
            // Load left operand back from temp local
            final_left_idx = fb.emitLoadLocal( temp_local);
        } else {
            // No call on right side, no spilling needed
            final_left_idx = self.lowerExpr(left_node);
            right_idx = self.lowerExpr(right_node);
        }
    
        // Pointer arithmetic scaling: ptr + n -> ptr + n * elem_size
        // This matches Zig/C semantics for pointer arithmetic
        if is_ptr_arith and is_add_or_sub {
            let elem_size: i64 = self.getPtrElemSize(left_type);
            // Pointer arithmetic scaling debug removed for cleaner output
            let size_val: i64 = fb.emitConstInt( elem_size);
            right_idx = fb.emitBinary(IR_OP_MUL, right_idx, size_val, TYPE_I64);
        }
    
        // Convert AST operator to IR operator
        let ir_op: i64 = ASTOp_toIROp(ast_op);
    
        // Determine result type
        let result_type: i64 = TYPE_I64;
        if ASTOp_isComparison(ast_op) {
            result_type = TYPE_BOOL;
        }
    
        return fb.emitBinary(ir_op, final_left_idx, right_idx, result_type);
    }

    fn lowerLogicalBinary(self: *Lowerer, left_node: *Node, right_node: *Node, ast_op: i64) i64 {
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        let is_and: bool = ast_op == 11;  // And=11, Or=12
    
        // Step 1: Lower left operand
        let left_idx: i64 = self.lowerExpr(left_node);
    
        // Step 2: Create blocks for control flow
        let eval_right_block: i64 = fb.newBlock();
        let short_circuit_block: i64 = fb.newBlock();
        let merge_block: i64 = fb.newBlock();
    
        // Step 3: Create temp local to store result (survives across blocks)
        let result_local: i64 = fb.addLocal( 0, 0, TYPE_BOOL, true);
    
        // Step 4: Emit conditional branch based on left value
        if is_and {
            // For AND: if left is true, evaluate right; if false, short-circuit to false
            fb.emitBranch( left_idx, eval_right_block, short_circuit_block);
        } else {
            // For OR: if left is true, short-circuit to true; if false, evaluate right
            fb.emitBranch( left_idx, short_circuit_block, eval_right_block);
        }
    
        // Step 5: eval_right block - evaluate right operand
        fb.setBlock( eval_right_block);
        let right_idx: i64 = self.lowerExpr(right_node);
        fb.emitStoreLocal( result_local, right_idx);
        fb.emitJump( merge_block);
    
        // Step 6: short_circuit block - use constant value
        fb.setBlock( short_circuit_block);
        var short_val: i64 = 0;
        if is_and {
            short_val = fb.emitConstBool( false);  // AND short-circuits to false
        } else {
            short_val = fb.emitConstBool( true);   // OR short-circuits to true
        }
        fb.emitStoreLocal( result_local, short_val);
        fb.emitJump( merge_block);
    
        // Step 7: merge block - load result from temp local
        fb.setBlock( merge_block);
        let result_idx: i64 = fb.emitLoadLocal( result_local);
    
        return result_idx;
    }

    fn lowerStrConcat(self: *Lowerer, left_node: *Node, right_node: *Node) i64 {
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        // Extract ptr and len from left string
        var ptr1: i64 = 0;
        var len1: i64 = 0;
        self.extractStringPtrLen(left_node, &ptr1, &len1);
    
        // Extract ptr and len from right string
        var ptr2: i64 = 0;
        var len2: i64 = 0;
        self.extractStringPtrLen(right_node, &ptr2, &len2);
    
        // Build args list: [ptr1, len1, ptr2, len2]
        var args: I64List = undefined;
        i64list_init(&args);
        i64list_append(&args, ptr1);
        i64list_append(&args, len1);
        i64list_append(&args, ptr2);
        i64list_append(&args, len2);
    
        // Emit StrConcat IR node - becomes StringConcat SSA op
        // Following Zig: ssa_builder.zig:851-859 (creates string_concat value)
        var concat_node: IRNode = IRNode_new(IRNodeKind.StrConcat, TYPE_STRING);
        concat_node.call_args = args;  // Use call_args to store the 4 args
        return fb.emit( concat_node);
    }

    fn extractStringPtrLen(self: *Lowerer, node: *Node, out_ptr: *i64, out_len: *i64) {
        let fb: *FuncBuilder = self.current_func;
    
        // Case 1: Local variable - load ptr and len from fields
        if node.kind == NodeKind.Ident {
            let local_idx: i64 = self.findLocal(node.field0, node.field1);
            if local_idx >= 0 {
                // Load ptr from offset 0, len from offset 8
                out_ptr.* = fb.emitFieldLocal( local_idx, 0, TYPE_I64);
                out_len.* = fb.emitFieldLocal( local_idx, 8, TYPE_I64);
                return;
            }
        }
    
        // Case 2: String literal - emit ConstString for ptr, ConstInt for len
        if node.kind == NodeKind.StringLit {
            let str_start: i64 = node.field0;
            let source_len: i64 = node.field1;
            let actual_len: i64 = compute_escaped_length(self.source, str_start, source_len);
            out_ptr.* = fb.emitConstString( str_start, source_len);
            out_len.* = fb.emitConstInt( actual_len);
            return;
        }
    
        // Case 3: Other expressions (e.g., function call) - lower and use SlicePtr/SliceLen
        let expr_ir: i64 = self.lowerExpr(node);
        out_ptr.* = fb.emitSlicePtr( expr_ir, TYPE_I64);
        out_len.* = fb.emitSliceLen( expr_ir);
    }

    fn findLocal(self: *Lowerer, name_start: i64, name_len: i64) i64 {
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return -1; }
    
        var i: i64 = 0;
        while i < fb.locals_count {
            let local: *IRLocal = fb.locals + i;
            if names_equal(self.source, local.name_start, local.name_len, name_start, name_len) {
                return i;
            }
            i = i + 1;
        }
        return -1;
    }

    fn lowerUnary(self: *Lowerer, node: *Node) i64 {
        // UnaryExpr fields:
        // field0 = operand (node index)
        // field1 = op (UnaryOp as integer)
    
        let fb: *FuncBuilder = self.current_func;
    
        let operand_node: *Node = self.nodes + node.field0;
        let operand_idx: i64 = self.lowerExpr(operand_node);
    
        // Convert AST operator to IR operator
        let ir_op: i64 = ASTUnaryOp_toIROp(node.field1);
    
        return fb.emitUnary( ir_op, operand_idx, TYPE_I64);
    }

    fn lowerBuiltinLen(self: *Lowerer, node: *Node) i64 {
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        // CallExpr: field1 = args_start, field2 = args_count
        let args_start: i64 = node.field1;
        let args_count: i64 = node.field2;
        if args_count != 1 { return NULL_NODE; }
    
        // Get the argument node
        let arg_child_ptr: *i64 = self.children + args_start;
        let arg_node_idx: i64 = arg_child_ptr.*;
        let arg_node: *Node = self.nodes + arg_node_idx;
    
        // String literal: len("hello") -> const 5
        // Following Zig pattern: compute actual length after escape processing
        if arg_node.kind == NodeKind.StringLit {
            // StringLiteral: field0 = str_start, field1 = str_len (source positions)
            let str_start: i64 = arg_node.field0;
            let source_len: i64 = arg_node.field1;
            // Compute actual length after escape processing
            let actual_len: i64 = compute_escaped_length(self.source, str_start, source_len);
            return fb.emitConstInt( actual_len);
        }
    
        // String variable: len(s) -> access length field at offset 8
        // String struct layout: [ptr: *u8, len: i64]
        if arg_node.kind == NodeKind.Ident {
            // Look up local variable
            var local_idx: i64 = -1;
            var i: i64 = 0;
            while i < fb.locals_count {
                let local: *IRLocal = fb.locals + i;
                if names_equal(self.source, local.name_start, local.name_len,
                              arg_node.field0, arg_node.field1) {
                    local_idx = i;
                }
                i = i + 1;
            }
    
            if local_idx >= 0 {
                // Access length field at offset 8 (field index 1)
                return fb.emitFieldLocal( local_idx, 8, TYPE_I64);
            }
        }
    
        return NULL_NODE;
    }

    fn lowerBuiltinPrint(self: *Lowerer, node: *Node, is_println: bool) i64 {
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        // Find "write" in source - it must be declared as extern fn write(...)
        let write_pos: i64 = find_write_in_source(self.source, self.source_len);
        if write_pos < 0 {
            // write not found in source, fall through to regular call handling
            return NULL_NODE;
        }
    
        // CallExpr: field1 = args_start, field2 = args_count
        let args_start: i64 = node.field1;
        let args_count: i64 = node.field2;
        if args_count != 1 { return NULL_NODE; }
    
        // Get the argument node
        let arg_child_ptr: *i64 = self.children + args_start;
        let arg_node_idx: i64 = arg_child_ptr.*;
        let arg_node: *Node = self.nodes + arg_node_idx;
    
        // Lower the string argument
        let str_val: i64 = self.lowerExpr(arg_node);
    
        // Extract ptr and len from the string (following Zig's pattern)
        let ptr_val: i64 = fb.emitSlicePtr( str_val, TYPE_I64);
        let len_val: i64 = fb.emitSliceLen( str_val);
    
        // Create fd=1 (stdout) constant
        let fd_val: i64 = fb.emitConstInt( 1);
    
        // Build args for write call: write(fd, ptr, len)
        // Following Zig: args stored directly in Call node
        var call_node: IRNode = IRNode_new(IRNodeKind.Call, TYPE_I64);
        call_node.func_name_start = copy_func_name(self.source, write_pos, 5);  // Copy "write" to owned buffer
        call_node.func_name_len = 5;
        i64list_append(&call_node.call_args, fd_val);   // arg0: fd
        i64list_append(&call_node.call_args, ptr_val);  // arg1: ptr
        i64list_append(&call_node.call_args, len_val);  // arg2: len
        let write_result: i64 = fb.emit( call_node);
    
        // TODO: For println, also write a newline
        // For now, print and println behave the same (no trailing newline)
    
        return NULL_NODE;  // print/println returns void
    }

    fn lowerMethodCall(self: *Lowerer, call_node: *Node, field_access: *Node) i64 {
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        // Extract receiver and method name from FieldAccess
        let receiver_idx: i64 = field_access.field0;
        let method_name_start: i64 = field_access.field1;
        let method_name_len: i64 = field_access.field2;
        let receiver_node: *Node = self.nodes + receiver_idx;
    
        // Determine the receiver's struct type
        // Currently supports: Ident (local variable) and DerefExpr (pointer dereference)
        var type_name_start: i64 = -1;
        var type_name_len: i64 = 0;
        var receiver_is_pointer: bool = false;
    
        if receiver_node.kind == NodeKind.Ident {
            // Look up the local variable to get its type
            let recv_name_start: i64 = receiver_node.field0;
            let recv_name_len: i64 = receiver_node.field1;
    
            var local_idx: i64 = 0;
            while local_idx < fb.locals_count {
                let local: *IRLocal = fb.locals + local_idx;
                if names_equal(self.source, local.name_start, local.name_len, recv_name_start, recv_name_len) {
                    // Found the local - get its type info
                    let type_info: *Type = self.type_pool.get( local.type_idx);
                    if type_info != null {
                        if type_info.kind == TypeKind.Struct {
                            type_name_start = type_info.name_start;
                            type_name_len = type_info.name_len;
                            receiver_is_pointer = false;
                        } else if type_info.kind == TypeKind.Pointer {
                            // Pointer to struct
                            let pointee: *Type = self.type_pool.get( type_info.elem);
                            if pointee != null and pointee.kind == TypeKind.Struct {
                                type_name_start = pointee.name_start;
                                type_name_len = pointee.name_len;
                                receiver_is_pointer = true;
                            }
                        }
                    }
                }
                local_idx = local_idx + 1;
            }
        }
    
        // If we couldn't determine the type, this isn't a method call
        if type_name_start < 0 {
            return NULL_NODE;
        }
    
        // Look up the method in the registry
        let method_entry: *MethodEntry = self.lookupMethod(type_name_start, type_name_len,
            method_name_start, method_name_len);
    
        if method_entry == null {
            // Not a registered method - fall back to regular field access (error later)
            return NULL_NODE;
        }
    
        // Found the method - emit call to synthesized name
        // First, lower the receiver expression
        var receiver_val: i64 = 0;
        if receiver_is_pointer {
            // Already a pointer, just lower the expression
            receiver_val = self.lowerExpr(receiver_node);
        } else {
            // Need to take address of receiver
            receiver_val = self.lowerAddressOfExpr(receiver_node);
        }
    
        // Get original call arguments
        let args_start: i64 = call_node.field1;
        let args_count: i64 = call_node.field2;
    
        // Create the call node with synthesized name
        var ir_node: IRNode = IRNode_new(IRNodeKind.Call, TYPE_I64);
        ir_node.func_name_start = method_entry.synth_name_ptr;
        ir_node.func_name_len = method_entry.synth_name_len;
    
        // Add receiver as first argument
        i64list_append(&ir_node.call_args, receiver_val);
    
        // Add original arguments
        var i: i64 = 0;
        while i < args_count {
            let arg_ptr: *i64 = self.children + args_start + i;
            let arg_node_idx: i64 = arg_ptr.*;
            let arg_node: *Node = self.nodes + arg_node_idx;
            let arg_val: i64 = self.lowerExpr(arg_node);
            i64list_append(&ir_node.call_args, arg_val);
            i = i + 1;
        }
    
        return fb.emit( ir_node);
    }

    fn lowerAddressOfExpr(self: *Lowerer, node: *Node) i64 {
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        // For an Ident node, get the local and take its address
        if node.kind == NodeKind.Ident {
            let name_start: i64 = node.field0;
            let name_len: i64 = node.field1;
    
            // Find the local
            var local_idx: i64 = 0;
            while local_idx < fb.locals_count {
                let local: *IRLocal = fb.locals + local_idx;
                if names_equal(self.source, local.name_start, local.name_len, name_start, name_len) {
                    // Found - emit local address
                    return fb.emitAddrLocal( local_idx, TYPE_I64);
                }
                local_idx = local_idx + 1;
            }
        }
    
        // For other expressions, lower and hope for the best
        // (This is a fallback - may need more cases)
        return self.lowerExpr(node);
    }

    fn lowerCall(self: *Lowerer, node: *Node) i64 {
        // CallExpr fields:
        // field0 = callee (node index)
        // field1 = args_start (index in children array)
        // field2 = args_count
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        // Get callee - can be identifier or method call (FieldAccess)
        let callee_node: *Node = self.nodes + node.field0;
    
        // cot1: Handle method call syntax (obj.method())
        // Transform obj.method(args) -> TypeName_method(&obj, args) or (obj, args) if already pointer
        if callee_node.kind == NodeKind.FieldAccess {
            return self.lowerMethodCall(node, callee_node);
        }
    
        if callee_node.kind != NodeKind.Ident {
            return NULL_NODE;  // Only simple function calls supported
        }
    
        let func_name_start: i64 = callee_node.field0;
        let func_name_len: i64 = callee_node.field1;
        let args_start: i64 = node.field1;
        let args_count: i64 = node.field2;
    
        // Handle builtin functions
        // Following Zig pattern: src/frontend/lower.zig:1848-1856
        if name_is_len(self.source, func_name_start, func_name_len) {
            return self.lowerBuiltinLen(node);
        }
        if name_is_print(self.source, func_name_start, func_name_len) {
            let result: i64 = self.lowerBuiltinPrint(node, false);
            if result != NULL_NODE or find_write_in_source(self.source, self.source_len) >= 0 {
                return result;  // Successfully handled or write found
            }
            // Fall through to regular call if write not in source
        }
        if name_is_println(self.source, func_name_start, func_name_len) {
            let result: i64 = self.lowerBuiltinPrint(node, true);
            if result != NULL_NODE or find_write_in_source(self.source, self.source_len) >= 0 {
                return result;  // Successfully handled or write found
            }
            // Fall through to regular call if write not in source
        }
    
        // Determine direct vs indirect call (Go: ClosureCall vs OCALL)
        // Following Zig pattern: src/frontend/lower.zig:1867-1884
        // - Direct call: callee is a function name
        // - Indirect call: callee is a local variable holding a function pointer
        var is_indirect_call: bool = false;
        var fn_ptr_local_idx: i64 = -1;
        var fn_ptr_return_type: i64 = TYPE_I64;
    
        // Check if callee identifier is a local variable with function type
        var local_check_idx: i64 = 0;
        while local_check_idx < fb.locals_count {
            let local: *IRLocal = fb.locals + local_check_idx;
            if names_equal(self.source, local.name_start, local.name_len, func_name_start, func_name_len) {
                // Found as a local variable - check if it's a function pointer type
                if TypeInfo_isFunc(self.type_pool, local.type_idx) {
                    is_indirect_call = true;
                    fn_ptr_local_idx = local_check_idx;
                    fn_ptr_return_type = TypeInfo_ret(self.type_pool, local.type_idx);
                }
            }
            local_check_idx = local_check_idx + 1;
        }
    
        // Two-pass approach to handle nested calls:
        // Pass 0: Pre-scan to check if ANY argument contains a call
        // Pass 1: Lower all arguments. If any arg is a call, store ALL arg results to temp locals
        //         (not just call results - earlier args would be clobbered by later calls)
        // Pass 2: Load from temp locals if we had any calls, then emit the main call
        //
        // This ensures loads happen AFTER all nested calls have completed.
        // Following the Zig compiler pattern (src/ssa/regalloc.zig): values need to
        // survive across calls by being spilled to stack, not held in caller-saved regs.
    
        // Pass 0: Pre-scan for any calls among arguments
        var has_any_call: bool = false;
        var pre_i: i64 = 0;
        while pre_i < args_count {
            let pre_arg_ptr: *i64 = self.children + args_start + pre_i;
            let pre_arg_idx: i64 = pre_arg_ptr.*;
            let pre_arg_node: *Node = self.nodes + pre_arg_idx;
            if pre_arg_node.kind == NodeKind.CallExpr {
                has_any_call = true;
            }
            pre_i = pre_i + 1;
        }
    
        // Track state for args using dynamic lists
        var arg_ir: I64List = undefined;
        var arg_local: I64List = undefined;
        i64list_init(&arg_ir);
        i64list_init(&arg_local);
    
        // Pass 1: Lower all arguments
        // If ANY arg is a call, store ALL arg results to temp locals
        var i: i64 = 0;
        while i < args_count {
            let arg_child_ptr: *i64 = self.children + args_start + i;
            let arg_node_idx: i64 = arg_child_ptr.*;
            let arg_node: *Node = self.nodes + arg_node_idx;
            let arg_ir_idx: i64 = self.lowerExpr(arg_node);
    
            i64list_append(&arg_ir, arg_ir_idx);
            if has_any_call {
                // Store ALL arguments to temp locals when any call exists
                // This prevents earlier args from being clobbered by later calls
                let local_idx: i64 = fb.addLocal( 0, 0, TYPE_I64, true);
                i64list_append(&arg_local, local_idx);
                fb.emitStoreLocal( local_idx, arg_ir_idx);
            } else {
                i64list_append(&arg_local, -1);
            }
    
            i = i + 1;
        }
    
        // Pass 2: Load from temp locals if we had any calls, build final args list
        // Following Zig: args stored directly in Call node (c.args slice)
        var final_args: I64List = undefined;
        i64list_init(&final_args);
    
        i = 0;
        while i < args_count {
            var final_arg_idx: i64 = i64list_get(&arg_ir, i);
            let local_idx: i64 = i64list_get(&arg_local, i);
            if has_any_call and local_idx >= 0 {
                final_arg_idx = fb.emitLoadLocal( local_idx);
            }
    
            // Store directly in final_args list (matches Zig pattern)
            i64list_append(&final_args, final_arg_idx);
    
            i = i + 1;
        }
    
        i64list_deinit(&arg_ir);
        i64list_deinit(&arg_local);
    
        // Emit Call or CallIndirect IR node
        // Following Zig pattern: src/frontend/lower.zig:1867-1906
        if is_indirect_call {
            // Indirect call through function pointer
            // Load the function pointer from local variable
            let fn_ptr_expr: i64 = fb.emitLoadLocal( fn_ptr_local_idx);
            // Emit indirect call with args stored directly
            var call_node: IRNode = IRNode_new(IRNodeKind.CallIndirect, fn_ptr_return_type);
            call_node.left = fn_ptr_expr;
            call_node.call_args = final_args;  // Transfer ownership
            return fb.emit( call_node);
        }
    
        // Direct call to named function
    
        // BUG-054: Look up the called function's return type for hidden return detection
        // This enables the codegen to detect calls returning >16B structs
        var call_ret_type: i64 = TYPE_I64;  // Default fallback
        let ret_type_handle: i64 = self.findFuncRetType(func_name_start, func_name_len);
        if ret_type_handle >= 0 {
            call_ret_type = resolve_type_expr(self, ret_type_handle);
            if call_ret_type < 0 {
                call_ret_type = TYPE_I64;  // Fallback if resolution fails
            }
        }
    
        var call_node: IRNode = IRNode_new(IRNodeKind.Call, call_ret_type);
        call_node.func_name_start = copy_func_name(self.source, func_name_start, func_name_len);
        call_node.func_name_len = func_name_len;
        call_node.call_args = final_args;  // Transfer ownership (matches Zig's c.args)
        return fb.emit( call_node);
    }

    fn lowerAssign(self: *Lowerer, node: *Node) i64 {
        // AssignExpr fields:
        // field0 = target (identifier node or deref expr)
        // field1 = value (expression)
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        let target_node: *Node = self.nodes + node.field0;
    
        // Lower the value expression first
        let value_node: *Node = self.nodes + node.field1;
        let value_idx: i64 = self.lowerExpr(value_node);
    
        // Handle assignment to dereferenced pointer: ptr.* = value
        if target_node.kind == NodeKind.DerefExpr {
            // Lower the pointer expression
            let ptr_operand: *Node = self.nodes + target_node.field0;
            let ptr_idx: i64 = self.lowerExpr(ptr_operand);
    
            // Emit store through pointer
            fb.emitStore( ptr_idx, value_idx);
            return value_idx;
        }
    
        // Handle field assignment: s.x = value or ptr.*.x = value
        if target_node.kind == NodeKind.FieldAccess {
            return self.lowerFieldAssign(target_node, value_idx);
        }
    
        // Handle array element assignment: arr[i] = value
        if target_node.kind == NodeKind.IndexExpr {
            return self.lowerIndexAssign(target_node, value_idx);
        }
    
        // Handle simple variable assignment: x = value
        // Following Zig: src/frontend/lower.zig:640-658 (assignment to identifier)
        if target_node.kind == NodeKind.Ident {
            // Look up local variable by name
            var local_idx: i64 = -1;
            var i: i64 = 0;
            while i < fb.locals_count {
                let local: *IRLocal = fb.locals + i;
                if names_equal(self.source, local.name_start, local.name_len, target_node.field0, target_node.field1) {
                    local_idx = i;
                }
                i = i + 1;
            }
    
            if local_idx >= 0 {
                // Check if this is a string assignment - need to store ptr and len separately
                let local: *IRLocal = fb.locals + local_idx;
                if local.type_idx == TYPE_STRING or local.type_idx == TYPE_SLICE {
                    // String/slice assignment: need to store ptr at offset 0, len at offset 8
                    // Check value expression type to determine how to extract ptr/len
                    if value_node.kind == NodeKind.StringLit {
                        // String literal: emit ConstString for ptr, ConstInt for len
                        let str_start: i64 = value_node.field0;
                        let source_len: i64 = value_node.field1;
                        let actual_len: i64 = compute_escaped_length(self.source, str_start, source_len);
                        let ptr_ir: i64 = fb.emitConstString( str_start, source_len);
                        let len_ir: i64 = fb.emitConstInt( actual_len);
                        fb.emitStoreFieldLocal( local_idx, 0, ptr_ir);
                        fb.emitStoreFieldLocal( local_idx, 8, len_ir);
                    } else if value_node.kind == NodeKind.Ident {
                        // Another string variable: copy ptr and len from source
                        let src_local_idx: i64 = self.findLocal(value_node.field0, value_node.field1);
                        if src_local_idx >= 0 {
                            let ptr_ir: i64 = fb.emitFieldLocal( src_local_idx, 0, TYPE_I64);
                            let len_ir: i64 = fb.emitFieldLocal( src_local_idx, 8, TYPE_I64);
                            fb.emitStoreFieldLocal( local_idx, 0, ptr_ir);
                            fb.emitStoreFieldLocal( local_idx, 8, len_ir);
                        } else {
                            // Fallback: use SlicePtr/SliceLen on lowered value
                            let ptr_ir: i64 = fb.emitSlicePtr( value_idx, TYPE_I64);
                            let len_ir: i64 = fb.emitSliceLen( value_idx);
                            fb.emitStoreFieldLocal( local_idx, 0, ptr_ir);
                            fb.emitStoreFieldLocal( local_idx, 8, len_ir);
                        }
                    } else {
                        // Other expressions (call result, concat result, etc.)
                        let ptr_ir: i64 = fb.emitSlicePtr( value_idx, TYPE_I64);
                        let len_ir: i64 = fb.emitSliceLen( value_idx);
                        fb.emitStoreFieldLocal( local_idx, 0, ptr_ir);
                        fb.emitStoreFieldLocal( local_idx, 8, len_ir);
                    }
                    return value_idx;
                }
                // Non-string: simple store
                fb.emitStoreLocal( local_idx, value_idx);
                return value_idx;
            }
    
            // Not a local - check for global variable
            // Following Zig: src/frontend/lower.zig:640-658 (lookupGlobal then emitGlobalStore)
            let global_idx: i64 = self.lookupGlobal(target_node.field0, target_node.field1);
            if global_idx >= 0 {
                let g: *IRGlobal = self.ir_globals + global_idx;
                fb.emitStoreGlobal( global_idx, value_idx, g.type_idx);
                return value_idx;
            }
    
            return NULL_NODE;  // Variable not found
        }
    
        return NULL_NODE;  // Unsupported assignment target
    }

    fn lowerAddressOf(self: *Lowerer, node: *Node) i64 {
        // AddressOf fields:
        // field0 = operand (the expression to take address of)
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        let operand_node: *Node = self.nodes + node.field0;
    
        // Handle address of index expressions: &array[index]
        // Result = base_addr + index * elem_size
        if operand_node.kind == NodeKind.IndexExpr {
            // IndexExpr: field0 = base, field1 = index
            let base_node: *Node = self.nodes + operand_node.field0;
            let index_node: *Node = self.nodes + operand_node.field1;
    
            // Lower the index expression
            let index_ir: i64 = self.lowerExpr(index_node);
    
            // For cot0, assume element type is u8/i8 (1 byte) when taking address
            let elem_size: i64 = 1;
    
            // Get base address - check local first, then global
            if base_node.kind == NodeKind.Ident {
                // Try local variable first
                var local_idx: i64 = -1;
                var i: i64 = 0;
                while i < fb.locals_count {
                    let local: *IRLocal = fb.locals + i;
                    if names_equal(self.source, local.name_start, local.name_len,
                                  base_node.field0, base_node.field1) {
                        local_idx = i;
                    }
                    i = i + 1;
                }
    
                if local_idx >= 0 {
                    let base_addr: i64 = fb.emitAddrLocal( local_idx, TYPE_I64);
                    let size_val: i64 = fb.emitConstInt( elem_size);
                    let offset_val: i64 = fb.emitBinary(IR_OP_MUL, index_ir, size_val, TYPE_I64);
                    return fb.emitBinary(IR_OP_ADD, base_addr, offset_val, TYPE_I64);
                }
    
                // Try global variable
                let global_idx: i64 = self.lookupGlobal(base_node.field0, base_node.field1);
                if global_idx >= 0 {
                    let base_addr: i64 = fb.emitAddrGlobal( global_idx, TYPE_I64);
                    let size_val: i64 = fb.emitConstInt( elem_size);
                    let offset_val: i64 = fb.emitBinary(IR_OP_MUL, index_ir, size_val, TYPE_I64);
                    return fb.emitBinary(IR_OP_ADD, base_addr, offset_val, TYPE_I64);
                }
            }
        }
    
        // Handle address of field access: &outer.inner
        // Result = address_of(base) + field_offset
        if operand_node.kind == NodeKind.FieldAccess {
            // FieldAccess: field0 = base, field1 = field_name_start, field2 = field_name_len
            let base_node: *Node = self.nodes + operand_node.field0;
            let field_name_start: i64 = operand_node.field1;
            let field_name_len: i64 = operand_node.field2;
    
            // Base must be an identifier (local variable)
            if base_node.kind == NodeKind.Ident {
                // Look up the local variable
                var local_idx: i64 = -1;
                var local_type_idx: i64 = TYPE_I64;
                var i: i64 = 0;
                while i < fb.locals_count {
                    let local: *IRLocal = fb.locals + i;
                    if names_equal(self.source, local.name_start, local.name_len,
                                  base_node.field0, base_node.field1) {
                        local_idx = i;
                        local_type_idx = local.type_idx;
                    }
                    i = i + 1;
                }
    
                if local_idx >= 0 {
                    // Look up field offset in the struct type
                    let field_info: *FieldInfo = self.type_pool.lookupField( local_type_idx,
                                                                   self.source + field_name_start, field_name_len);
                    if field_info != null {
                        // Get address of local + field offset
                        let base_addr: i64 = fb.emitAddrLocal( local_idx, TYPE_I64);
                        if field_info.offset == 0 {
                            return base_addr;
                        }
                        let offset_val: i64 = fb.emitConstInt( field_info.offset);
                        return fb.emitBinary(IR_OP_ADD, base_addr, offset_val, TYPE_I64);
                    }
    
                    // Fallback: use struct type info from the local variable if available
                    let local: *IRLocal = fb.locals + local_idx;
                    if local.struct_type_start >= 0 {
                        let struct_type_idx: i64 = self.type_pool.lookupByName( self.source,
                                                                              local.struct_type_start, local.struct_type_len);
                        if struct_type_idx > 0 {
                            let field_info: *FieldInfo = self.type_pool.lookupField( struct_type_idx,
                                                                                   self.source + field_name_start, field_name_len);
                            if field_info != null {
                                let base_addr: i64 = fb.emitAddrLocal( local_idx, TYPE_I64);
                                if field_info.offset == 0 {
                                    return base_addr;
                                }
                                let offset_val: i64 = fb.emitConstInt( field_info.offset);
                                return fb.emitBinary(IR_OP_ADD, base_addr, offset_val, TYPE_I64);
                            }
                        }
                    }
    
                    // Last resort: return base address without offset (field at offset 0)
                    return fb.emitAddrLocal( local_idx, TYPE_I64);
                }
    
                // Try global variable (Zig: lower.zig:1270-1289)
                // Handle &global.field
                let global_idx: i64 = self.lookupGlobal(base_node.field0, base_node.field1);
                if global_idx >= 0 {
                    // Get the global's type index
                    let global: *IRGlobal = self.ir_globals + global_idx;
                    let global_type_idx: i64 = global.type_idx;
    
                    // Look up field offset in the struct type
                    let field_info: *FieldInfo = self.type_pool.lookupField( global_type_idx,
                                                                   self.source + field_name_start, field_name_len);
                    if field_info != null {
                        // Get address of global + field offset
                        let base_addr: i64 = fb.emitAddrGlobal( global_idx, TYPE_I64);
                        if field_info.offset == 0 {
                            return base_addr;
                        }
                        let offset_val: i64 = fb.emitConstInt( field_info.offset);
                        return fb.emitBinary(IR_OP_ADD, base_addr, offset_val, TYPE_I64);
                    }
    
                    // Last resort: return global address without offset (field at offset 0)
                    return fb.emitAddrGlobal( global_idx, TYPE_I64);
                }
            }
        }
    
        // Handle address of identifiers (local or global variables)
        if operand_node.kind == NodeKind.Ident {
            // Look up local variable by name first
            var i: i64 = 0;
            while i < fb.locals_count {
                let local: *IRLocal = fb.locals + i;
                if names_equal(self.source, local.name_start, local.name_len,
                              operand_node.field0, operand_node.field1) {
                    // Emit address of local - type is *i64 for now (TYPE_I64 + some offset for ptr)
                    return fb.emitAddrLocal( i, TYPE_I64);
                }
                i = i + 1;
            }
    
            // Try global variable
            let global_idx: i64 = self.lookupGlobal(operand_node.field0, operand_node.field1);
            if global_idx >= 0 {
                return fb.emitAddrGlobal( global_idx, TYPE_I64);
            }
        }
    
        return NULL_NODE;
    }

    fn lowerDeref(self: *Lowerer, node: *Node) i64 {
        // DerefExpr fields:
        // field0 = operand (the pointer expression)
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        // Lower the pointer expression
        let operand_node: *Node = self.nodes + node.field0;
        let ptr_idx: i64 = self.lowerExpr(operand_node);
    
        // Use Lowerer_inferExprType to get the pointee type
        // This handles all cases: simple identifiers, pointer arithmetic, etc.
        let result_type: i64 = self.inferExprType(node);
    
        // Emit load from pointer with the correct pointee type
        return fb.emitLoad( ptr_idx, result_type);
    }

    fn lowerFieldAccess(self: *Lowerer, node: *Node) i64 {
        // FieldAccess fields:
        // field0 = base expression (node index)
        // field1 = field_name_start (offset in source)
        // field2 = field_name_len
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        let base_node: *Node = self.nodes + node.field0;
        let field_name_start: i64 = node.field1;
        let field_name_len: i64 = node.field2;
    
        // Check for enum variant access first (e.g., Status.Active)
        // Following Zig's pattern (lower.zig:1510-1519)
        if base_node.kind == NodeKind.Ident {
            // Try to look up as enum variant
            let enum_name_start: i64 = base_node.field0;
            let enum_name_len: i64 = base_node.field1;
            let variant_value: i64 = self.lookupEnumVariant(enum_name_start, enum_name_len,
                                                               field_name_start, field_name_len);
            if variant_value >= 0 {
                // Found enum variant, emit as constant
                return fb.emitConstInt( variant_value);
            }
        }
    
        // Case 1: Base is an identifier (local variable or parameter)
        if base_node.kind == NodeKind.Ident {
            // Look up the local variable
            var local_idx: i64 = -1;
            var local_type_idx: i64 = TYPE_I64;
            var i: i64 = 0;
            while i < fb.locals_count {
                let local: *IRLocal = fb.locals + i;
                if names_equal(self.source, local.name_start, local.name_len,
                              base_node.field0, base_node.field1) {
                    local_idx = i;
                    local_type_idx = local.type_idx;
                }
                i = i + 1;
            }
    
            if local_idx < 0 {
                return NULL_NODE;  // Variable not found
            }
    
            // Check if local is a pointer to struct (auto-dereference)
            let local_type: *Type = self.type_pool.get( local_type_idx);
            var struct_type_idx: i64 = local_type_idx;
    
            // Special handling for slice/string types: .ptr (offset 0) and .len (offset 8)
            // Check TYPE_SLICE, TYPE_STRING, TypeKind.Slice, and TypeKind.String
            var is_slice: bool = local_type_idx == TYPE_SLICE or local_type_idx == TYPE_STRING;
            if local_type != null {
                if local_type.kind == TypeKind.Slice or local_type.kind == TypeKind.String {
                    is_slice = true;
                }
            }
            if is_slice {
                if name_is_ptr(self.source, field_name_start, field_name_len) {
                    return fb.emitFieldLocal( local_idx, 0, TYPE_I64);
                }
                if name_is_len(self.source, field_name_start, field_name_len) {
                    return fb.emitFieldLocal( local_idx, 8, TYPE_I64);
                }
                // Unknown slice field
                return NULL_NODE;
            }
    
            if local_type.kind == TypeKind.Pointer {
                // Pointer to struct - need to load the pointer first
                struct_type_idx = local_type.elem;
    
                // Look up field in the pointee struct
                let field_info: *FieldInfo = self.type_pool.lookupField( struct_type_idx,
                                                               self.source + field_name_start, field_name_len);
                if field_info != null {
                    // Load the pointer value
                    let ptr_val: i64 = fb.emitLoadLocal( local_idx);
                    // Access field through the pointer
                    return fb.emitFieldValue( ptr_val, field_info.offset, field_info.type_idx);
                }
    
                // Fallback: use TypeRegistry with local's struct type info
                let local: *IRLocal = fb.locals + local_idx;
                if local.struct_type_start >= 0 {
                    let local_struct_type: i64 = self.type_pool.lookupByName( self.source,
                                                                            local.struct_type_start, local.struct_type_len);
                    if local_struct_type > 0 {
                        let local_field_info: *FieldInfo = self.type_pool.lookupField( local_struct_type,
                                                                                     self.source + field_name_start, field_name_len);
                        if local_field_info != null {
                            // Load the pointer value
                            let ptr_val: i64 = fb.emitLoadLocal( local_idx);
                            // Access field through the pointer
                            return fb.emitFieldValue( ptr_val, local_field_info.offset, local_field_info.type_idx);
                        }
                    }
                }
    
                // Return NULL_NODE if field not found by any method
                return NULL_NODE;
            }
    
            // Direct struct access
            let field_info: *FieldInfo = self.type_pool.lookupField( struct_type_idx,
                                                           self.source + field_name_start, field_name_len);
            if field_info != null {
                return fb.emitFieldLocal( local_idx, field_info.offset, field_info.type_idx);
            }
    
            // Fallback: use TypeRegistry with local's struct type info
            let local: *IRLocal = fb.locals + local_idx;
            if local.struct_type_start >= 0 {
                let local_struct_type: i64 = self.type_pool.lookupByName( self.source,
                                                                        local.struct_type_start, local.struct_type_len);
                if local_struct_type > 0 {
                    let local_field_info: *FieldInfo = self.type_pool.lookupField( local_struct_type,
                                                                                 self.source + field_name_start, field_name_len);
                    if local_field_info != null {
                        return fb.emitFieldLocal( local_idx, local_field_info.offset, local_field_info.type_idx);
                    }
                }
            }
            // Last resort fallback: offset 0 (should rarely happen now)
            return fb.emitFieldLocal( local_idx, 0, TYPE_I64);
        }
    
        // Case 2: Base is a dereference expression (ptr.*.field)
        // Following Go's ODOTPTR and Zig's lower.zig pattern:
        // Get pointer value, look up field offset in pointee struct, emit FieldValue
        if base_node.kind == NodeKind.DerefExpr {
            // Get the pointer value without loading the struct
            let ptr_operand: *Node = self.nodes + base_node.field0;
            let ptr_val: i64 = self.lowerExpr(ptr_operand);
    
            // Try to find struct type from the pointer local's info
            var field_offset: i64 = 0;
            if ptr_operand.kind == NodeKind.Ident {
                // Look up the pointer local to get its struct type info
                var i: i64 = 0;
                while i < fb.locals_count {
                    let local: *IRLocal = fb.locals + i;
                    if names_equal(self.source, local.name_start, local.name_len,
                                  ptr_operand.field0, ptr_operand.field1) {
                        // Found the pointer local - check if it has struct type info
                        if local.struct_type_start >= 0 {
                            // Use TypeRegistry to find field offset
                            let local_struct_type: i64 = self.type_pool.lookupByName( self.source,
                                                                                    local.struct_type_start, local.struct_type_len);
                            if local_struct_type > 0 {
                                let info: *FieldInfo = self.type_pool.lookupField( local_struct_type,
                                                                                 self.source + field_name_start, field_name_len);
                                if info != null {
                                    field_offset = info.offset;
                                }
                            }
                        }
                        break;
                    }
                    i = i + 1;
                }
            }
    
            return fb.emitFieldValue( ptr_val, field_offset, TYPE_I64);
        }
    
        // Case 3: Base is another field access (chained: a.b.c)
        // BUG-051 FIX: Use AST-based lookup (no checker/type pool dependency)
        // For o.inner.a: base_node is o.inner, field_name is "a"
        if base_node.kind == NodeKind.FieldAccess {
            var total_offset: i64 = 0;
            var root_local_idx: i64 = -1;
    
            // Walk up the field access chain to find root local
            var walk_node: *Node = base_node;
            var depth: i64 = 0;
            while walk_node.kind == NodeKind.FieldAccess and depth < 10 {
                walk_node = self.nodes + walk_node.field0;
                depth = depth + 1;
            }
    
            // Check if root is a local variable identifier
            if walk_node.kind == NodeKind.Ident {
                var i: i64 = 0;
                while i < fb.locals_count {
                    let local: *IRLocal = fb.locals + i;
                    if names_equal(self.source, local.name_start, local.name_len,
                                  walk_node.field0, walk_node.field1) {
                        root_local_idx = i;
    
                        // Use TypeRegistry lookup with struct_type_start/len
                        if local.struct_type_start >= 0 {
                            let root_struct_type: i64 = self.type_pool.lookupByName( self.source,
                                                                                   local.struct_type_start, local.struct_type_len);
                            if root_struct_type > 0 {
                                // Get base field info (e.g., "inner" in o.inner)
                                let base_field_name_start: i64 = base_node.field1;
                                let base_field_name_len: i64 = base_node.field2;
    
                                // Look up base field in root's struct type
                                let base_info: *FieldInfo = self.type_pool.lookupField( root_struct_type,
                                                                                      self.source + base_field_name_start, base_field_name_len);
    
                                if base_info != null and base_info.type_idx > 0 {
                                    total_offset = base_info.offset;
    
                                    // Look up final field in nested struct type
                                    let final_info: *FieldInfo = self.type_pool.lookupField( base_info.type_idx,
                                                                                           self.source + field_name_start, field_name_len);
    
                                    if final_info != null {
                                        total_offset = total_offset + final_info.offset;
                                        // BUG FIX: Check if root local is a pointer type
                                        // For pointers: load pointer, then access field through it
                                        // For values: access field directly from local
                                        let root_local: *IRLocal = fb.locals + root_local_idx;
                                        let root_type: *Type = self.type_pool.get( root_local.type_idx);
                                        if root_type != null and root_type.kind == TypeKind.Pointer {
                                            // Pointer to struct - load the pointer first
                                            let ptr_val: i64 = fb.emitLoadLocal( root_local_idx);
                                            return fb.emitFieldValue( ptr_val, total_offset, TYPE_I64);
                                        }
                                        return fb.emitFieldLocal( root_local_idx, total_offset, TYPE_I64);
                                    }
                                }
                            }
                        }
                    }
                    i = i + 1;
                }
            }
    
            // Fallback: Use TypeRegistry to look up field in base's type
            var base_struct_type_idx: i64 = -1;
    
            // Walk the base field access to find its type
            if walk_node.kind == NodeKind.Ident and root_local_idx >= 0 {
                let local: *IRLocal = fb.locals + root_local_idx;
                if local.struct_type_start >= 0 {
                    let root_struct_type: i64 = self.type_pool.lookupByName( self.source,
                                                                           local.struct_type_start, local.struct_type_len);
                    if root_struct_type > 0 {
                        // Look up the base field (e.g., "inner" in outer.inner)
                        let base_field_name_start: i64 = base_node.field1;
                        let base_field_name_len: i64 = base_node.field2;
                        let base_info: *FieldInfo = self.type_pool.lookupField( root_struct_type,
                                                                              self.source + base_field_name_start, base_field_name_len);
                        if base_info != null {
                            base_struct_type_idx = base_info.type_idx;
                        }
                    }
                }
            }
    
            // Now look up the final field in the base's struct type
            var final_offset: i64 = 0;
            if base_struct_type_idx > 0 {
                let final_info: *FieldInfo = self.type_pool.lookupField( base_struct_type_idx,
                                                                       self.source + field_name_start, field_name_len);
                if final_info != null {
                    final_offset = final_info.offset;
                }
            }
    
            // Lower the base expression and access the field at computed offset
            let base_val: i64 = self.lowerFieldAccess(base_node);
            return fb.emitFieldValue( base_val, final_offset, TYPE_I64);
        }
    
        // Case 4: Base is an IndexExpr (arr[i].field)
        // Need to compute element address and load at field offset
        if base_node.kind == NodeKind.IndexExpr {
            let array_node: *Node = self.nodes + base_node.field0;
            let index_node: *Node = self.nodes + base_node.field1;
    
            // Lower the index expression
            let index_ir: i64 = self.lowerExpr(index_node);
    
            if array_node.kind == NodeKind.Ident {
                // Look up the array local
                var local_idx: i64 = -1;
                var local_type_idx: i64 = TYPE_I64;
                var i: i64 = 0;
                while i < fb.locals_count {
                    let local: *IRLocal = fb.locals + i;
                    if names_equal(self.source, local.name_start, local.name_len,
                                  array_node.field0, array_node.field1) {
                        local_idx = i;
                        local_type_idx = local.type_idx;
                    }
                    i = i + 1;
                }
    
                if local_idx >= 0 {
                    // Get array element type and size from TypeRegistry
                    var elem_size: i64 = 8;  // Default to i64
                    var elem_type_idx: i64 = TYPE_I64;
                    var field_type_idx: i64 = TYPE_I64;
                    let local_type: *Type = self.type_pool.get( local_type_idx);
                    if local_type != null and local_type.kind == TypeKind.Array {
                        elem_type_idx = local_type.elem;
                        elem_size = self.type_pool.sizeof( elem_type_idx);
                    }
    
                    // Get field offset within the element struct
                    var field_offset: i64 = 0;
                    let field_info: *FieldInfo = self.type_pool.lookupField( elem_type_idx,
                                                                           self.source + field_name_start, field_name_len);
                    if field_info != null {
                        field_offset = field_info.offset;
                        field_type_idx = field_info.type_idx;
                    }
    
                    // Compute element address: base_addr + index * elem_size
                    let base_addr: i64 = fb.emitAddrLocal( local_idx, TYPE_I64);
                    let size_val: i64 = fb.emitConstInt( elem_size);
                    let offset_val: i64 = fb.emitBinary(IR_OP_MUL, index_ir, size_val, TYPE_I64);
                    let elem_addr: i64 = fb.emitBinary(IR_OP_ADD, base_addr, offset_val, TYPE_I64);
    
                    // Load from field offset within element
                    return fb.emitFieldValue( elem_addr, field_offset, field_type_idx);
                }
            }
        }
    
        // Case 4b: String literal with .ptr or .len access
        // When "Hi".ptr is used directly, emit SlicePtr(ConstString) not FieldValue
        if base_node.kind == NodeKind.StringLit {
            let base_val: i64 = self.lowerExpr(base_node);
            if name_is_ptr(self.source, field_name_start, field_name_len) {
                return fb.emitSlicePtr( base_val, TYPE_I64);
            }
            if name_is_len(self.source, field_name_start, field_name_len) {
                return fb.emitSliceLen( base_val);
            }
        }
    
        // Case 5: Other expressions - lower them and access field at offset 0
        let base_val: i64 = self.lowerExpr(base_node);
        return fb.emitFieldValue( base_val, 0, TYPE_I64);
    }

    fn lowerIndex(self: *Lowerer, node: *Node) i64 {
        // IndexExpr fields:
        // field0 = base expression (array/pointer)
        // field1 = index expression
        //
        // Following src/frontend/lower.zig:1623-1712 (lowerIndex)
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        let base_node: *Node = self.nodes + node.field0;
        let index_node_idx: i64 = node.field1;
    
        // For cot0, assume element type is i64 (8 bytes)
        let elem_size: i64 = 8;
        let elem_type: i64 = TYPE_I64;
    
        // Lower the index expression
        let index_node: *Node = self.nodes + index_node_idx;
        let index_ir: i64 = self.lowerExpr(index_node);
    
        // Check if base is a local variable (optimized path)
        // Following src/frontend/lower.zig:1668-1697
        if base_node.kind == NodeKind.Ident {
            // Look up the local variable
            var local_idx: i64 = -1;
            var local: *IRLocal = null;
            var i: i64 = 0;
            while i < fb.locals_count {
                let check_local: *IRLocal = fb.locals + i;
                if names_equal(self.source, check_local.name_start, check_local.name_len,
                              base_node.field0, base_node.field1) {
                    local_idx = i;
                    local = check_local;
                }
                i = i + 1;
            }
    
            if local_idx >= 0 and local != null {
                let local_type_idx: i64 = local.type_idx;
    
                // Slice/String variables: load slice, extract ptr, then index
                // Following src/frontend/lower.zig:1677-1687
                if local_type_idx == TYPE_SLICE or local_type_idx == TYPE_STRING {
                    // For strings, element size is 1 (u8), for slices use default
                    var slice_elem_size: i64 = elem_size;
                    var slice_elem_type: i64 = elem_type;
                    if local_type_idx == TYPE_STRING {
                        slice_elem_size = 1;
                        slice_elem_type = TYPE_U8;
                    }
                    // Load the ptr field directly from the local (offset 0)
                    let ptr_val: i64 = fb.emitFieldLocal( local_idx, 0, TYPE_I64);
                    // Index through the pointer
                    return fb.emitIndexValue( ptr_val, index_ir, slice_elem_size, slice_elem_type);
                }
    
                // Pointer parameters/variables: load the pointer, then index through it
                // Following src/frontend/lower.zig:1689-1694 pattern
                // Use TypeRegistry to check for pointer types (not PTYPE ranges after refactor)
                var is_pointer_type: bool = false;
                if local_type_idx > 0 {
                    let type_info: *Type = self.type_pool.get( local_type_idx);
                    if type_info != null {
                        if type_info.kind == TypeKind.Pointer {
                            is_pointer_type = true;
                        }
                    }
                }
                if is_pointer_type {
                    // Local contains a pointer - load it and use index_value
                    let ptr_val: i64 = fb.emitLoadLocal( local_idx);
                    return fb.emitIndexValue( ptr_val, index_ir, elem_size, elem_type);
                }
    
                // Array parameters are passed by reference - the local contains a pointer
                // Following src/frontend/lower.zig:1689-1694
                // Use TypeRegistry to check for array types
                var is_array_param: bool = false;
                if local.is_param and local_type_idx > 0 {
                    let type_info: *Type = self.type_pool.get( local_type_idx);
                    if type_info != null {
                        if type_info.kind == TypeKind.Array {
                            is_array_param = true;
                        }
                    }
                }
                if is_array_param {
                    let ptr_val: i64 = fb.emitLoadLocal( local_idx);
                    return fb.emitIndexValue( ptr_val, index_ir, elem_size, elem_type);
                }
    
                // Regular local array - emit index_local for direct access
                // Following src/frontend/lower.zig:1695-1696
                return fb.emitIndexLocal( local_idx, index_ir, elem_size, elem_type);
            }
    
            // TODO: Check for global array variable (BUG-029)
            // Following src/frontend/lower.zig:1699-1706
        }
    
        // Base is a computed expression - lower it and emit IndexValue
        // Following src/frontend/lower.zig:1709-1711
        let base_val: i64 = self.lowerExpr(base_node);
    
        // Check if base returns a slice - extract pointer first
        if self.exprReturnsSlice(base_node) {
            let ptr_val: i64 = fb.emitSlicePtr( base_val, TYPE_I64);
            return fb.emitIndexValue( ptr_val, index_ir, elem_size, elem_type);
        }
    
        return fb.emitIndexValue( base_val, index_ir, elem_size, elem_type);
    }

    fn lowerSliceExpr(self: *Lowerer, node: *Node) i64 {
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        let base_node: *Node = self.nodes + node.field0;
        let start_node_idx: i64 = node.field1;
        let end_node_idx: i64 = node.field2;
    
        // For cot0, assume element type is i64 (8 bytes)
        let elem_size: i64 = 8;
    
        // Default start to 0 if not specified
        var start_ir: i64;
        if start_node_idx < 0 {
            start_ir = fb.emitConstInt( 0);
        } else {
            let start_node: *Node = self.nodes + start_node_idx;
            start_ir = self.lowerExpr(start_node);
        }
    
        // Look up the local variable first to get type info for implicit end
        var local_idx: i64 = -1;
        var local_type_idx: i64 = TYPE_I64;
        var array_len: i64 = 0;
        var deref_ptr_local_idx: i64 = -1;
    
        if base_node.kind == NodeKind.Ident {
            var i: i64 = 0;
            while i < fb.locals_count {
                let local: *IRLocal = fb.locals + i;
                if names_equal(self.source, local.name_start, local.name_len,
                              base_node.field0, base_node.field1) {
                    local_idx = i;
                    local_type_idx = local.type_idx;
                }
                i = i + 1;
            }
    
            // Get array length from local size (arrays are stored with size = len * 8)
            // This works because FuncBuilder_setLocalSize is called for arrays
            if local_idx >= 0 {
                let local: *IRLocal = fb.locals + local_idx;
                // For arrays, size = elem_count * 8 (assuming i64 elements)
                // Skip slices (size 16 = ptr + len struct)
                if local.size > 0 and local.size != 16 and local_type_idx != TYPE_SLICE {
                    array_len = local.size / 8;
                }
            }
        } else if base_node.kind == NodeKind.DerefExpr {
            // Handle arr.*[:] where arr is a pointer to an array
            let ptr_operand: *Node = self.nodes + base_node.field0;
            if ptr_operand.kind == NodeKind.Ident {
                // Look up the pointer local
                var i: i64 = 0;
                while i < fb.locals_count {
                    let local: *IRLocal = fb.locals + i;
                    if names_equal(self.source, local.name_start, local.name_len,
                                  ptr_operand.field0, ptr_operand.field1) {
                        deref_ptr_local_idx = i;
                        // Get array length from pointee type
                        let ptr_type: *Type = self.type_pool.get( local.type_idx);
                        if ptr_type.kind == TypeKind.Pointer {
                            let pointee_type: *Type = self.type_pool.get( ptr_type.elem);
                            if pointee_type.kind == TypeKind.Array {
                                array_len = pointee_type.len;
                            }
                        }
                    }
                    i = i + 1;
                }
            }
        }
    
        // Lower end index - use array length if not specified
        var end_ir: i64;
        if end_node_idx < 0 {
            // End not specified - use array length if known
            end_ir = fb.emitConstInt( array_len);
        } else {
            let end_node: *Node = self.nodes + end_node_idx;
            end_ir = self.lowerExpr(end_node);
        }
    
        // Calculate length: end - start
        let len_ir: i64 = fb.emitBinary(IR_OP_SUB, end_ir, start_ir, TYPE_I64);
    
        // Get pointer to base[start]
        // If base is a local array, get address of element at start index
        if local_idx >= 0 {
            // Check if local is a pointer (like ptr: *[3]i64)
            let local_type: *Type = self.type_pool.get( local_type_idx);
            var base_ptr: i64;
            if local_type.kind == TypeKind.Pointer {
                // Pointer variable: load its value (the address it points to)
                base_ptr = fb.emitLoadLocal( local_idx);
            } else {
                // Array local: get address of the local storage
                base_ptr = fb.emitAddrLocal( local_idx, TYPE_I64);
            }
            // Calculate offset: start * elem_size
            let elem_size_ir: i64 = fb.emitConstInt( elem_size);
            let offset_ir: i64 = fb.emitBinary(IR_OP_MUL, start_ir, elem_size_ir, TYPE_I64);
            // Add offset to base pointer
            let ptr_ir: i64 = fb.emitBinary(IR_OP_ADD, base_ptr, offset_ir, TYPE_I64);
            // Make slice (ptr, len)
            return fb.emitMakeSlice( ptr_ir, len_ir, TYPE_I64);
        }
    
        // Handle arr.*[:] - use pointer value as slice base
        if deref_ptr_local_idx >= 0 {
            let base_ptr: i64 = fb.emitLoadLocal( deref_ptr_local_idx);
            // Calculate offset: start * elem_size
            let elem_size_ir: i64 = fb.emitConstInt( elem_size);
            let offset_ir: i64 = fb.emitBinary(IR_OP_MUL, start_ir, elem_size_ir, TYPE_I64);
            // Add offset to base pointer
            let ptr_ir: i64 = fb.emitBinary(IR_OP_ADD, base_ptr, offset_ir, TYPE_I64);
            // Make slice (ptr, len)
            return fb.emitMakeSlice( ptr_ir, len_ir, TYPE_I64);
        }
    
        // Fallback: lower base expression and treat as pointer
        let base_val: i64 = self.lowerExpr(base_node);
        let elem_size_ir: i64 = fb.emitConstInt( elem_size);
        let offset_ir: i64 = fb.emitBinary(IR_OP_MUL, start_ir, elem_size_ir, TYPE_I64);
        let ptr_ir: i64 = fb.emitBinary(IR_OP_ADD, base_val, offset_ir, TYPE_I64);
        return fb.emitMakeSlice( ptr_ir, len_ir, TYPE_I64);
    }

    fn lowerFieldAssign(self: *Lowerer, target: *Node, value_idx: i64) i64 {
        // FieldAccess fields:
        // field0 = base expression (node index)
        // field1 = field_name_start
        // field2 = field_name_len
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        let base_node: *Node = self.nodes + target.field0;
        let field_name_start: i64 = target.field1;
        let field_name_len: i64 = target.field2;
    
        // Case 1: Base is an identifier (local struct variable)
        if base_node.kind == NodeKind.Ident {
            // Look up the local variable
            var local_idx: i64 = -1;
            var local_type_idx: i64 = TYPE_I64;
            var i: i64 = 0;
            while i < fb.locals_count {
                let local: *IRLocal = fb.locals + i;
                if names_equal(self.source, local.name_start, local.name_len,
                              base_node.field0, base_node.field1) {
                    local_idx = i;
                    local_type_idx = local.type_idx;
                }
                i = i + 1;
            }
    
            if local_idx < 0 {
                return NULL_NODE;  // Variable not found
            }
    
            // Check if local is a pointer to struct (auto-dereference for assignment)
            let local_type: *Type = self.type_pool.get( local_type_idx);
            var struct_type_idx: i64 = local_type_idx;
    
            if local_type.kind == TypeKind.Pointer {
                // Pointer to struct - need to load the pointer first
                struct_type_idx = local_type.elem;
    
                // Look up field in the pointee struct
                let field_info: *FieldInfo = self.type_pool.lookupField( struct_type_idx,
                                                               self.source + field_name_start, field_name_len);
                if field_info == null {
                    return NULL_NODE;  // Field not found
                }
    
                // Load the pointer value
                let ptr_val: i64 = fb.emitLoadLocal( local_idx);
                // Store value through the pointer at field offset
                return fb.emitStoreField( ptr_val, field_info.offset, value_idx);
            }
    
            // Direct struct assignment
            let field_info: *FieldInfo = self.type_pool.lookupField( struct_type_idx,
                                                           self.source + field_name_start, field_name_len);
            if field_info != null {
                return fb.emitStoreFieldLocal( local_idx, field_info.offset, value_idx);
            }
    
            // Fallback: check if local has struct_type_start set (for struct literals)
            let local: *IRLocal = fb.locals + local_idx;
            if local.struct_type_start >= 0 {
                let local_struct_type: i64 = self.type_pool.lookupByName( self.source,
                                                                        local.struct_type_start, local.struct_type_len);
                if local_struct_type > 0 {
                    let local_field_info: *FieldInfo = self.type_pool.lookupField( local_struct_type,
                                                                                 self.source + field_name_start, field_name_len);
                    if local_field_info != null {
                        return fb.emitStoreFieldLocal( local_idx, local_field_info.offset, value_idx);
                    }
                }
            }
    
            // If local is a parameter, assume it might be a pointer to struct
            // Load the pointer value and store through it
            if local.is_param {
                // Try to find field in any struct type in TypeRegistry
                var field_offset: i64 = 0;  // Default to offset 0 if not found
                // Use the local's type_idx if available
                if local.type_idx > 0 {
                    var search_type_idx: i64 = local.type_idx;
                    // Dereference pointer types
                    if TypeInfo_isPointer(self.type_pool, search_type_idx) {
                        search_type_idx = TypeInfo_getPointee(self.type_pool, search_type_idx);
                    }
                    if search_type_idx > 0 {
                        let param_field_info: *FieldInfo = self.type_pool.lookupField( search_type_idx,
                                                                                     self.source + field_name_start, field_name_len);
                        if param_field_info != null {
                            field_offset = param_field_info.offset;
                        }
                    }
                }
                let ptr_val: i64 = fb.emitLoadLocal( local_idx);
                return fb.emitStoreField( ptr_val, field_offset, value_idx);
            }
    
            // Last fallback: use offset 0 (for untyped cases)
            return fb.emitStoreFieldLocal( local_idx, 0, value_idx);
        }
    
        // Case 2: Base is a dereference expression (ptr.*.field = value)
        // Following Go's ODOTPTR and Zig's lower.zig pattern:
        // Get pointer value, look up field offset in pointee struct, emit StoreField
        if base_node.kind == NodeKind.DerefExpr {
            let ptr_operand: *Node = self.nodes + base_node.field0;
            let ptr_val: i64 = self.lowerExpr(ptr_operand);
    
            // Try to find struct type from the pointer local's info
            var field_offset: i64 = 0;
            if ptr_operand.kind == NodeKind.Ident {
                // Look up the pointer local to get its struct type info
                var i: i64 = 0;
                while i < fb.locals_count {
                    let local: *IRLocal = fb.locals + i;
                    if names_equal(self.source, local.name_start, local.name_len,
                                  ptr_operand.field0, ptr_operand.field1) {
                        // Found the pointer local - check if it has struct type info
                        if local.struct_type_start >= 0 {
                            // Use TypeRegistry to find field offset
                            let local_struct_type: i64 = self.type_pool.lookupByName( self.source,
                                                                                    local.struct_type_start, local.struct_type_len);
                            if local_struct_type > 0 {
                                let info: *FieldInfo = self.type_pool.lookupField( local_struct_type,
                                                                                 self.source + field_name_start, field_name_len);
                                if info != null {
                                    field_offset = info.offset;
                                }
                            }
                        }
                        break;
                    }
                    i = i + 1;
                }
            }
    
            return fb.emitStoreField( ptr_val, field_offset, value_idx);
        }
    
        // Case 3: Base is another field access (chained: a.b.c = value)
        // Following Zig lower.zig:731-738 pattern
        // For o.inner.x: base_node is o.inner, field_name is "x"
        if base_node.kind == NodeKind.FieldAccess {
            var total_offset: i64 = 0;
            var root_local_idx: i64 = -1;
            var root_type_idx: i64 = TYPE_I64;
    
            // Walk up the field access chain to find root local
            var walk_node: *Node = base_node;
            var depth: i64 = 0;
            while walk_node.kind == NodeKind.FieldAccess and depth < 10 {
                walk_node = self.nodes + walk_node.field0;
                depth = depth + 1;
            }
    
            // Check if root is a local variable identifier
            if walk_node.kind == NodeKind.Ident {
                var i: i64 = 0;
                while i < fb.locals_count {
                    let local: *IRLocal = fb.locals + i;
                    if names_equal(self.source, local.name_start, local.name_len,
                                  walk_node.field0, walk_node.field1) {
                        root_local_idx = i;
                        root_type_idx = local.type_idx;
    
                        // FIRST: Try TypeRegistry-based lookup (like Case 1)
                        // This is more reliable than AST-based lookup
                        let base_field_name_start: i64 = base_node.field1;
                        let base_field_name_len: i64 = base_node.field2;
    
                        // Look up base field (e.g., "inner") in root's struct type
                        let base_field_info: *FieldInfo = self.type_pool.lookupField( root_type_idx,
                            self.source + base_field_name_start, base_field_name_len);
    
                        if base_field_info != null {
                            total_offset = base_field_info.offset;
    
                            // Look up final field (e.g., "x") in base field's type
                            let final_field_info: *FieldInfo = self.type_pool.lookupField( base_field_info.type_idx,
                                self.source + field_name_start, field_name_len);
    
                            if final_field_info != null {
                                total_offset = total_offset + final_field_info.offset;
                                return fb.emitStoreFieldLocal( root_local_idx, total_offset, value_idx);
                            }
                        }
    
                        // FALLBACK: Use TypeRegistry lookup with struct_type_start/len
                        if local.struct_type_start >= 0 {
                            let local_struct_type: i64 = self.type_pool.lookupByName( self.source,
                                                                                    local.struct_type_start, local.struct_type_len);
                            if local_struct_type > 0 {
                                // Look up base field in root's struct type
                                let base_info: *FieldInfo = self.type_pool.lookupField( local_struct_type,
                                                                                      self.source + base_field_name_start, base_field_name_len);
    
                                if base_info != null and base_info.type_idx > 0 {
                                    total_offset = base_info.offset;
    
                                    // Look up final field in nested struct type
                                    let final_info: *FieldInfo = self.type_pool.lookupField( base_info.type_idx,
                                                                                           self.source + field_name_start, field_name_len);
    
                                    if final_info != null {
                                        total_offset = total_offset + final_info.offset;
                                        // BUG FIX: Check if root local is a pointer type
                                        // For pointers: load pointer, then store field through it
                                        // For values: store field directly to local
                                        let root_local: *IRLocal = fb.locals + root_local_idx;
                                        let root_type: *Type = self.type_pool.get( root_local.type_idx);
                                        if root_type != null and root_type.kind == TypeKind.Pointer {
                                            // Pointer to struct - load the pointer first
                                            let ptr_val: i64 = fb.emitLoadLocal( root_local_idx);
                                            return fb.emitStoreField( ptr_val, total_offset, value_idx);
                                        }
                                        return fb.emitStoreFieldLocal( root_local_idx, total_offset, value_idx);
                                    }
                                }
                            }
                        }
                    }
                    i = i + 1;
                }
            }
    
            // Fallback: lower base and store with proper field offset
            // Following Zig lower.zig:731-738
            let base_val: i64 = self.lowerFieldAccess(base_node);
    
            // Look up the final field offset in the base's struct type
            // base_node is the intermediate field access (e.g., o.inner)
            // We need to find what type that field has, then look up field_name in it
            var final_field_offset: i64 = 0;
    
            // Try to find the base field's type using TypeRegistry lookup
            if walk_node.kind == NodeKind.Ident and root_local_idx >= 0 {
                let local: *IRLocal = fb.locals + root_local_idx;
                if local.struct_type_start >= 0 {
                    let local_struct_type: i64 = self.type_pool.lookupByName( self.source,
                                                                            local.struct_type_start, local.struct_type_len);
                    if local_struct_type > 0 {
                        // Look up the intermediate field (e.g., "inner")
                        let base_field_name_start: i64 = base_node.field1;
                        let base_field_name_len: i64 = base_node.field2;
                        let base_info: *FieldInfo = self.type_pool.lookupField( local_struct_type,
                                                                              self.source + base_field_name_start, base_field_name_len);
    
                        if base_info != null and base_info.type_idx > 0 {
                            // Now look up the final field in the base's type
                            let final_info: *FieldInfo = self.type_pool.lookupField( base_info.type_idx,
                                                                                   self.source + field_name_start, field_name_len);
                            if final_info != null {
                                final_field_offset = final_info.offset;
                            }
                        }
                    }
                }
            }
    
            return fb.emitStoreField( base_val, final_field_offset, value_idx);
        }
    
        // Case 4: Base is an IndexExpr (arr[i].field = value)
        // Need to compute element address and add field offset
        if base_node.kind == NodeKind.IndexExpr {
            let array_node: *Node = self.nodes + base_node.field0;
            let index_node: *Node = self.nodes + base_node.field1;
    
            // Lower the index expression
            let index_ir: i64 = self.lowerExpr(index_node);
    
            if array_node.kind == NodeKind.Ident {
                // Look up the array local
                var local_idx: i64 = -1;
                var local_type_idx: i64 = TYPE_I64;
                var i: i64 = 0;
                while i < fb.locals_count {
                    let local: *IRLocal = fb.locals + i;
                    if names_equal(self.source, local.name_start, local.name_len,
                                  array_node.field0, array_node.field1) {
                        local_idx = i;
                        local_type_idx = local.type_idx;
                    }
                    i = i + 1;
                }
    
                if local_idx >= 0 {
                    // Get array element type and size from TypeRegistry
                    var elem_size: i64 = 8;  // Default to i64
                    var elem_type_idx: i64 = TYPE_I64;
                    let local_type: *Type = self.type_pool.get( local_type_idx);
                    if local_type != null and local_type.kind == TypeKind.Array {
                        elem_type_idx = local_type.elem;
                        elem_size = self.type_pool.sizeof( elem_type_idx);
                    }
    
                    // Get field offset within the element struct
                    var field_offset: i64 = 0;
                    let field_info: *FieldInfo = self.type_pool.lookupField( elem_type_idx,
                                                                           self.source + field_name_start, field_name_len);
                    if field_info != null {
                        field_offset = field_info.offset;
                    }
    
                    // Compute element address: base_addr + index * elem_size
                    let base_addr: i64 = fb.emitAddrLocal( local_idx, TYPE_I64);
                    let size_val: i64 = fb.emitConstInt( elem_size);
                    let offset_val: i64 = fb.emitBinary(IR_OP_MUL, index_ir, size_val, TYPE_I64);
                    let elem_addr: i64 = fb.emitBinary(IR_OP_ADD, base_addr, offset_val, TYPE_I64);
    
                    // Store at field offset within element
                    return fb.emitStoreField( elem_addr, field_offset, value_idx);
                }
            }
        }
    
        // Case 5: Other expressions - lower and store at offset 0
        let base_val: i64 = self.lowerExpr(base_node);
        return fb.emitStoreField( base_val, 0, value_idx);
    }

    fn lowerIndexAssign(self: *Lowerer, target: *Node, value_idx: i64) i64 {
        // IndexExpr fields:
        // field0 = base expression (array/pointer)
        // field1 = index expression
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        let base_node: *Node = self.nodes + target.field0;
        let index_node_idx: i64 = target.field1;
    
        // Lower the index expression
        let index_node: *Node = self.nodes + index_node_idx;
        let index_ir: i64 = self.lowerExpr(index_node);
    
        // Case 1: Base is an identifier (local array or slice variable)
        if base_node.kind == NodeKind.Ident {
            // Look up the local variable
            var local_idx: i64 = -1;
            var local_type_idx: i64 = TYPE_I64;
            var i: i64 = 0;
            while i < fb.locals_count {
                let local: *IRLocal = fb.locals + i;
                if names_equal(self.source, local.name_start, local.name_len,
                              base_node.field0, base_node.field1) {
                    local_idx = i;
                    local_type_idx = local.type_idx;
                }
                i = i + 1;
            }
    
            if local_idx >= 0 {
                // BUG FIX: Compute elem_size from array type instead of defaulting to 8
                // Without this, byte arrays get 64-bit stores which corrupt the stack
                var elem_size: i64 = 8;  // Default to i64
                let local_type: *Type = self.type_pool.get( local_type_idx);
                if local_type != null and local_type.kind == TypeKind.Array {
                    let elem_type_idx: i64 = local_type.elem;
                    elem_size = self.type_pool.sizeof( elem_type_idx);
                }
    
                // Check if local is a slice - slices store a pointer, not data
                // Following src/frontend/lower.zig:815-825 slice handling
                if local_type_idx == TYPE_SLICE {
                    // For slices: load the pointer first, then store through it
                    let ptr_val: i64 = fb.emitLoadLocal( local_idx);
                    return fb.emitStoreIndexValue( ptr_val, index_ir, value_idx, elem_size);
                } else {
                    // For arrays: store directly into local storage
                    return fb.emitStoreIndexLocal( local_idx, index_ir, value_idx, elem_size);
                }
            }
        }
    
        // Default elem_size for non-local cases
        let elem_size: i64 = 8;
    
        // Case 2: Base is any other expression - lower it and emit StoreIndexValue
        // Following src/frontend/lower.zig:849-857 slice handling pattern
        let base_val: i64 = self.lowerExpr(base_node);
    
        // Check if base returns a slice (e.g., get_slice_from_ptr()[0] = x)
        // For slices, we need to extract the pointer first using SlicePtr
        if self.exprReturnsSlice(base_node) {
            // Emit SlicePtr to extract pointer from slice value
            let ptr_val: i64 = fb.emitSlicePtr( base_val, TYPE_I64);
            return fb.emitStoreIndexValue( ptr_val, index_ir, value_idx, elem_size);
        }
    
        return fb.emitStoreIndexValue( base_val, index_ir, value_idx, elem_size);
    }

    fn lowerBuiltinCall(self: *Lowerer, node: *Node) i64 {
        // BuiltinCall fields:
        // field0 = name_start (offset in source after @)
        // field1 = name_len
        // field2 = type_arg (for @intCast, @sizeOf, @alignOf; -1 if none)
        // field3 = arg1 (first value argument node index)
        // field4 = arg2 (second value argument node index; -1 if none)
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        let name_start: i64 = node.field0;
        let name_len: i64 = node.field1;
        let arg1_idx: i64 = node.field3;
        let arg2_idx: i64 = node.field4;
    
        // Check builtin name by first character (using pointer arithmetic)
        // @string starts with 's', @intCast/@sizeOf with 'i'/'s', @alignOf with 'a'
        let first_char: u8 = (self.source + name_start).*;
    
        // @string(ptr, len)
        if first_char == 115 and name_len == 6 {  // 's' and length 6
            // Verify it's "string" by checking second char
            let second_char: u8 = (self.source + name_start + 1).*;
            if second_char == 116 {  // 't'
                // Lower both arguments
                let ptr_node: *Node = self.nodes + arg1_idx;
                let len_node: *Node = self.nodes + arg2_idx;
                let ptr_ir: i64 = self.lowerExpr(ptr_node);
                let len_ir: i64 = self.lowerExpr(len_node);
                return fb.emitMakeString( ptr_ir, len_ir);
            }
        }
    
        // @intCast(type, val) - integer type conversion with truncation
        // Following Zig pattern (ssa_builder.zig:1138-1222): emit truncation for narrowing casts
        if first_char == 105 and name_len == 7 {  // 'i' and length 7
            // Get target type and value
            let type_arg_idx: i64 = node.field2;
            if arg1_idx >= 0 {
                let val_node: *Node = self.nodes + arg1_idx;
                let val_ir: i64 = self.lowerExpr(val_node);
    
                // Resolve target type to determine if truncation is needed
                if type_arg_idx >= 0 {
                    let target_type: i64 = resolve_type_expr(self, type_arg_idx);
                    let target_size: i64 = self.type_pool.sizeof( target_type);
    
                    // For narrowing casts, emit AND with appropriate mask
                    // Following Zig's .trunc64to8, .trunc64to16, etc.
                    if target_size == 1 {
                        // u8/i8: mask with 0xFF
                        let mask: i64 = fb.emitConstInt( 255);
                        return fb.emitBinary(IR_OP_BIT_AND, val_ir, mask, target_type);
                    }
                    if target_size == 2 {
                        // u16/i16: mask with 0xFFFF
                        let mask: i64 = fb.emitConstInt( 65535);
                        return fb.emitBinary(IR_OP_BIT_AND, val_ir, mask, target_type);
                    }
                    if target_size == 4 {
                        // u32/i32: mask with 0xFFFFFFFF
                        let mask: i64 = fb.emitConstInt( 4294967295);
                        return fb.emitBinary(IR_OP_BIT_AND, val_ir, mask, target_type);
                    }
                }
    
                // No truncation needed (widening or same size)
                return val_ir;
            }
        }
    
        // @sizeOf(type) - return type size using TypeRegistry
        if first_char == 115 and name_len == 6 {  // 's' and length 6
            let second_char: u8 = (self.source + name_start + 1).*;
            if second_char == 105 {  // 'i' for "sizeOf"
                // Get the type argument and compute its size
                let type_arg_idx: i64 = node.field2;
                if type_arg_idx >= 0 {
                    let type_idx: i64 = resolve_type_expr(self, type_arg_idx);
                    let size: i64 = self.type_pool.sizeof( type_idx);
                    return fb.emitConstInt( size);
                }
                // Fallback if no type arg
                return fb.emitConstInt( 8);
            }
        }
    
        // @alignOf(type) - return type alignment (simplified: assume 8 for now)
        if first_char == 97 and name_len == 7 {  // 'a' and length 7
            // For now, return 8 (alignment of i64)
            return fb.emitConstInt( 8);
        }
    
        // @ptrToInt(ptr) - convert pointer to i64
        // Following Zig pattern: src/frontend/lower.zig:2456-2461
        // Just return the operand - pointers are already i64 internally
        if first_char == 112 and name_len == 8 {  // 'p' and length 8 for "ptrToInt"
            if arg1_idx >= 0 {
                let ptr_node: *Node = self.nodes + arg1_idx;
                return self.lowerExpr(ptr_node);
            }
        }
    
        // @intToPtr(type, val) - convert i64 to pointer
        // Just return the value - it's already i64 internally
        if first_char == 105 and name_len == 8 {  // 'i' and length 8 for "intToPtr"
            if arg1_idx >= 0 {
                let val_node: *Node = self.nodes + arg1_idx;
                return self.lowerExpr(val_node);
            }
        }
    
        // @ptrCast(type, ptr) - reinterpret pointer type
        // Following Zig: just return the operand since pointers are i64 internally
        if first_char == 112 and name_len == 7 {  // 'p' and length 7 for "ptrCast"
            if arg1_idx >= 0 {
                let ptr_node: *Node = self.nodes + arg1_idx;
                return self.lowerExpr(ptr_node);
            }
        }

        // @assert(condition) - if condition is false, trigger crash
        // 'a' = 97, 's' = 115, checking "assert" (length 6)
        if first_char == 97 and name_len == 6 {  // 'a' and length 6
            let second_char: u8 = (self.source + name_start + 1).*;
            if second_char == 115 {  // 's' for "assert"
                if arg1_idx >= 0 {
                    // Lower the condition
                    let cond_node: *Node = self.nodes + arg1_idx;
                    let condition: i64 = self.lowerExpr(cond_node);
                    if condition == NULL_NODE { return NULL_NODE; }

                    // Create blocks for conditional
                    let fail_block: i64 = fb.newBlock();
                    let continue_block: i64 = fb.newBlock();

                    // Branch: if true continue, if false fail
                    fb.emitBranch(condition, continue_block, fail_block);

                    // Fail block: call exit(1) by creating a call node
                    fb.setBlock(fail_block);
                    let exit_code: i64 = fb.emitConstInt(1);
                    // Create the exit call manually
                    var call_args: I64List = undefined;
                    i64list_init(&call_args);
                    i64list_append(&call_args, exit_code);
                    var call_node: IRNode = IRNode_new(IRNodeKind.Call, TYPE_VOID);
                    call_node.func_name_start = get_exit_name();
                    call_node.func_name_len = 4;
                    call_node.call_args = call_args;
                    fb.emit(call_node);
                    // Jump to continue (will never execute, but needed for valid IR)
                    fb.emitJump(continue_block);

                    // Continue block
                    fb.setBlock(continue_block);

                    return NULL_NODE;  // Assertion is a statement, not expression
                }
            }
        }

        return NULL_NODE;
    }

    fn lowerSwitchExpr(self: *Lowerer, node: *Node) i64 {
        // SwitchExpr fields:
        // field0 = subject (expression node index)
        // field1 = cases_start (index in children array)
        // field2 = cases_count
        // field3 = else_body (node index, -1 if no else)
    
        let fb: *FuncBuilder = self.current_func;
        if fb == null { return NULL_NODE; }
    
        // Lower the subject expression once
        let subject_node: *Node = self.nodes + node.field0;
        let subject: i64 = self.lowerExpr(subject_node);
    
        // Start with else value (or 0 if no else)
        var current_result: i64 = NULL_NODE;
        if node.field3 >= 0 {
            let else_node: *Node = self.nodes + node.field3;
            current_result = self.lowerExpr(else_node);
        } else {
            current_result = fb.emitConstInt( 0);
        }
    
        // Process cases in reverse order to build nested selects
        let cases_start: i64 = node.field1;
        let cases_count: i64 = node.field2;
    
        var case_idx: i64 = cases_count - 1;
        while case_idx >= 0 {
            // Get case node from children array using pointer arithmetic
            let case_child_ptr: *i64 = self.children + cases_start + case_idx;
            let case_child_idx: i64 = case_child_ptr.*;
            let case_node: *Node = self.nodes + case_child_idx;
    
            // SwitchCase fields:
            // field0 = patterns_start (index in children array)
            // field1 = patterns_count
            // field2 = body (expression node index)
    
            let patterns_start: i64 = case_node.field0;
            let patterns_count: i64 = case_node.field1;
            let body_node_idx: i64 = case_node.field2;
    
            // Build condition: OR together all patterns compared for equality
            var case_cond: i64 = NULL_NODE;
            var pat_idx: i64 = 0;
            while pat_idx < patterns_count {
                // Get pattern node from children array using pointer arithmetic
                let pattern_child_ptr: *i64 = self.children + patterns_start + pat_idx;
                let pattern_child_idx: i64 = pattern_child_ptr.*;
                let pattern_node: *Node = self.nodes + pattern_child_idx;
                let pattern_val: i64 = self.lowerExpr(pattern_node);
    
                // Emit: subject == pattern
                let pattern_cond: i64 = fb.emitBinary(IR_OP_EQ, subject, pattern_val, TYPE_BOOL);
    
                if case_cond == NULL_NODE {
                    case_cond = pattern_cond;
                } else {
                    // OR together: case_cond || pattern_cond
                    case_cond = fb.emitBinary(IR_OP_OR, case_cond, pattern_cond, TYPE_BOOL);
                }
    
                pat_idx = pat_idx + 1;
            }
    
            // Lower the case body
            let body_node: *Node = self.nodes + body_node_idx;
            let case_body: i64 = self.lowerExpr(body_node);
    
            // Emit select: if case_cond then case_body else current_result
            if case_cond != NULL_NODE {
                current_result = fb.emitSelect( case_cond, case_body, current_result, TYPE_I64);
            }
    
            case_idx = case_idx - 1;
        }
    
        return current_result;
    }

}

// Static helper function (moved outside impl block)
fn Lowerer_printNodeKind(kind: NodeKind) {
    if kind == NodeKind.IntLit { print("IntLit"); }
    else if kind == NodeKind.StringLit { print("StringLit"); }
    else if kind == NodeKind.Ident { print("Ident"); }
    else if kind == NodeKind.BinaryExpr { print("BinaryExpr"); }
    else if kind == NodeKind.CallExpr { print("CallExpr"); }
    else if kind == NodeKind.UnaryExpr { print("UnaryExpr"); }
    else if kind == NodeKind.AddressOf { print("AddressOf"); }
    else if kind == NodeKind.DerefExpr { print("DerefExpr"); }
    else if kind == NodeKind.AssignExpr { print("AssignExpr"); }
    else if kind == NodeKind.ReturnStmt { print("ReturnStmt"); }
    else if kind == NodeKind.ExprStmt { print("ExprStmt"); }
    else if kind == NodeKind.BlockStmt { print("BlockStmt"); }
    else if kind == NodeKind.IfStmt { print("IfStmt"); }
    else if kind == NodeKind.WhileStmt { print("WhileStmt"); }
    else if kind == NodeKind.ForStmt { print("ForStmt"); }
    else if kind == NodeKind.BreakStmt { print("BreakStmt"); }
    else if kind == NodeKind.ContinueStmt { print("ContinueStmt"); }
    else if kind == NodeKind.DeferStmt { print("DeferStmt"); }
    else if kind == NodeKind.FnDecl { print("FnDecl"); }
    else if kind == NodeKind.FieldAccess { print("FieldAccess"); }
    else if kind == NodeKind.IndexExpr { print("IndexExpr"); }
    else if kind == NodeKind.SliceExpr { print("SliceExpr"); }
    else if kind == NodeKind.StructLit { print("StructLit"); }
    else if kind == NodeKind.FieldInit { print("FieldInit"); }
    else if kind == NodeKind.ArrayLit { print("ArrayLit"); }
    else if kind == NodeKind.BuiltinCall { print("BuiltinCall"); }
    else if kind == NodeKind.SwitchExpr { print("SwitchExpr"); }
    else if kind == NodeKind.TypeExprNamed { print("TypeExprNamed"); }
    else if kind == NodeKind.TypeExprPointer { print("TypeExprPointer"); }
    else if kind == NodeKind.TypeExprArray { print("TypeExprArray"); }
    else if kind == NodeKind.TypeExprSlice { print("TypeExprSlice"); }
    else if kind == NodeKind.TypeExprOptional { print("TypeExprOptional"); }
    else if kind == NodeKind.TypeExprErrorUnion { print("TypeExprErrorUnion"); }
    else if kind == NodeKind.TypeExprFunc { print("TypeExprFunc"); }
    else if kind == NodeKind.TypeAliasDecl { print("TypeAliasDecl"); }
    else if kind == NodeKind.VarDecl { print("VarDecl"); }
    else if kind == NodeKind.ParamDecl { print("ParamDecl"); }
    else { print("UNKNOWN"); }
}

fn resolve_type_expr(l: *Lowerer, type_expr_idx: i64) i64 {
    if type_expr_idx < 0 {
        return TYPE_INVALID;
    }

    let node: *Node = l.nodes + type_expr_idx;

    // TypeExprNamed: look up type by name
    // cot1: Updated to use Lowerer_resolveNamedType which checks type aliases first
    if node.kind == NodeKind.TypeExprNamed {
        let name_start: i64 = node.field0;
        let name_len: i64 = node.field1;
        return l.resolveNamedType( name_start, name_len);
    }

    // TypeExprPointer: *T
    if node.kind == NodeKind.TypeExprPointer {
        let inner_idx: i64 = node.field0;
        let inner_type: i64 = resolve_type_expr(l, inner_idx);
        return l.type_pool.makePointer( inner_type);
    }

    // TypeExprArray: [N]T
    if node.kind == NodeKind.TypeExprArray {
        let size_node_idx: i64 = node.field0;
        let elem_node_idx: i64 = node.field1;
        // Get array size from IntLit node
        var array_size: i64 = 0;
        if size_node_idx >= 0 {
            let size_node: *Node = l.nodes + size_node_idx;
            if size_node.kind == NodeKind.IntLit {
                array_size = size_node.field0;  // IntLit stores value in field0
            }
        }
        let elem_type: i64 = resolve_type_expr(l, elem_node_idx);
        return l.type_pool.makeArray( elem_type, array_size);
    }

    // TypeExprSlice: []T
    if node.kind == NodeKind.TypeExprSlice {
        let elem_node_idx: i64 = node.field0;
        let elem_type: i64 = resolve_type_expr(l, elem_node_idx);
        return l.type_pool.makeSlice( elem_type);
    }

    // TypeExprOptional: ?T
    if node.kind == NodeKind.TypeExprOptional {
        let inner_idx: i64 = node.field0;
        let inner_type: i64 = resolve_type_expr(l, inner_idx);
        // TODO: TypeRegistry_makeOptional
        return inner_type;
    }

    // TypeExprErrorUnion: !T
    // Reference: Zig's lower.zig:2425-2427
    if node.kind == NodeKind.TypeExprErrorUnion {
        let payload_idx: i64 = node.field0;
        let payload_type: i64 = resolve_type_expr(l, payload_idx);
        // TODO: TypeRegistry_makeErrorUnion
        return payload_type;
    }

    // TypeExprFunc: fn(params) -> ret
    // The type was pre-resolved during parsing and stored in field1
    if node.kind == NodeKind.TypeExprFunc {
        return node.field1;  // Pre-resolved TypeRegistry index
    }

    return TYPE_INVALID;
}

fn resolve_named_type(pool: *TypeRegistry, source: *u8, name_start: i64, name_len: i64) i64 {
    // Check built-in types first (compare name in source)
    if name_len == 3 {
        // i64, i32
        if (source + name_start).* == 105 {  // 'i'
            if (source + name_start + 1).* == 54 and (source + name_start + 2).* == 52 {  // '6', '4'
                return TYPE_I64;
            }
            if (source + name_start + 1).* == 51 and (source + name_start + 2).* == 50 {  // '3', '2'
                return TYPE_I32;
            }
        }
    }
    if name_len == 2 {
        // u8
        if (source + name_start).* == 117 and (source + name_start + 1).* == 56 {  // 'u', '8'
            return TYPE_U8;
        }
    }
    if name_len == 4 {
        // bool, void
        if (source + name_start).* == 98 {  // 'b'
            return TYPE_BOOL;
        }
        if (source + name_start).* == 118 {  // 'v'
            return TYPE_VOID;
        }
    }
    if name_len == 6 {
        // string
        if (source + name_start).* == 115 {  // 's'
            return TYPE_STRING;
        }
    }

    // Look up user-defined type in TypeRegistry
    return pool.findByName( source + name_start, name_len);
}

fn resolve_type_from_source(pool: *TypeRegistry, source: *u8, type_start: i64, type_len: i64) i64 {
    if type_len <= 0 { return TYPE_I64; }

    // Check for pointer type (*T)
    let first_char: u8 = (source + type_start).*;
    if first_char == 42 {  // '*'
        // It's a pointer type - resolve pointee type first
        let pointee_type: i64 = resolve_type_from_source(pool, source, type_start + 1, type_len - 1);
        // Create or find pointer type to pointee
        return pool.makePointer( pointee_type);
    }

    // Not a pointer, resolve as named type
    return resolve_named_type(pool, source, type_start, type_len);
}

fn get_type_len_from_node(nodes: *Node, type_node_idx: i64) i64 {
    let type_node: *Node = nodes + type_node_idx;
    // For all type expression nodes, (end - start) gives the source length
    // TypeExprNamed: end = name_start + name_len
    // TypeExprPointer: end = position after inner type
    // etc.
    return type_node.end - type_node.start;
}

fn resolve_type_handle(pool: *TypeRegistry, source: *u8, type_handle: i64) i64 {
    // If it's a valid TypeRegistry index, return it directly
    if type_handle >= 0 and type_handle < 100 {
        return type_handle;
    }
    return TYPE_INVALID;
}

fn compute_escaped_length(source: *u8, str_start: i64, source_len: i64) i64 {
    var actual_len: i64 = 0;
    var i: i64 = 0;
    while i < source_len {
        let c: u8 = (source + str_start + i).*;
        if c == 92 and i + 1 < source_len {  // backslash
            // Escape sequence - counts as 1 character
            i = i + 1;  // Skip the escaped char
        }
        actual_len = actual_len + 1;
        i = i + 1;
    }
    return actual_len;
}

fn names_equal(source: *u8, start1: i64, len1: i64, start2: i64, len2: i64) bool {
    if len1 != len2 { return false; }
    var i: i64 = 0;
    while i < len1 {
        let p1: *u8 = source + start1 + i;
        let p2: *u8 = source + start2 + i;
        if p1.* != p2.* { return false; }
        i = i + 1;
    }
    return true;
}

fn name_is_len(source: *u8, start: i64, len: i64) bool {
    if len != 3 { return false; }
    let c0: u8 = (source + start).*;
    let c1: u8 = (source + start + 1).*;
    let c2: u8 = (source + start + 2).*;
    return c0 == 108 and c1 == 101 and c2 == 110;  // 'l', 'e', 'n'
}

fn name_is_ptr(source: *u8, start: i64, len: i64) bool {
    if len != 3 { return false; }
    let c0: u8 = (source + start).*;
    let c1: u8 = (source + start + 1).*;
    let c2: u8 = (source + start + 2).*;
    return c0 == 112 and c1 == 116 and c2 == 114;  // 'p', 't', 'r'
}

fn name_is_undefined(source: *u8, start: i64, len: i64) bool {
    if len != 9 { return false; }
    // u=117 n=110 d=100 e=101 f=102 i=105 n=110 e=101 d=100
    let c0: u8 = (source + start).*;
    let c1: u8 = (source + start + 1).*;
    let c2: u8 = (source + start + 2).*;
    let c3: u8 = (source + start + 3).*;
    let c4: u8 = (source + start + 4).*;
    let c5: u8 = (source + start + 5).*;
    let c6: u8 = (source + start + 6).*;
    let c7: u8 = (source + start + 7).*;
    let c8: u8 = (source + start + 8).*;
    return c0 == 117 and c1 == 110 and c2 == 100 and c3 == 101 and c4 == 102
       and c5 == 105 and c6 == 110 and c7 == 101 and c8 == 100;
}

fn name_is_null(source: *u8, start: i64, len: i64) bool {
    if len != 4 { return false; }
    let c0: u8 = (source + start).*;
    let c1: u8 = (source + start + 1).*;
    let c2: u8 = (source + start + 2).*;
    let c3: u8 = (source + start + 3).*;
    return c0 == 110 and c1 == 117 and c2 == 108 and c3 == 108;  // 'n', 'u', 'l', 'l'
}

fn name_is_true(source: *u8, start: i64, len: i64) bool {
    if len != 4 { return false; }
    let c0: u8 = (source + start).*;
    let c1: u8 = (source + start + 1).*;
    let c2: u8 = (source + start + 2).*;
    let c3: u8 = (source + start + 3).*;
    return c0 == 116 and c1 == 114 and c2 == 117 and c3 == 101;  // 't', 'r', 'u', 'e'
}

fn name_is_false(source: *u8, start: i64, len: i64) bool {
    if len != 5 { return false; }
    let c0: u8 = (source + start).*;
    let c1: u8 = (source + start + 1).*;
    let c2: u8 = (source + start + 2).*;
    let c3: u8 = (source + start + 3).*;
    let c4: u8 = (source + start + 4).*;
    return c0 == 102 and c1 == 97 and c2 == 108 and c3 == 115 and c4 == 101;  // 'f', 'a', 'l', 's', 'e'
}

fn name_is_print(source: *u8, start: i64, len: i64) bool {
    if len != 5 { return false; }
    let c0: u8 = (source + start).*;
    let c1: u8 = (source + start + 1).*;
    let c2: u8 = (source + start + 2).*;
    let c3: u8 = (source + start + 3).*;
    let c4: u8 = (source + start + 4).*;
    return c0 == 112 and c1 == 114 and c2 == 105 and c3 == 110 and c4 == 116;  // 'p', 'r', 'i', 'n', 't'
}

fn name_is_println(source: *u8, start: i64, len: i64) bool {
    if len != 7 { return false; }
    let c0: u8 = (source + start).*;
    let c1: u8 = (source + start + 1).*;
    let c2: u8 = (source + start + 2).*;
    let c3: u8 = (source + start + 3).*;
    let c4: u8 = (source + start + 4).*;
    let c5: u8 = (source + start + 5).*;
    let c6: u8 = (source + start + 6).*;
    // 'p', 'r', 'i', 'n', 't', 'l', 'n'
    return c0 == 112 and c1 == 114 and c2 == 105 and c3 == 110 and c4 == 116 and c5 == 108 and c6 == 110;
}

fn find_write_in_source(source: *u8, source_len: i64) i64 {
    var i: i64 = 0;
    while i < source_len - 4 {  // Need at least 5 chars for "write"
        let c0: u8 = (source + i).*;
        if c0 == 119 {  // 'w'
            let c1: u8 = (source + i + 1).*;
            let c2: u8 = (source + i + 2).*;
            let c3: u8 = (source + i + 3).*;
            let c4: u8 = (source + i + 4).*;
            // 'w', 'r', 'i', 't', 'e'
            if c1 == 114 and c2 == 105 and c3 == 116 and c4 == 101 {
                return i;
            }
        }
        i = i + 1;
    }
    return -1;  // Not found
}

fn ASTOp_toIROp(ast_op: i64) i64 {
    // Map AST operators to IR operator codes
    // Arithmetic
    if ast_op == 0 { return IR_OP_ADD; }
    if ast_op == 1 { return IR_OP_SUB; }
    if ast_op == 2 { return IR_OP_MUL; }
    if ast_op == 3 { return IR_OP_DIV; }
    if ast_op == 4 { return IR_OP_MOD; }

    // Comparison
    if ast_op == 5 { return IR_OP_EQ; }
    if ast_op == 6 { return IR_OP_NE; }
    if ast_op == 7 { return IR_OP_LT; }
    if ast_op == 8 { return IR_OP_LE; }
    if ast_op == 9 { return IR_OP_GT; }
    if ast_op == 10 { return IR_OP_GE; }

    // Logical
    if ast_op == 11 { return IR_OP_AND; }
    if ast_op == 12 { return IR_OP_OR; }

    // Bitwise
    if ast_op == 13 { return IR_OP_BIT_AND; }
    if ast_op == 14 { return IR_OP_BIT_OR; }
    if ast_op == 15 { return IR_OP_BIT_XOR; }
    if ast_op == 16 { return IR_OP_SHL; }
    if ast_op == 17 { return IR_OP_SHR; }

    return 0;
}

fn ASTUnaryOp_toIROp(ast_op: i64) i64 {
    if ast_op == 0 { return IR_OP_NEG; }
    if ast_op == 1 { return IR_OP_NOT; }
    if ast_op == 2 { return IR_OP_BIT_NOT; }
    return 0;
}

fn ASTOp_isComparison(ast_op: i64) bool {
    // Comparison ops are 5-10 (Equal through GreaterEq)
    if ast_op >= 5 and ast_op <= 10 { return true; }
    return false;
}

// IR Operation codes
const IR_OP_ADD: i64 = 0;
const IR_OP_SUB: i64 = 1;
const IR_OP_MUL: i64 = 2;
const IR_OP_DIV: i64 = 3;
const IR_OP_MOD: i64 = 4;
const IR_OP_EQ: i64 = 5;
const IR_OP_NE: i64 = 6;
const IR_OP_LT: i64 = 7;
const IR_OP_LE: i64 = 8;
const IR_OP_GT: i64 = 9;
const IR_OP_GE: i64 = 10;
const IR_OP_AND: i64 = 11;
const IR_OP_OR: i64 = 12;
const IR_OP_BIT_AND: i64 = 13;
const IR_OP_BIT_OR: i64 = 14;
const IR_OP_BIT_XOR: i64 = 15;
const IR_OP_SHL: i64 = 16;
const IR_OP_SHR: i64 = 17;
const IR_OP_NEG: i64 = 18;
const IR_OP_NOT: i64 = 19;
const IR_OP_BIT_NOT: i64 = 20;

// ============================================================================
// TEST HELPER FUNCTIONS
// ============================================================================

fn test_helper_add(a: i64, b: i64) i64 {
    return a + b
}

fn test_helper_identity(x: i64) i64 {
    return x
}

fn test_helper_sum8(a: i64, b: i64, c: i64, d: i64, e: i64, f: i64, g: i64, h: i64) i64 {
    return a + b + c + d + e + f + g + h
}

fn test_helper_sum9(a: i64, b: i64, c: i64, d: i64, e: i64, f: i64, g: i64, h: i64, i: i64) i64 {
    return a + b + c + d + e + f + g + h + i
}

fn test_helper_factorial(n: i64) i64 {
    if n <= 1 {
        return 1
    }
    return n * test_helper_factorial(n - 1)
}

fn test_helper_void() void {
    // Does nothing
}

fn test_helper_fib(n: i64) i64 {
    if n <= 1 {
        return n
    }
    return test_helper_fib(n - 1) + test_helper_fib(n - 2)
}

// ============================================================================
// INLINE TESTS - Arithmetic and Comparisons
// ============================================================================

// --- Arithmetic Tests ---

test "return literal" {
    @assert(42 == 42)
}

test "multiplication" {
    @assert(6 * 7 == 42)
}

test "division" {
    @assert(84 / 2 == 42)
}

test "subtraction" {
    @assert(50 - 8 == 42)
}

test "negation" {
    let x: i64 = -5
    @assert(x + 47 == 42)
}

test "modulo" {
    @assert(17 % 5 + 40 == 42)
}

test "operator precedence" {
    // 2 + (3*4) + (2*3*4) + 4 = 2 + 12 + 24 + 4 = 42
    @assert(2 + 3 * 4 + 2 * 3 * 4 + 4 == 42)
}

test "parentheses" {
    // (1+2) * (3+4) * 2 = 3 * 7 * 2 = 42
    @assert((1 + 2) * (3 + 4) * 2 == 42)
}

test "large numbers" {
    let big: i64 = 1000000000
    @assert(big / 1000000000 == 1)
}

test "addition" {
    @assert(20 + 22 == 42)
}

// --- Comparison Tests ---

test "not equal" {
    @assert(1 != 2)
}

test "less than" {
    @assert(10 < 20)
}

test "greater than" {
    @assert(20 > 10)
}

test "less or equal - less" {
    @assert(4 <= 5)
}

test "less or equal - equal" {
    @assert(5 <= 5)
}

test "greater or equal - greater" {
    @assert(6 >= 5)
}

test "greater or equal - equal" {
    @assert(5 >= 5)
}

test "equal" {
    @assert(42 == 42)
}

test "negative comparison" {
    let x: i64 = -10
    let y: i64 = -5
    @assert(x < y)
}

test "negative vs positive" {
    @assert(-1 < 1)
}

test "zero comparisons" {
    @assert(0 == 0)
    @assert(0 <= 0)
    @assert(0 >= 0)
}

// ============================================================================
// INLINE TESTS - Control Flow
// ============================================================================

test "if true branch" {
    var result: i64 = 0
    if 1 == 1 {
        result = 42
    }
    @assert(result == 42)
}

test "if false branch" {
    var result: i64 = 0
    if 1 == 2 {
        result = 1
    } else {
        result = 42
    }
    @assert(result == 42)
}

test "nested if" {
    var result: i64 = 0
    if 1 == 1 {
        if 2 == 2 {
            result = 42
        }
    }
    @assert(result == 42)
}

test "while skip" {
    var result: i64 = 42
    while 1 == 2 {
        result = 0
    }
    @assert(result == 42)
}

test "while loop" {
    var x: i64 = 0
    while x < 42 {
        x = x + 1
    }
    @assert(x == 42)
}

test "while countdown" {
    var x: i64 = 10
    while x > 0 {
        x = x - 1
    }
    @assert(x == 0)
}

test "nested while" {
    var sum: i64 = 0
    var i: i64 = 0
    while i < 3 {
        var j: i64 = 0
        while j < 3 {
            sum = sum + 1
            j = j + 1
        }
        i = i + 1
    }
    @assert(sum == 9)
}

test "break statement" {
    var x: i64 = 0
    while x < 100 {
        x = x + 1
        if x == 42 {
            break
        }
    }
    @assert(x == 42)
}

test "continue statement" {
    var sum: i64 = 0
    var i: i64 = 0
    while i < 10 {
        i = i + 1
        if i == 5 {
            continue
        }
        sum = sum + i
    }
    // sum = 1+2+3+4+6+7+8+9+10 = 50
    @assert(sum == 50)
}

test "if chain" {
    var x: i64 = 5
    var result: i64 = 0
    if x == 1 {
        result = 1
    } else {
        if x == 5 {
            result = 42
        } else {
            result = 0
        }
    }
    @assert(result == 42)
}

// ============================================================================
// INLINE TESTS - Function Calls
// ============================================================================

test "simple call" {
    @assert(test_helper_add(20, 22) == 42)
}

test "nested call" {
    @assert(test_helper_add(test_helper_identity(20), test_helper_identity(22)) == 42)
}

test "8 register args" {
    @assert(test_helper_sum8(1, 2, 3, 4, 5, 6, 7, 8) == 36)
}

test "9 args with stack" {
    @assert(test_helper_sum9(1, 2, 3, 4, 5, 6, 7, 8, 9) == 45)
}

test "recursion factorial" {
    @assert(test_helper_factorial(5) == 120)
}

test "recursion fibonacci" {
    @assert(test_helper_fib(10) == 55)
}

test "void call" {
    test_helper_void()
    @assert(1 == 1)
}

// ============================================================================
// INLINE TESTS - Variables and Assignment
// ============================================================================

test "var assign" {
    var x: i64 = 42
    @assert(x == 42)
}

test "var reassign" {
    var x: i64 = 10
    x = 42
    @assert(x == 42)
}

test "const decl" {
    let x: i64 = 42
    @assert(x == 42)
}

test "multiple vars" {
    let a: i64 = 10
    let b: i64 = 20
    let c: i64 = 12
    @assert(a + b + c == 42)
}

test "var in expression" {
    var x: i64 = 20
    var y: i64 = 22
    @assert(x + y == 42)
}

// ============================================================================
// INLINE TESTS - Bitwise Operations
// ============================================================================

test "bitwise and" {
    @assert((15 & 10) == 10)
}

test "bitwise or" {
    @assert((5 | 10) == 15)
}

test "bitwise xor" {
    @assert((15 ^ 10) == 5)
}

test "shift left" {
    @assert((4 << 3) == 32)
}

test "shift right" {
    @assert((32 >> 3) == 4)
}

test "bitwise combo" {
    @assert(((15 & 12) | 8) == 12)
}

test "mask extract" {
    let val: i64 = 255
    @assert((val & 15) == 15)
}

// ============================================================================
// INLINE TESTS - Logical Operations
// ============================================================================

test "logical and true" {
    @assert(true and true)
}

test "logical and false first" {
    var result: bool = false and true
    @assert(result == false)
}

test "logical and false second" {
    var result: bool = true and false
    @assert(result == false)
}

test "logical or false" {
    var result: bool = false or false
    @assert(result == false)
}

test "logical or true first" {
    var result: bool = true or false
    @assert(result)  // result is true
}

test "logical or true second" {
    var result: bool = false or true
    @assert(result)  // result is true
}

test "logical not" {
    var x: bool = !false
    @assert(x)  // x should be true
}
