// Cot0 Self-Hosting Compiler
// Full pipeline: Source → Scanner → Parser → Lowerer → SSA → genssa → Mach-O
//
// Usage: cot0 <source.cot> -o <output>

// ============================================================================
// Module Imports
// ============================================================================

// Frontend modules - import in specific order (required for compatibility)
import "frontend/token.cot"
import "frontend/scanner.cot"
import "frontend/types.cot"
import "frontend/ast.cot"
import "frontend/parser.cot"
import "frontend/lower.cot"

// Codegen - genssa.cot imports ../ssa/func.cot transitively
import "codegen/genssa.cot"

// SSA Builder - IR to SSA conversion (matches Zig's ssa_builder.zig)
// Must be imported AFTER genssa.cot to avoid duplicate func.cot imports
import "ssa/builder.cot"

// Object file writer
import "obj/macho.cot"

// ============================================================================
// Syscall Wrappers (libc)
// ============================================================================

extern fn open(path: *u8, flags: i32, mode: i32) i32;
extern fn read(fd: i32, buf: *u8, count: i64) i64;
extern fn write(fd: i32, buf: *u8, count: i64) i64;
extern fn close(fd: i32) i32;

// File flags (macOS)
const O_RDONLY: i32 = 0;
const O_WRONLY: i32 = 1;
const O_CREAT: i32 = 512;
const O_TRUNC: i32 = 1024;
const FILE_MODE: i32 = 420;  // 0o644

// ============================================================================
// Global Buffers - Use MAIN_ prefix to avoid conflicts with imported modules
// Note: MAX_NODES and MAX_CHILDREN are defined in ast.cot
// ============================================================================

const MAIN_MAX_SOURCE: i64 = 1048576;    // 1 MB source file
var g_source: [1048576]u8;
var g_source_len: i64 = 0;

const MAIN_MAX_OUTPUT_PATH: i64 = 256;
var g_output_path: [256]u8;
var g_output_path_len: i64 = 0;

// AST storage - nodes are fixed array, children are dynamic
var g_nodes: [100000]Node;  // 100k nodes for large files
var g_pool: NodePool;       // children list is inside, initialized dynamically

// Type pool storage
const MAIN_MAX_TYPES: i64 = 1000;
const MAIN_MAX_PARAMS: i64 = 5000;
const MAIN_MAX_FIELDS: i64 = 5000;
var g_types: [1000]Type;
var g_type_params: [5000]i64;
var g_type_fields: [5000]FieldInfo;
var g_type_pool: TypeRegistry;

// IR storage
const MAIN_MAX_IR_NODES: i64 = 50000;
const MAIN_MAX_IR_LOCALS: i64 = 5000;
const MAIN_MAX_IR_FUNCS: i64 = 1000;
const MAIN_MAX_CONSTANTS: i64 = 2000;
const MAIN_MAX_CALL_ARGS: i64 = 10000;
var g_ir_nodes: [50000]IRNode;
var g_ir_locals: [5000]IRLocal;
var g_ir_funcs: [1000]IRFunc;
var g_constants: [2000]ConstEntry;
var g_call_args: [10000]i64;

// SSA storage
const MAIN_MAX_SSA_BLOCKS: i64 = 5000;
const MAIN_MAX_SSA_VALUES: i64 = 50000;
const MAIN_MAX_SSA_LOCALS: i64 = 2500;
var g_ssa_blocks: [5000]Block;
var g_ssa_values: [50000]Value;
var g_ssa_locals: [2500]Local;

// Codegen storage
const MAIN_MAX_CODE: i64 = 262144;
const MAIN_MAX_CALL_SITES: i64 = 5000;
var g_code: [262144]u8;
var g_bstart: [5000]i64;
var g_branches: [5000]Branch;
var g_call_sites: [5000]CallSite;

// Mach-O storage
const MAIN_MAX_DATA: i64 = 65536;
const MAIN_MAX_SYMBOLS: i64 = 1000;
const MAIN_MAX_STRINGS: i64 = 32768;
const MAIN_MAX_RELOCS: i64 = 10000;
const MAIN_MAX_OUTPUT: i64 = 1048576;
var g_data: [65536]u8;
var g_symbols: [1000]Symbol;
var g_strings: [32768]u8;
var g_relocs: [10000]Reloc;
var g_output: [1048576]u8;

// IR to SSA mapping (IR node index -> SSA value ID)
var g_ir_to_ssa_id: [50000]i64;

// Local variable to SSA value mapping (local index -> SSA value ID)
var g_local_to_ssa_id: [5000]i64;

// SSABuilder storage arrays (for builder.cot)
const BUILDER_MAX_BLOCK_DEFS: i64 = 500;
const BUILDER_MAX_VAR_DEFS: i64 = 50000;
const BUILDER_MAX_BLOCK_MAP: i64 = 500;
var g_builder_all_defs: [500]BlockDefs;
var g_builder_block_map: [500]BlockMapping;
var g_builder_node_values: [50000]VarDef;
var g_builder_var_storage: [100000]VarDef;

// Import tracking - store imported file paths to avoid duplicates
const MAX_IMPORT_PATHS: i64 = 100;
const MAX_IMPORT_PATH_LEN: i64 = 256;
var g_import_paths: [25600]u8;  // 100 * 256 = flat array for paths
var g_import_path_lens: [100]i64;
var g_import_count: i64 = 0;

// Base directory for resolving relative imports
var g_base_dir: [256]u8;
var g_base_dir_len: i64 = 0;

// Temporary buffer for building import paths (separate from g_output_path)
var g_import_path_buf: [256]u8;

// ============================================================================
// Driver Struct (matching src/driver.zig)
// ============================================================================

struct Driver {
    // In cot0, we use global state instead of allocator
    // These fields track compilation state
    source_ptr: *u8,
    source_len: i64,
    output_path: *u8,
    output_path_len: i64,
}

fn Driver_init() Driver {
    var d: Driver = undefined;
    d.source_ptr = &g_source[0];
    d.source_len = 0;
    d.output_path = &g_output_path[0];
    d.output_path_len = 0;
    return d;
}

// Compile source text directly (matches src/driver.zig compileSource)
// Note: In cot0, this is a thin wrapper since we use global state
fn Driver_compileSource(source: string, out_path: *u8, out_path_len: i64) i64 {
    return Driver_compileFile(source, out_path, out_path_len);
}

// Set debug phases for verbose output (matches src/driver.zig setDebugPhases)
// Note: In cot0, debug is controlled via print statements - stub for API parity
fn Driver_setDebugPhases(phases: *u8, phases_len: i64) {
    // TODO: Parse phases string and enable selective debug output
    // For now, this is a no-op - cot0 uses unconditional print statements
}

// ============================================================================
// Helper Functions
// ============================================================================

// NOTE: ir_op_to_ssa_op and ir_unary_op_to_ssa_op are now in ssa/builder.cot

// print(s) and println(s) are built-in functions - do not redefine them

fn print_int(n: i64) {
    var buf: [20]u8;
    var i: i64 = 19;
    var val: i64 = n;

    if val == 0 {
        buf[i] = @intCast(u8, 48);
        write(1, &buf[i], 1);
        return;
    }

    if val < 0 {
        print("-");
        val = 0 - val;
    }

    while val > 0 {
        let digit: i64 = val - (val / 10) * 10;
        buf[i] = @intCast(u8, 48 + digit);
        val = val / 10;
        i = i - 1;
    }

    write(1, &buf[i + 1], 19 - i);
}

// ============================================================================
// File I/O
// ============================================================================

fn read_file(path: *u8) i64 {
    let fd: i32 = open(path, O_RDONLY, 0);
    if fd < 0 {
        print("Error: Cannot open file\n");
        return -1;
    }

    g_source_len = read(fd, &g_source[0], MAIN_MAX_SOURCE - 1);
    close(fd);

    if g_source_len < 0 {
        print("Error: Cannot read file\n");
        return -1;
    }

    g_source[g_source_len] = 0;
    return g_source_len;
}

fn write_file(path: *u8, data: *u8, data_len: i64) i64 {
    let fd: i32 = open(path, O_WRONLY | O_CREAT | O_TRUNC, FILE_MODE);
    if fd < 0 {
        print("Error: Cannot open output file\n");
        return -1;
    }

    let written: i64 = write(fd, data, data_len);
    close(fd);

    if written != data_len {
        print("Error: Failed to write output\n");
        return -1;
    }

    return written;
}

// ============================================================================
// Pool Initialization
// ============================================================================

fn init_node_pool() *NodePool {
    g_pool.nodes = &g_nodes[0];
    g_pool.count = 0;
    i64list_init(&g_pool.children);  // Dynamic list - grows as needed
    return &g_pool;
}

// ============================================================================
// Import Processing
// ============================================================================

// Check if a path has already been imported
fn is_path_imported(path: *u8, path_len: i64) bool {
    var i: i64 = 0;
    while i < g_import_count {
        let stored_len: i64 = g_import_path_lens[i];
        if stored_len == path_len {
            // Compare paths
            let stored_path: *u8 = &g_import_paths[i * MAX_IMPORT_PATH_LEN];
            var match: bool = true;
            var j: i64 = 0;
            while j < path_len {
                let c1: *u8 = stored_path + j;
                let c2: *u8 = path + j;
                if c1.* != c2.* {
                    match = false;
                }
                j = j + 1;
            }
            if match {
                return true;
            }
        }
        i = i + 1;
    }
    return false;
}

// Add a path to the imported list
fn add_imported_path(path: *u8, path_len: i64) {
    if g_import_count >= MAX_IMPORT_PATHS {
        return;
    }
    let dest: *u8 = &g_import_paths[g_import_count * MAX_IMPORT_PATH_LEN];
    var i: i64 = 0;
    while i < path_len and i < MAX_IMPORT_PATH_LEN {
        let src_c: *u8 = path + i;
        let dst_c: *u8 = dest + i;
        dst_c.* = src_c.*;
        i = i + 1;
    }
    g_import_path_lens[g_import_count] = path_len;
    g_import_count = g_import_count + 1;
}

// Extract directory from a file path (everything before last '/')
fn extract_base_dir(path: *u8, path_len: i64) {
    // Find last '/' in path
    var last_slash: i64 = -1;
    var i: i64 = 0;
    while i < path_len {
        let c: *u8 = path + i;
        if c.* == 47 {  // '/'
            last_slash = i;
        }
        i = i + 1;
    }

    if last_slash < 0 {
        // No directory component
        g_base_dir_len = 0;
        return;
    }

    // Copy directory part including the slash
    i = 0;
    while i <= last_slash and i < 256 {
        let src: *u8 = path + i;
        g_base_dir[i] = src.*;
        i = i + 1;
    }
    g_base_dir_len = last_slash + 1;
}

// Build full path: base_dir + import_path
// Result stored in g_import_path_buf
fn build_import_path(import_path: *u8, import_path_len: i64) i64 {
    var result_len: i64 = 0;

    // Copy base directory
    var i: i64 = 0;
    while i < g_base_dir_len and result_len < MAX_IMPORT_PATH_LEN {
        g_import_path_buf[result_len] = g_base_dir[i];
        result_len = result_len + 1;
        i = i + 1;
    }

    // Copy import path
    i = 0;
    while i < import_path_len and result_len < MAX_IMPORT_PATH_LEN {
        let c: *u8 = import_path + i;
        g_import_path_buf[result_len] = c.*;
        result_len = result_len + 1;
        i = i + 1;
    }

    // Null terminate
    g_import_path_buf[result_len] = 0;
    return result_len;
}

// Adjust source positions in newly parsed nodes to be absolute in g_source
// This is needed because the parser reports positions relative to the string slice
// it was given, but we need absolute positions for the combined source buffer.
fn adjust_node_positions(pool: *NodePool, start_idx: i64, end_idx: i64, offset: i64) {
    var i: i64 = start_idx;
    while i < end_idx {
        let node: *Node = pool.nodes + i;

        // Adjust source span (all nodes have these)
        node.start = node.start + offset;
        node.end = node.end + offset;

        // Adjust kind-specific position fields
        // These are fields that contain source positions (not indices or values)
        if node.kind == NodeKind.Ident {
            // field0 = name_start (source position)
            node.field0 = node.field0 + offset;
        } else if node.kind == NodeKind.FnDecl {
            // field0 = name_start
            node.field0 = node.field0 + offset;
        } else if node.kind == NodeKind.ExternFnDecl {
            // field0 = name_start
            node.field0 = node.field0 + offset;
        } else if node.kind == NodeKind.VarDecl {
            // field0 = name_start
            node.field0 = node.field0 + offset;
        } else if node.kind == NodeKind.ConstDecl {
            // field0 = name_start
            node.field0 = node.field0 + offset;
        } else if node.kind == NodeKind.ImportDecl {
            // field0 = path_start
            node.field0 = node.field0 + offset;
        } else if node.kind == NodeKind.StructDecl {
            // field0 = name_start
            node.field0 = node.field0 + offset;
        } else if node.kind == NodeKind.EnumDecl {
            // field0 = name_start
            node.field0 = node.field0 + offset;
        } else if node.kind == NodeKind.FieldDecl {
            // field0 = name_start
            // Note: field2 is type_handle (not a source position)
            node.field0 = node.field0 + offset;
        } else if node.kind == NodeKind.StringLit {
            // field0 = content_start (source position of string content)
            node.field0 = node.field0 + offset;
        }
        // Other node kinds don't have source positions in their fields
        // (they have node indices, values, or type handles instead)

        i = i + 1;
    }
}

// Read and parse an imported file, returns number of new nodes or -1 on error
fn parse_import_file(import_path: *u8, import_path_len: i64, pool: *NodePool) i64 {
    // Build full path
    let full_path_len: i64 = build_import_path(import_path, import_path_len);

    // Check if already imported
    if is_path_imported(&g_import_path_buf[0], full_path_len) {
        return 0;  // Already imported, skip
    }

    // Mark as imported
    add_imported_path(&g_import_path_buf[0], full_path_len);

    // Read the file - append to existing source
    let fd: i32 = open(&g_import_path_buf[0], O_RDONLY, 0);
    if fd < 0 {
        print("  Warning: Cannot open import: ");
        write(1, &g_import_path_buf[0], full_path_len);
        print("\n");
        return 0;  // Non-fatal, continue with other imports
    }

    let start_offset: i64 = g_source_len;
    let bytes_read: i64 = read(fd, &g_source[g_source_len], MAIN_MAX_SOURCE - g_source_len - 1);
    close(fd);

    if bytes_read < 0 {
        print("  Warning: Cannot read import\n");
        return 0;
    }

    g_source_len = g_source_len + bytes_read;
    g_source[g_source_len] = 0;

    // Parse the imported file
    // Create a string slice pointing to just the new content
    let import_source: string = @string(&g_source[start_offset], bytes_read);

    let nodes_before: i64 = pool.count;
    var parser: Parser = Parser_init(import_source, pool, &g_type_pool);
    Parser_parseFile(&parser);

    if Parser_hadError(&parser) {
        print("  Warning: Parse error in import\n");
    }

    // Adjust positions in new nodes to be absolute in g_source
    // The parser reported positions relative to import_source (starting at 0)
    // but we need them relative to g_source (starting at start_offset)
    let new_nodes: i64 = pool.count - nodes_before;
    if new_nodes > 0 {
        adjust_node_positions(pool, nodes_before, pool.count, start_offset);
    }

    return new_nodes;
}

// Process all imports in the parsed AST (matches src/driver.zig parseFileRecursive)
// This scans for ImportDecl nodes and recursively parses imported files
fn Driver_parseFileRecursive(pool: *NodePool) {
    // Process imports iteratively - new nodes from imports may have their own imports
    var last_count: i64 = 0;

    while last_count < pool.count {
        let start_idx: i64 = last_count;
        last_count = pool.count;

        var i: i64 = start_idx;
        while i < last_count {
            let node: *Node = pool.nodes + i;
            if node.kind == NodeKind.ImportDecl {
                // field0 = path_start (offset in source), field1 = path_len
                let path_start: i64 = node.field0;
                let path_len: i64 = node.field1;

                // Get pointer to path in source
                let import_path: *u8 = &g_source[path_start];

                // Parse the imported file
                let new_nodes: i64 = parse_import_file(import_path, path_len, pool);
                if new_nodes > 0 {
                    print("  Imported: ");
                    write(1, import_path, path_len);
                    print(" (");
                    print_int(new_nodes);
                    print(" nodes)\n");
                }
            }
            i = i + 1;
        }
    }
}

// ============================================================================
// Compilation Pipeline
// ============================================================================

fn Driver_compileFile(source: string, out_path: *u8, out_path_len: i64) i64 {
    print("Phase 1: Scanning...\n");

    // Phase 1: Scan and count tokens
    var scanner: Scanner = Scanner_init(source);
    var tok_count: i64 = 0;
    var tok: Token = Scanner_next(&scanner);
    while tok.kind != TokenType.Eof {
        tok_count = tok_count + 1;
        tok = Scanner_next(&scanner);
    }
    print("  Tokens: ");
    print_int(tok_count);
    print("\n");

    // Initialize type registry (needed for parser)
    g_type_pool.types = &g_types[0];
    g_type_pool.params = &g_type_params[0];
    g_type_pool.fields = &g_type_fields[0];
    TypeRegistry_init(&g_type_pool);

    // Phase 2: Parse
    print("Phase 2: Parsing...\n");
    let pool: *NodePool = init_node_pool();
    var parser: Parser = Parser_init(source, pool, &g_type_pool);
    let file_node: i64 = Parser_parseFile(&parser);

    if Parser_hadError(&parser) {
        print("  FAIL: Parser error at position ");
        print_int(parser.scanner.pos);
        print("\n");
        return 1;
    }

    print("  Nodes: ");
    print_int(pool.count);
    print(", Children: ");
    print_int(pool.children.count);
    print("\n");

    // Phase 2.5: Process imports
    print("Phase 2.5: Processing imports...\n");
    Driver_parseFileRecursive(pool);
    print("  Total nodes after imports: ");
    print_int(pool.count);
    print("\n");

    // Phase 3: Lower to IR
    print("Phase 3: Lowering to IR...\n");

    // Update type registry source to combined source buffer (after imports)
    TypeRegistry_setSource(&g_type_pool, &g_source[0], g_source_len);

    var lowerer: Lowerer = undefined;
    Lowerer_init(&lowerer,
                 &g_nodes[0], pool.count,
                 pool.children.items, pool.children.count,
                 &g_source[0], g_source_len,
                 &g_type_pool,
                 &g_ir_nodes[0], MAIN_MAX_IR_NODES,
                 &g_ir_locals[0], MAIN_MAX_IR_LOCALS,
                 &g_ir_funcs[0], MAIN_MAX_IR_FUNCS,
                 &g_constants[0], MAIN_MAX_CONSTANTS,
                 &g_call_args[0], MAIN_MAX_CALL_ARGS);

    let ir_count: i64 = Lowerer_lowerAll(&lowerer);
    print("  IR nodes: ");
    print_int(ir_count);
    print(", Functions: ");
    print_int(lowerer.ir_funcs_count);
    print("\n");

    // Phase 4 & 5: Build SSA and generate code for each function
    print("Phase 4/5: Building SSA and generating code...\n");

    // Initialize code generator state (shared across functions)
    var gs: GenState = undefined;
    GenState_init(&gs, null,  // Will set func for each function
                  &g_code[0], MAIN_MAX_CODE,
                  &g_bstart[0], MAIN_MAX_SSA_BLOCKS,
                  &g_branches[0], 1000,
                  &g_call_sites[0], MAIN_MAX_CALL_SITES);

    var total_blocks: i64 = 0;
    var total_values: i64 = 0;

    // Process each function
    var func_idx: i64 = 0;
    while func_idx < lowerer.ir_funcs_count {
        let ir_func: *IRFunc = &g_ir_funcs[func_idx];

        // Record code offset for this function
        ir_func.code_offset = gs.code_count;

        // Initialize SSA function (reuse global arrays, they'll be overwritten)
        var ssa_func: Func = undefined;
        Func_init(&ssa_func, ir_func.name_start, ir_func.name_len, TYPE_I64,
                  &g_ssa_blocks[0], MAIN_MAX_SSA_BLOCKS,
                  &g_ssa_values[0], MAIN_MAX_SSA_VALUES,
                  &g_ssa_locals[0], MAIN_MAX_SSA_LOCALS);

        // ==================================================================
        // IR to SSA Conversion using SSABuilder
        // Matches Zig's ssa_builder.zig structure
        // ==================================================================

        // Initialize SSA builder with storage arrays
        var builder: SSABuilder = undefined;
        SSABuilder_init(&builder, &ssa_func,
                        &g_builder_all_defs[0], BUILDER_MAX_BLOCK_DEFS,
                        &g_builder_block_map[0], BUILDER_MAX_BLOCK_MAP,
                        &g_builder_node_values[0], BUILDER_MAX_VAR_DEFS,
                        &g_builder_var_storage[0], 100000);

        // Set IR references for this function
        SSABuilder_setIR(&builder,
                         &g_ir_nodes[0], ir_func.nodes_start, ir_func.nodes_count,
                         &g_ir_locals[0], ir_func.locals_start, ir_func.locals_count,
                         &g_source[0], g_source_len,
                         &g_call_args[0]);

        // Build SSA from IR (handles blocks, locals, params, conversion)
        let build_result: i64 = SSABuilder_build(&builder);

        // Compute stack layout using StackAlloc pass
        // This assigns offsets to locals and computes frame_size with 16-byte alignment
        let stack_result: StackAllocResult = StackAlloc_run(&ssa_func);

        // Compute dominator tree for the function
        // This sets b.dom (immediate dominator) and b.dom_level (depth) for each block
        var dom_tree: DomTree = undefined;
        DomTree_init(&dom_tree);
        DomTree_compute(&dom_tree, &ssa_func);
        DomTree_deinit(&dom_tree);

        total_blocks = total_blocks + ssa_func.blocks_count;
        total_values = total_values + ssa_func.values_count;

        // Generate code for this function
        // Following Zig compiler pattern (src/codegen/arm64.zig:461-462):
        // Clear branch fixups at start of each function
        gs.func = &ssa_func;
        gs.branches_count = 0;  // Reset branches for this function
        let genssa_result: i64 = GenState_generate(&gs);
        if genssa_result != 0 {
            print("  FAIL: genssa error\n");
            return 2;
        }

        func_idx = func_idx + 1;
    }

    print("  Total blocks: ");
    print_int(total_blocks);
    print(", Total values: ");
    print_int(total_values);
    print(", Code bytes: ");
    print_int(gs.code_count);
    print(", Call sites: ");
    print_int(gs.call_sites_count);
    print("\n");

    // Resolve call sites: patch BL instructions with correct offsets
    var call_idx: i64 = 0;
    while call_idx < gs.call_sites_count {
        let cs: *CallSite = &g_call_sites[call_idx];

        // Find target function by name
        var target_offset: i64 = -1;
        var target_idx: i64 = 0;
        while target_idx < lowerer.ir_funcs_count {
            let ir_func: *IRFunc = &g_ir_funcs[target_idx];
            // Compare function names
            if ir_func.name_len == cs.func_name_len {
                var match: bool = true;
                var name_i: i64 = 0;
                while name_i < cs.func_name_len {
                    // Use g_source (combined buffer) instead of original source
                    // This allows cross-file function calls to work correctly
                    let src_char: *u8 = &g_source[ir_func.name_start + name_i];
                    let call_char: *u8 = &g_source[cs.func_name_start + name_i];
                    if src_char.* != call_char.* {
                        match = false;
                    }
                    name_i = name_i + 1;
                }
                if match {
                    target_offset = ir_func.code_offset;
                }
            }
            target_idx = target_idx + 1;
        }

        // Patch BL instruction if target found
        if target_offset >= 0 {
            // BL offset = (target - call_site) / 4, encoded in bits 25:0
            let call_addr: i64 = cs.code_offset;
            let offset: i64 = (target_offset - call_addr) / 4;
            print("  Patching call at ");
            print_int(call_addr);
            print(" -> target ");
            print_int(target_offset);
            print(", offset ");
            print_int(offset);
            print("\n");
            // Re-encode BL with correct offset
            let bl_inst: i64 = encode_bl(offset);
            // Patch the code buffer (4 bytes, little endian)
            let code_ptr: *u8 = &g_code[call_addr];
            code_ptr.* = @intCast(u8, bl_inst & 255);
            let code_ptr1: *u8 = &g_code[call_addr + 1];
            code_ptr1.* = @intCast(u8, (bl_inst >> 8) & 255);
            let code_ptr2: *u8 = &g_code[call_addr + 2];
            code_ptr2.* = @intCast(u8, (bl_inst >> 16) & 255);
            let code_ptr3: *u8 = &g_code[call_addr + 3];
            code_ptr3.* = @intCast(u8, (bl_inst >> 24) & 255);
        } else {
            // External function call - will be resolved by linker via relocation
            print("  External call at offset ");
            print_int(cs.code_offset);
            print(" (len ");
            print_int(cs.func_name_len);
            print(")\n");
        }

        call_idx = call_idx + 1;
    }

    // Phase 6: Create Mach-O object
    print("Phase 6: Creating Mach-O object...\n");

    var writer: MachOWriter = undefined;
    MachOWriter_init(&writer,
                      &g_code[0], gs.code_count,
                      &g_data[0], MAIN_MAX_DATA,
                      &g_symbols[0], MAIN_MAX_SYMBOLS,
                      &g_strings[0], MAIN_MAX_STRINGS,
                      &g_relocs[0], MAIN_MAX_RELOCS,
                      &g_output[0], MAIN_MAX_OUTPUT);

    // Copy code from genssa output
    writer.code_count = gs.code_count;

    // Add symbols for all functions
    var sym_name: [128]u8;  // Buffer for mangled name (_funcname)
    func_idx = 0;
    while func_idx < lowerer.ir_funcs_count {
        let ir_func: *IRFunc = &g_ir_funcs[func_idx];

        // Build symbol name: "_" + function name from source
        sym_name[0] = 95;  // '_'
        var name_idx: i64 = 0;
        while name_idx < ir_func.name_len and name_idx < 126 {
            let src_ptr: *u8 = source.ptr + ir_func.name_start + name_idx;
            sym_name[1 + name_idx] = src_ptr.*;
            name_idx = name_idx + 1;
        }
        let sym_len: i64 = 1 + ir_func.name_len;

        // Add symbol at function's code offset
        MachOWriter_addSymbol(&writer, &sym_name[0], sym_len, ir_func.code_offset, SECT_TEXT, true);

        func_idx = func_idx + 1;
    }

    // Add external call relocations
    // Second pass through call sites to find external calls and add relocations
    call_idx = 0;
    while call_idx < gs.call_sites_count {
        let cs2: *CallSite = &g_call_sites[call_idx];

        // Check if this is an internal function (already found in ir_funcs)
        var is_internal: bool = false;
        var target_idx2: i64 = 0;
        while target_idx2 < lowerer.ir_funcs_count {
            let ir_func2: *IRFunc = &g_ir_funcs[target_idx2];
            if ir_func2.name_len == cs2.func_name_len {
                var match2: bool = true;
                var name_i3: i64 = 0;
                while name_i3 < cs2.func_name_len {
                    let src_char2: *u8 = &g_source[ir_func2.name_start + name_i3];
                    let call_char2: *u8 = &g_source[cs2.func_name_start + name_i3];
                    if src_char2.* != call_char2.* {
                        match2 = false;
                    }
                    name_i3 = name_i3 + 1;
                }
                if match2 {
                    is_internal = true;
                }
            }
            target_idx2 = target_idx2 + 1;
        }

        // If not internal, add as external symbol and relocation
        if not is_internal {
            // Build external symbol name: "_" + function name
            sym_name[0] = 95;  // '_'
            var ext_name_idx: i64 = 0;
            while ext_name_idx < cs2.func_name_len and ext_name_idx < 126 {
                let src_ptr2: *u8 = &g_source[cs2.func_name_start + ext_name_idx];
                sym_name[1 + ext_name_idx] = src_ptr2.*;
                ext_name_idx = ext_name_idx + 1;
            }
            let ext_sym_len: i64 = 1 + cs2.func_name_len;

            // Add undefined external symbol (section = 0)
            let sym_idx: i64 = MachOWriter_addSymbol(&writer, &sym_name[0], ext_sym_len, 0, 0, true);

            // Add relocation for the BL instruction
            MachOWriter_addReloc(&writer, cs2.code_offset, sym_idx, ARM64_RELOC_BRANCH26, true);

            print("  Added external reloc at offset ");
            print_int(cs2.code_offset);
            print(" (sym_idx ");
            print_int(sym_idx);
            print(")\n");
        }

        call_idx = call_idx + 1;
    }

    let macho_bytes: i64 = MachOWriter_write(&writer);
    print("  Mach-O bytes: ");
    print_int(macho_bytes);
    print("\n");

    // Phase 7: Write to output file
    print("Phase 7: Writing output...\n");

    if out_path_len > 0 {
        let written: i64 = write_file(out_path, &g_output[0], macho_bytes);
        if written < 0 {
            return 3;
        }
        print("  Wrote ");
        print_int(written);
        print(" bytes\n");
    } else {
        print("  (No output path specified, skipping write)\n");
    }

    return 0;
}

// ============================================================================
// Command Line Parsing
// ============================================================================

// Get string length (null-terminated)
fn strlen(s: *u8) i64 {
    var len: i64 = 0;
    var ptr: *u8 = s;
    while ptr.* != 0 {
        len = len + 1;
        ptr = ptr + 1;
    }
    return len;
}

// Compare two strings for equality
fn streq(a: *u8, b: *u8) bool {
    var pa: *u8 = a;
    var pb: *u8 = b;
    while pa.* != 0 and pb.* != 0 {
        if pa.* != pb.* {
            return false;
        }
        pa = pa + 1;
        pb = pb + 1;
    }
    return pa.* == pb.*;
}

// Copy string to buffer, return length
fn strcpy(dest: *u8, src: *u8, max_len: i64) i64 {
    var i: i64 = 0;
    var src_ptr: *u8 = src;
    var dst_ptr: *u8 = dest;
    while src_ptr.* != 0 and i < max_len - 1 {
        dst_ptr.* = src_ptr.*;
        src_ptr = src_ptr + 1;
        dst_ptr = dst_ptr + 1;
        i = i + 1;
    }
    dst_ptr.* = 0;  // Null terminate
    return i;
}

fn print_usage() {
    print("Usage: cot0 <source.cot> -o <output>\n");
    print("\n");
    print("  <source.cot>  Input Cot source file\n");
    print("  -o <output>   Output object file\n");
}

// ============================================================================
// Main Entry Point
// ============================================================================

fn main(argc: i64, argv: **u8) i64 {
    print("Cot0 Self-Hosting Compiler v0.2\n");
    print("================================\n\n");

    // Parse command line arguments
    // Expected: cot0 <source.cot> -o <output>
    if argc < 4 {
        print("Error: Not enough arguments\n\n");
        print_usage();
        return 1;
    }

    // Get source file path (argv[1])
    let argv_ptr1: **u8 = argv + 1;
    let source_path: *u8 = argv_ptr1.*;

    // Check for -o flag (argv[2])
    let argv_ptr2: **u8 = argv + 2;
    let flag: *u8 = argv_ptr2.*;

    // Build expected flag string
    var dash_o: [3]u8;
    dash_o[0] = 45;  // '-'
    dash_o[1] = 111; // 'o'
    dash_o[2] = 0;

    if !streq(flag, &dash_o[0]) {
        print("Error: Expected -o flag\n\n");
        print_usage();
        return 1;
    }

    // Get output path (argv[3])
    let argv_ptr3: **u8 = argv + 3;
    let output_path: *u8 = argv_ptr3.*;
    let output_len: i64 = strlen(output_path);

    // Copy output path to global buffer (for null-termination)
    g_output_path_len = strcpy(&g_output_path[0], output_path, MAIN_MAX_OUTPUT_PATH);

    // Read source file
    print("Reading: ");
    var source_ptr: *u8 = source_path;
    while source_ptr.* != 0 {
        write(1, source_ptr, 1);
        source_ptr = source_ptr + 1;
    }
    print("\n");

    let bytes_read: i64 = read_file(source_path);
    if bytes_read < 0 {
        return 1;
    }

    print("  Read ");
    print_int(bytes_read);
    print(" bytes\n\n");

    // Extract base directory from source path for resolving imports
    let source_path_len: i64 = strlen(source_path);
    extract_base_dir(source_path, source_path_len);

    // Create string view of source
    let source: string = @string(&g_source[0], g_source_len);

    let result: i64 = Driver_compileFile(source, &g_output_path[0], g_output_path_len);

    if result == 0 {
        print("\nCompilation successful!\n");
    } else {
        print("\nCompilation failed with code ");
        print_int(result);
        print("\n");
    }

    return result;
}
